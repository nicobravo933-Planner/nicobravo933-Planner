[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Arquitectura de suministros",
    "section": "",
    "text": "Bienvenido\nEste espacio [Aún en construcción] no es solo texto teórico sobre logística; es una hoja de ruta diseñada para transformar datos crudos en decisiones estratégicas. En el mundo real de la Supply Chain, la teoría académica suele chocar con la fricción de los datos sucios, la incertidumbre de los tiempos de entrega y la volatilidad implacable de la demanda. Aquí no encontrarás soluciones ideales para problemas inexistentes; aprenderás a navegar el caos real, paso a paso.\nNuestra premisa es clara: en la cadena de suministro moderna, la intuición ya no es suficiente. A medida que los mercados se vuelven más complejos, la capacidad de procesar, modelar y simular escenarios se convierte en la ventaja competitiva definitiva. Este manual ha sido creado para cerrar la brecha entre el analista tradicional y el Supply Chain Data Scientist, dotándote de un arsenal de herramientas que van desde la limpieza profunda de datos hasta la optimización multi-escalón.",
    "crumbs": [
      "Bienvenido"
    ]
  },
  {
    "objectID": "index.html#de-qué-trata-este-espacio",
    "href": "index.html#de-qué-trata-este-espacio",
    "title": "Arquitectura de suministros",
    "section": "¿De qué trata este espacio?",
    "text": "¿De qué trata este espacio?\nEs, fundamentalmente, un manual de ingeniería aplicada. Es el recurso que a muchos nos hubiera gustado tener al iniciar nuestra carrera en la intersección de las operaciones y la analítica: un puente que no solo explica qué es un inventario, sino cómo optimizarlo utilizando el poder del código y la Ciencia de Datos moderna.\nNuestra filosofía es simple: hacer lo complejo, accionable. No pretendemos reinventar la rueda, sino enseñarte a construir una que ruede mejor bajo presión. A lo largo de estas páginas, pasaremos de los conceptos básicos a la implementación robusta en R y Python, priorizando siempre la generación de valor que impacte directamente en el nivel de servicio y la salud financiera de la organización.\nLa realidad de la cadena de suministro es un sistema vivo, dinámico y, a menudo, desordenado. En este manual, desarrollaremos un ecosistema de herramientas para domesticar esa incertidumbre, transitando desde la auditoría inicial de visibilidad hasta la simulación avanzada de redes complejas.",
    "crumbs": [
      "Bienvenido"
    ]
  },
  {
    "objectID": "index.html#a-quien-está-dirigido",
    "href": "index.html#a-quien-está-dirigido",
    "title": "Arquitectura de suministros",
    "section": "¿A quien está dirigido?",
    "text": "¿A quien está dirigido?\nSi eres un analista que busca evolucionar hacia el Data Science, un planeador de demanda que desea automatizar sus modelos para ganar tiempo estratégico, o un líder de operaciones que necesita entender la “caja negra” de los algoritmos para tomar mejores decisiones, este manual es para ti.\nAquí no solo encontrarás ecuaciones; aprenderás a interpretar visualizaciones que cuentan historias, a detectar y mitigar sesgos humanos y, sobre todo, a responder con confianza a la pregunta crítica del negocio: “¿Para qué nos sirve esto hoy?”",
    "crumbs": [
      "Bienvenido"
    ]
  },
  {
    "objectID": "index.html#estructura-detallada",
    "href": "index.html#estructura-detallada",
    "title": "Arquitectura de suministros",
    "section": "Estructura Detallada",
    "text": "Estructura Detallada\nA través de estas páginas, no solo construiremos modelos; construiremos un criterio técnico para saber cuándo confiar en un algoritmo y cuándo intervenir con el juicio de negocio. El objetivo final es simple pero ambicioso: que dejes de ser un espectador de los problemas de inventario y te conviertas en el arquitecto de una red de suministro resiliente, eficiente y, sobre todo, inteligente.\nEl sitio está diseñado como una hoja de ruta técnica y estratégica, dividida en seis ejes fundamentales:\n\nParte I: El Diagnóstico (Llegando a la empresa)\nEnfoque: Visibilidad y limpieza. No puedes arreglar lo que no ves.\n\nCapítulo 1: ¿Dónde estoy parado? Auditoría de datos, identificación de fuentes y mapeo del flujo de la cadena de suministro.\nCapítulo 2: El Espejo de la Realidad: Diferenciación entre ventas históricas y demanda real (no restringida), analizando el impacto oculto de los quiebres de stock.\nCapítulo 3: Clasificando el Caos: Implementación de segmentación ABC/XYZ dinámica utilizando Python para priorizar productos según valor y variabilidad.\nCapítulo 4: ¿Qué tan mal estamos? Definición del Baseline y métricas críticas de error como MAE, RMSE y Bias para medir la precisión actual.\n\n\n\nParte II: Prediciendo el Futuro (La Base del Pronóstico)\nEnfoque: Pasar de la intuición a la estadística descriptiva e inferencial.\n\nCapítulo 5: El Pronóstico Ingenuo: Implementación de modelos Naive para establecer un punto de comparación (Benchmark) mínimo.\nCapítulo 6: Suavizando la Curva: Aplicación de Suavizamiento Exponencial (Simple, Holt y Holt-Winters) y modelos estadísticos tradicionales.\nCapítulo 7: Detectando Patrones: Identificación y descomposición de series de tiempo en sus componentes: Estacionalidad, Tendencia y Ciclos.\n\n\n\nParte III: El Arsenal del Científico de Datos\nEnfoque: Escalando la precisión mediante el uso de Machine Learning avanzado.\n\nCapítulo 8: Creando Inteligencia: Ingeniería de atributos (Feature Engineering), creación de Lags, impacto de precios y uso de variables externas.\nCapítulo 9: El Bosque de las Decisiones: Aplicación práctica de algoritmos Random Forest y XGBoost para capturar patrones no lineales en la demanda.\nCapítulo 10: Evitando el Espejismo: Técnicas de Validación Cruzada (Time Series Split) y estrategias para prevenir el sobreajuste (Overfitting).\n\n\n\nParte IV: La Ciencia del Stock (Optimización de Inventarios)\nEnfoque: Traducir el pronóstico en decisiones de compra y almacenamiento: ¿Cuánto y cuándo pedir?\n\nCapítulo 11: El Costo del Dinero y el Costo del Vacío: Modelado financiero de los costos de mantener inventario frente a los costos de escasez.\nCapítulo 12: La Receta Básica: Aplicación del Lote Económico (EOQ) y Punto de Reorden en entornos de demanda estable.\nCapítulo 13: El Colchón contra la Incertidumbre: Cálculo científico del Stock de Seguridad basado en el Nivel de Servicio objetivo y la variabilidad.\nCapítulo 14: Más allá de la Curva Normal: Modelado de demandas erráticas o “Lumpy” utilizando Distribución Gamma y otros enfoques no tradicionales.\n\n\n\nParte V: Simulaciones y Redes Complejas\nEnfoque: Reconocer que el mundo real es un sistema dinámico y no una fórmula estática.\n\nCapítulo 15: El Laboratorio Virtual: Uso de Simulación de Monte Carlo para someter a prueba las políticas de inventario bajo miles de escenarios posibles.\nCapítulo 16: El Efecto Dominó: Comprensión y mitigación del Efecto Látigo (Bullwhip Effect) y optimización de redes multi-escalón (MEIO).\nCapítulo 17: Optimizando bajo Presión: Uso de Sim-Opt (Simulación-Optimización) para hallar la política perfecta en sistemas complejos.\n\n\n\nParte VI: El Factor Humano y la Ejecución\nEnfoque: Asegurar la adopción de los modelos por parte de la organización.\n\nCapítulo 18: ¿Aportamos Valor?: Implementación del marco FVA (Forecast Value Added) para medir qué pasos del proceso realmente mejoran la precisión.\nCapítulo 19: La Guerra contra los Sesgos: Cómo gestionar el juicio humano y aprovechar la “sabiduría de las multitudes” sin dañar el pronóstico.\nCapítulo 20: El Plan Maestro: Integración final de los modelos en el proceso de S&OP (Sales and Operations Planning) y comunicación efectiva hacia la alta gerencia.\n\n\n\n\n\n\n\nNoteRequisitos previos\n\n\n\nPara aprovechar al máximo este espacio, necesitarás:\n\nConocimientos básicos de R, Python.\nFamiliaridad con conceptos de Supply Chain\nAcceso a RStudio y las librerías mencionadas en cada capítulo\n\n\n\n\nPrepárate para “ensuciarte las manos” y cambiar tu forma de ver un inventario para siempre.",
    "crumbs": [
      "Bienvenido"
    ]
  },
  {
    "objectID": "cap-1-auditoria.html",
    "href": "cap-1-auditoria.html",
    "title": "1. Auditoría de Datos y Arquitectura de Red",
    "section": "",
    "text": "¿Dónde estoy parado? ¿Como empiezo?\nSi estás leyendo esto, probablemente acabas de aterrizar en un nuevo rol, te han asignado un proyecto de mejora o simplemente te cansaste de vivir apagando incendios. Tienes tu café en mano, tu notebook moderna y acceso a un montón de carpetas compartidas y esa clásica sensación de “¿por dónde empiezo?”.\nTranquilo, todos hemos estado ahí. No vamos a empezar tirando código a lo loco ni hablando de algoritmos complejos. Primero vamos a entender el terreno, como quien revisa el mapa y el equipo antes de salir de excursión a la montaña. Relájate, tómate un sorbo de ese café y veamos qué tenemos realmente entre manos antes de ponernos el casco de ingeniero.\nAl iniciar un proyecto de optimización de cadena de suministro, la primera tarea crítica no es la selección del algoritmo de predicción, sino la auditoría estructural de la información. Independientemente de si la organización opera con un ERP1 de última generación (como SAP S/4HANA) o con sistemas legados fragmentados, el principio fundamental de la ingeniería de datos permanece inalterable: la validación de la fuente.\nEn el entorno actual, es común encontrar iniciativas de transformación digital que fallan no por la tecnología, sino por la calidad de la materia prima: los datos. Si no existe certeza sobre la integridad del inventario, la veracidad de los tiempos de entrega (Lead Times) o la consistencia de las unidades de medida, cualquier modelo avanzado actuará simplemente como un amplificador de errores sistémicos.\nEste capítulo establece el protocolo técnico para auditar la infraestructura de datos y definir la arquitectura de la red antes de iniciar cualquier modelado.\nSonó complejo, eh? Vamos de a poco.",
    "crumbs": [
      "I: El Diagnóstico",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>1. Auditoría de Datos y Arquitectura de Red</span>"
    ]
  },
  {
    "objectID": "cap-1-auditoria.html#arquitectura-de-la-cadena-de-la-línea-a-la-red",
    "href": "cap-1-auditoria.html#arquitectura-de-la-cadena-de-la-línea-a-la-red",
    "title": "1. Auditoría de Datos y Arquitectura de Red",
    "section": "1.1 Arquitectura de la Cadena: De la Línea a la Red",
    "text": "1.1 Arquitectura de la Cadena: De la Línea a la Red\nUn error conceptual frecuente en la fase de diseño es la simplificación excesiva de la cadena de suministro, asumiendo un flujo lineal unidireccional (Proveedor \\(\\rightarrow\\) Fábrica \\(\\rightarrow\\) Cliente). La realidad operativa moderna se configura como una red de grafos complejos compuesta por nodos y arcos con restricciones específicas.\nPara modelar correctamente el flujo de materiales e información, debemos mapear la topología de la red con precisión:\n\n1.1.1 Definición de Nodos (Vertices)\nLos nodos representan los puntos estáticos donde el producto se detiene, se transforma o cambia de propiedad.\n\nCentros de Manufactura: Deben caracterizarse por sus restricciones de capacidad finita, calendarios operativos y tiempos de cambio (setup times).\nCentros de Distribución (CDs) y Hubs: Es crítico distinguir entre CDs propios y operadores logísticos externos (3PL2). La visibilidad de datos en un 3PL suele tener mayor latencia.\nPuntos de Venta / Nodos Finales: La estructura debe diferenciar si el nodo final posee capacidad de almacenamiento (Back-room) o si opera bajo modelos de flujo tenso.\n\n\n\n1.1.2 Definición de Arcos (Edges)\nLos arcos representan el movimiento y las reglas de flujo entre nodos.\n\nRutas Logísticas: No todos los flujos son directos. Existen operaciones de Cross-docking, Milk-runs y Transbordos.\nImpacto en la Modelación: Si el sistema registra una venta directa A \\(\\rightarrow\\) B, pero físicamente el producto pasa por un nodo C, la omisión del nodo C en el modelo resultará en una subestimación de costos y tiempos.\n\n\n\n\n\n\n\nTipConsejo de Implementación\n\n\n\nAl documentar la arquitectura, no confíes solo en el plano teórico del sistema. Valida físicamente los flujos con el Jefe de Tráfico. A menudo, las “rutas excepcionales” (que no están en el manual) representan el 20% del volumen real y son las causantes de la variabilidad no explicada en el Lead Time.",
    "crumbs": [
      "I: El Diagnóstico",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>1. Auditoría de Datos y Arquitectura de Red</span>"
    ]
  },
  {
    "objectID": "cap-1-auditoria.html#estandarización-de-la-nomenclatura-y-jerarquías",
    "href": "cap-1-auditoria.html#estandarización-de-la-nomenclatura-y-jerarquías",
    "title": "1. Auditoría de Datos y Arquitectura de Red",
    "section": "1.2 Estandarización de la Nomenclatura y Jerarquías",
    "text": "1.2 Estandarización de la Nomenclatura y Jerarquías\nLa falta de un léxico estandarizado entre Operaciones, Comercial y Data Science es la causa raíz de numerosas discrepancias analíticas. Es imperativo definir la Unidad de Análisis.\n\n1.2.1 La Unidad Fundamental: SKU vs. DFU\n\nSKU (Stock Keeping Unit): Referencia al ítem físico con sus atributos intrínsecos (peso, dimensiones, fórmula). Definición estática.\nDFU (Demand Forecasting Unit): Unidad mínima de planificación. Intersección entre Producto, Ubicación y Canal.\nEAN / UPC : Es el código de barras universal. Un mismo SKU puede tener varios EAN si el proveedor cambió el empaque pero el producto es el mismo.\n\nJustificación Técnica: Analizar la demanda a nivel SKU agregado oculta la variabilidad geográfica. Los parámetros de inventario (Stock de Seguridad, ROP) deben calcularse siempre a nivel DFU.\n\n\n1.2.2 Jerarquías de Producto\nPara gestionar la complejidad de miles de SKUs, es necesario estructurar una jerarquía de agregación robusta (SKU \\(\\rightarrow\\) Subfamilia \\(\\rightarrow\\) Familia \\(\\rightarrow\\) Categoría).\nEl BOM (Bill of Materials) o Explosión de Materiales\nEl BOM es la “receta” que define los componentes necesarios para fabricar o ensamblar un producto terminado.\nIntegridad de la Planificación: Si el BOM en el ERP tiene errores (cantidades incorrectas o componentes obsoletos), cualquier modelo de optimización generará compras erróneas de materia prima.\nDemanda Independiente: Es la del producto final (SKU Padre) que se vende al cliente y que debemos pronosticar.\nDemanda Dependiente: Es la de los componentes (SKUs Hijos) definidos en el BOM. Esta no se pronostica, se calcula a partir del plan de producción del producto padre.\nKits y Packs: En distribución, el BOM define si ciertos SKUs se venden como “combos”. Auditar esto evita duplicar el pronóstico del producto individual y del kit simultáneamente.\n\n\n1.2.3 Consistencia en Unidades de Medida (UoM) y el Factor de Conversión\nLa inconsistencia en las unidades de medida es uno de los riesgos más subestimados y críticos en la integración de datos. Mientras el departamento comercial habla en “pesos”, el almacén opera en “pallets” y el cliente final compra en “unidades”.\nPara un modelo de Ciencia de Datos, trabajar con unidades heterogéneas es una receta para el desastre. Imagina que tu algoritmo de Machine Learning predice una demanda de “10”, pero el sistema de compras lo interpreta como “10 cajas de 24 unidades” en lugar de “10 unidades sueltas”. El error resultante es de un 2,400%.\nEl Problema de la Multiplicidad de Unidades:\n\nVentas: Suele reportar en Moneda o Unidades de Venta (Cajas/Packs).\nAlmacén (WMS): Gestiona Pallets, Camas o Ubicaciones.\nMarketing/Comercial: Analiza Unidades de Consumo (EAN individual).\nProducción/Compras: Utiliza Unidades de Medida Base (Kilos, Litros, Metros).",
    "crumbs": [
      "I: El Diagnóstico",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>1. Auditoría de Datos y Arquitectura de Red</span>"
    ]
  },
  {
    "objectID": "cap-1-auditoria.html#el-ecosistema-de-sistemas-de-información-el-mapa-de-la-verdad",
    "href": "cap-1-auditoria.html#el-ecosistema-de-sistemas-de-información-el-mapa-de-la-verdad",
    "title": "1. Auditoría de Datos y Arquitectura de Red",
    "section": "1.3 El Ecosistema de Sistemas de Información: El Mapa de la Verdad",
    "text": "1.3 El Ecosistema de Sistemas de Información: El Mapa de la Verdad\nLa información de la cadena de suministro no es monolítica; reside en un ecosistema de aplicaciones interconectadas. Para un científico de datos, identificar el Sistema de Registro (System of Record - SoR) es vital para asegurar que se está extrayendo la variable de la fuente primaria y no de una réplica distorsionada.\n\nERP (Enterprise Resource Planning): Es la columna vertebral financiera y el repositorio de los Datos Maestros. Aquí auditaremos los precios netos, los costos unitarios (PPP) y las jerarquías oficiales de productos. Sin embargo, el ERP suele ser “ciego” a los movimientos granulares de la bodega.\nWMS (Warehouse Management System): Es la autoridad absoluta sobre el Inventario Físico. A diferencia del ERP, el WMS registra mermas, bloqueos de calidad y ubicaciones en tiempo real. Es nuestra fuente para calcular la disponibilidad real frente a la teórica.\nTMS (Transportation Management System): Es la fuente esencial para auditar el Lead Time de Transporte. Mientras el ERP dice cuándo “debería” llegar un camión, el TMS registra mediante GPS o estatus de transportista cuándo llegó realmente, permitiéndonos modelar la variabilidad del suministro.\nPOS (Point of Sale): En entornos de Retail, el POS proporciona el Sell-out (la venta real al consumidor final)9. Este dato es la “demanda pura”, libre del ruido que generan los pedidos intermedios de los distribuidores o el reabastecimiento a tiendas.\nMRP (Material Requirements Planning): Es el motor lógico que orquestra la ejecución. El MRP toma el pronóstico de demanda, consulta el BOM (Bill of Materials) para realizar la explosión de materiales y revisa los niveles de stock para generar órdenes de compra o producción.\n\n\n\n\n\n\n\nCautionEl riesgo del dato “duplicado”\n\n\n\nEs común que el ERP y el WMS tengan cifras de inventario distintas. En tu auditoría, establece siempre una jerarquía de verdad: si hay discrepancia en unidades físicas, el WMS manda; si la hay en valor monetario, el ERP manda. Ignorar estas jerarquías llevará a que tus modelos de optimización (Parte IV) sugieran comprar productos que ya tienes “escondidos” en alguna ubicación del WMS no sincronizada con el ERP.",
    "crumbs": [
      "I: El Diagnóstico",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>1. Auditoría de Datos y Arquitectura de Red</span>"
    ]
  },
  {
    "objectID": "cap-1-auditoria.html#selección-de-herramientas-excel-pythonr-y-sql",
    "href": "cap-1-auditoria.html#selección-de-herramientas-excel-pythonr-y-sql",
    "title": "1. Auditoría de Datos y Arquitectura de Red",
    "section": "1.4 Selección de Herramientas: Excel, Python/R y SQL",
    "text": "1.4 Selección de Herramientas: Excel, Python/R y SQL\nAntes de proceder al análisis, debemos justificar la elección de la plataforma tecnológica. Si bien las hojas de cálculo son omnipresentes, presentan limitaciones severas para la ingeniería de datos robusta.\n\n1.4.1 Limitaciones de la Hoja de Cálculo\n\nVolumen: Excel tiene un límite físico de 1,048,576 filas. Una cadena de suministro mediana genera este volumen de transacciones en cuestión de semanas. R y Python están limitados únicamente por la memoria RAM del equipo.\nTrazabilidad: En una hoja de cálculo, las acciones (filtrar, borrar, ordenar) son efímeras. Si un analista elimina un registro por error (“Fat Finger”), no queda rastro de la operación.\nReproducibilidad: Este es el factor decisivo. Un análisis basado en código (script) es una “receta” auditable y repetible. Si los datos base cambian, el script se ejecuta nuevamente sin intervención manual, garantizando consistencia.\n\n\n\n1.4.2 El Rol de SQL: La Fuente de la Verdad\nUna práctica común pero deficiente es basar el análisis en archivos planos (CSV, TXT) exportados manualmente. * El problema del CSV: Es una “foto estática” (snapshot). En el momento en que se descarga, el dato comienza a volverse obsoleto. Además, pierde los tipos de datos (fechas que se vuelven texto, números que pierden decimales). * La ventaja de SQL: Conectarse directamente a la base de datos permite consultar la Fuente de la Verdad (SSOT) en tiempo real. Permite realizar el filtrado y agregación en el servidor antes de traer los datos a la memoria local.\n\n\n\n\n\n\nTipFlujo de Trabajo Recomendado\n\n\n\nEl flujo profesional recomendado hoy en dia es: SQL (Extracción y Filtrado) \\(\\rightarrow\\) R/Python (Limpieza y Modelado) \\(\\rightarrow\\) BI/Reporte (Visualización) Power BI / Tableau",
    "crumbs": [
      "I: El Diagnóstico",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>1. Auditoría de Datos y Arquitectura de Red</span>"
    ]
  },
  {
    "objectID": "cap-1-auditoria.html#análisis-exploratorio-de-datos-eda-y-calidad",
    "href": "cap-1-auditoria.html#análisis-exploratorio-de-datos-eda-y-calidad",
    "title": "1. ¿Dónde estoy parado? ¿Como empiezo?",
    "section": "1.5 Análisis Exploratorio de Datos (EDA) y Calidad",
    "text": "1.5 Análisis Exploratorio de Datos (EDA) y Calidad\nVamos a utilizar dataset de ejemplo, que nos acompañe durante el desarrollo de estos capítulos:\n\n# Cargamos la configuración global y el generador de datos\nsource(\"_common.R\")\n\n# Obtenemos los activos para el Capítulo 1 (Escenario simplificado)\nactivos &lt;- get_chapter_assets(1)\n\nproductos &lt;- activos$productos\nventas    &lt;- activos$ventas\ncompras   &lt;- activos$compras\n\n#Evitar notacion cientifica\noptions(scipen = 999)\n\n\nMaestro de Productos (productos): Datos que no cambian seguido (Atributos).\nTransacciones de Ventas (ventas): La voz del cliente (Demanda).\nTransacciones de Compras (compras): Nuestra gestión con proveedores (Abastecimiento).\n\nAntes de analizar cuánto vendemos, debemos saber qué vendemos. El maestro de productos contiene información crítica como el costo, el precio y el Lead Time Prometido.\n\nlibrary(kableExtra)\n\n# Veamos nuestros primeros productos\nknitr::kable(head(productos), align = \"c\",digits = 2) %&gt;%\n  kable_styling(position = \"center\")\n\n\n\n\nsku_id\ncategoria\ncosto_unitario\nprecio_venta\nlead_time_prometido\nstock_inicial\n\n\n\n\nSKU-0001\nElectrónica\n80.87\n110.33\n30\n393\n\n\nSKU-0002\nElectrónica\n77.44\n136.80\n5\n324\n\n\nSKU-0003\nAlimentos\n49.93\n73.27\n15\n299\n\n\nSKU-0004\nQuímicos\n54.08\n82.48\n15\n436\n\n\nSKU-0005\nTextil\n28.40\n36.83\n30\n285\n\n\nSKU-0006\nHogar\n44.06\n71.19\n15\n180\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nObserva que cada producto tiene un lead_time_prometido. Este es el valor que el proveedor nos aseguró por contrato. En capítulos siguientes, veremos si realmente lo cumplen.\n\n\n\n1.5.1 Completitud, Corte de Datos y el Peligro de Trabajar con “Fantasmas”\nEl análisis de completitud no es más que una inspección de salud: ¿están todos los que deberían estar? En Supply Chain, los datos no son solo números; son el rastro digital de camiones moviéndose, gente haciendo picking y clientes comprando. Si faltan datos, es como intentar armar un rompecabezas al que le faltan las piezas del centro.\n¿Qué revisar en la integridad de datos entonces?\n\nCompletitud → ¿faltan valores en columnas críticas?\nConsistencia → ¿los tipos de datos son correctos (fechas, números, texto)?\nValidez → ¿los valores cumplen reglas de negocio (ejemplo: precio ≥ 0)?\nUnicidad → ¿hay duplicados en claves primarias (ejemplo: ID de venta)?\nRangos → ¿las fechas están dentro del período esperado?\n\n\n¿Qué pasa si NO lo haces?\n\nResultados erróneos en los análisis: Si hay duplicados, valores faltantes o inconsistentes, las métricas (promedios, totales, tendencias) pueden quedar distorsionadas y llevar a conclusiones equivocadas.\nDecisiones equivocadas: En un entorno empresarial, basarse en datos incorrectos puede significar comprar demasiado stock, calcular mal la rentabilidad o tomar decisiones estratégicas con información falsa.\nPérdida de confianza: Si los reportes muestran incoherencias, los equipos y directivos dejan de confiar en los datos, lo que afecta la credibilidad del área de análisis o del sistema.\nProblemas regulatorios y legales: En sectores como finanzas, salud o energía, datos incompletos o incorrectos pueden violar normas de cumplimiento y generar sanciones.\nCostos ocultos: Tiempo extra para limpiar datos después, reprocesar informes, corregir errores en sistemas, o incluso pérdidas económicas por decisiones mal fundamentadas.\nImposibilidad de escalar proyectos: Si la base no es confiable, cualquier intento de aplicar modelos predictivos, machine learning o dashboards avanzados se vuelve inestable.\n\nPaso 1: Panorama general\nUsa skimr para ver tipos de variables, valores faltantes y rangos:\n\nlibrary(skimr)\n\nskim(maestro_prod)\n\n\nData summary\n\n\nName\nmaestro_prod\n\n\nNumber of rows\n1000\n\n\nNumber of columns\n6\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n2\n\n\nnumeric\n4\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nsku_id\n0\n1\n8\n8\n0\n1000\n0\n\n\ncategoria\n0\n1\n5\n11\n0\n5\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\ncosto_unitario\n0\n1\n50.07\n28.00\n5.00\n29.89\n49.61\n69.83\n154.86\n▆▇▅▁▁\n\n\nprecio_venta\n0\n1\n75.54\n43.56\n6.01\n42.35\n74.09\n102.87\n271.84\n▇▇▃▁▁\n\n\nlead_time_prometido\n0\n1\n15.62\n9.64\n5.00\n10.00\n15.00\n30.00\n30.00\n▇▃▁▁▅\n\n\nstock_inicial\n0\n1\n300.13\n116.78\n100.00\n202.00\n303.50\n399.25\n500.00\n▇▇▇▇▇\n\n\n\n\nskim(compras_hist)\n\n\nData summary\n\n\nName\ncompras_hist\n\n\nNumber of rows\n90822\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n1\n\n\nDate\n2\n\n\nnumeric\n2\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nsku_id\n0\n1\n8\n8\n0\n1000\n0\n\n\n\nVariable type: Date\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\nfecha_pedido\n0\n1\n2019-01-01\n2023-12-26\n2021-06-27\n1821\n\n\nfecha_recepcion\n0\n1\n2019-01-05\n2023-12-31\n2021-07-14\n1822\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\ncantidad_pedida\n0\n1\n750.68\n144.56\n500\n626.00\n751.00\n876.0\n1000.0\n▇▇▇▇▇\n\n\ncosto_total_compra\n0\n1\n37527.55\n22538.71\n2500\n20606.74\n35699.73\n51704.3\n154549.4\n▇▇▂▁▁\n\n\n\n\nskim(ventas_hist)\n\n\nData summary\n\n\nName\nventas_hist\n\n\nNumber of rows\n1807904\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n1\n\n\nDate\n1\n\n\nnumeric\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nsku_id\n0\n1\n8\n8\n0\n1000\n0\n\n\n\nVariable type: Date\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\nfecha\n0\n1\n2019-01-01\n2023-12-31\n2021-07-09\n1826\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\ncantidad_solicitada\n0\n1\n13.14\n5.30\n1.00\n9.00\n13.00\n17.00\n37.00\n▃▇▅▁▁\n\n\nprecio_venta\n0\n1\n75.55\n43.55\n6.01\n42.40\n74.11\n102.89\n271.84\n▇▇▃▁▁\n\n\nventa_total_usd\n0\n1\n992.64\n735.38\n6.01\n428.24\n857.30\n1395.85\n8155.18\n▇▂▁▁▁\n\n\n\n\n\nPaso 2: Integridad básica\n\nDuplicados\n\n\nlibrary(janitor)\n\nget_dupes(maestro_prod)   # productos repetidos\n\n# A tibble: 0 × 7\n# ℹ 7 variables: sku_id &lt;chr&gt;, categoria &lt;chr&gt;, costo_unitario &lt;dbl&gt;,\n#   precio_venta &lt;dbl&gt;, lead_time_prometido &lt;dbl&gt;, stock_inicial &lt;dbl&gt;,\n#   dupe_count &lt;int&gt;\n\nget_dupes(compras_hist)     # compras repetidas\n\n# A tibble: 0 × 6\n# ℹ 6 variables: sku_id &lt;chr&gt;, fecha_pedido &lt;date&gt;, fecha_recepcion &lt;date&gt;,\n#   cantidad_pedida &lt;dbl&gt;, costo_total_compra &lt;dbl&gt;, dupe_count &lt;int&gt;\n\nget_dupes(ventas_hist)      # ventas repetidas\n\n# A tibble: 0 × 6\n# ℹ 6 variables: fecha &lt;date&gt;, sku_id &lt;chr&gt;, cantidad_solicitada &lt;dbl&gt;,\n#   precio_venta &lt;dbl&gt;, venta_total_usd &lt;dbl&gt;, dupe_count &lt;int&gt;\n\n\n\nValores faltantes:\n\n\nsapply(productos, function(x) sum(is.na(x)))\n\n             sku_id           categoria      costo_unitario        precio_venta \n                  0                   0                   0                   0 \nlead_time_prometido       stock_inicial \n                  0                   0 \n\nsapply(compras, function(x) sum(is.na(x)))\n\n            sku_id       fecha_pedido    fecha_recepcion    cantidad_pedida \n                 0                  0                  0                  0 \ncosto_total_compra \n                 0 \n\nsapply(ventas, function(x) sum(is.na(x)))\n\n              fecha              sku_id cantidad_solicitada        precio_venta \n                  0                   0                   0                   0 \n    venta_total_usd \n                  0 \n\n\n\nRangos válidos (ejemplo: precios ≥ 0, cantidades &gt; 0):\n\n\nventas %&gt;% filter(cantidad_solicitada &lt;= 0 | precio_venta &lt;= 0)\n\n# A tibble: 0 × 5\n# ℹ 5 variables: fecha &lt;date&gt;, sku_id &lt;chr&gt;, cantidad_solicitada &lt;dbl&gt;,\n#   precio_venta &lt;dbl&gt;, venta_total_usd &lt;dbl&gt;\n\n\nPaso 3: Relaciones entre tabla\n\nIntegridad referencial: ¿las claves coinciden?\n\n\n# Ventas con productos inexistentes\nventas %&gt;% filter(!sku_id %in% productos$sku_id)\n\n# A tibble: 0 × 5\n# ℹ 5 variables: fecha &lt;date&gt;, sku_id &lt;chr&gt;, cantidad_solicitada &lt;dbl&gt;,\n#   precio_venta &lt;dbl&gt;, venta_total_usd &lt;dbl&gt;\n\n# Compras con productos inexistentes\ncompras %&gt;% filter(!sku_id %in% productos$sku_id)\n\n# A tibble: 0 × 5\n# ℹ 5 variables: sku_id &lt;chr&gt;, fecha_pedido &lt;date&gt;, fecha_recepcion &lt;date&gt;,\n#   cantidad_pedida &lt;dbl&gt;, costo_total_compra &lt;dbl&gt;\n\n\n\nFechas coherentes: ¿Las ventas ocurren después de las compras? ¿Hay fechas futuras?\n\n\nrange(ventas_hist$fecha)\n\n[1] \"2019-01-01\" \"2023-12-31\"\n\nrange(compras_hist$fecha_pedido)\n\n[1] \"2019-01-01\" \"2023-12-26\"\n\n\nPaso 4: Estadísticas rápidas\n\nDistribución de precios y cantidades:\n\n\nsummary(ventas_hist$precio_venta)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  6.013  42.403  74.107  75.545 102.893 271.839 \n\nsummary(ventas_hist$cantidad_pedido)\n\nLength  Class   Mode \n     0   NULL   NULL \n\n\n\nTop productos más vendidos:\n\n\nventas %&gt;%\n  group_by(sku_id) %&gt;%\n  summarise(total = sum(cantidad_solicitada)) %&gt;%\n  arrange(desc(total)) %&gt;%\n  head(10)\n\n# A tibble: 10 × 2\n   sku_id   total\n   &lt;chr&gt;    &lt;dbl&gt;\n 1 SKU-0004  3352\n 2 SKU-0006  3346\n 3 SKU-0002  3338\n 4 SKU-0001  3298\n 5 SKU-0003  3285\n 6 SKU-0008  3277\n 7 SKU-0010  3272\n 8 SKU-0005  3218\n 9 SKU-0007  3216\n10 SKU-0009  3200\n\n\nPaso 5: Visualizaciones rápida\n\nlibrary(ggplot2)\n\n# Ventas por mes\nventas_hist %&gt;%\n  mutate(mes = lubridate::floor_date(fecha, \"month\")) %&gt;%\n  group_by(mes) %&gt;%\n  summarise(total = sum(cantidad_solicitada)) %&gt;%\n  ggplot(aes(mes, total)) +\n  geom_line() +\n  labs(title = \"Ventas mensuales\")\n\n\n\n\n\n\n\n\nLa prueba de fuego: ¿Faltan días?\nSi estamos analizando un año, deberíamos tener registros de venta (o al menos la presencia de la fecha con venta cero) para cada día. Vamos a crear un calendario “maestro” y compararlo con nuestras ventas reales para detectar silencios del sistema.\n\n# 1. Crear el calendario ideal\ncalendario_ideal &lt;- tibble(fecha = seq(min(ventas$fecha), max(ventas$fecha), by = \"day\"))\n\n# 2. Cruzar con nuestras ventas para encontrar NAs (Vacíos)\nauditoria_fechas &lt;- calendario_ideal %&gt;%\n  left_join(ventas %&gt;% group_by(fecha) %&gt;% summarise(ventas_reales = n()), by = \"fecha\")\n\n# 3. Identificar los \"Fantasmas\"\ndias_sin_datos &lt;- sum(is.na(auditoria_fechas$ventas_reales))\n\nEl Semáforo de Integridad\nIgnorar estos huecos nos llevaría al Sesgo del Mes Incompleto. Si un algoritmo ve un cero donde debería haber un dato no grabado, bajará los niveles de inventario erróneamente. Visualicemos la salud de nuestros datos:\n\nauditoria_fechas %&gt;%\n  mutate(mes = floor_date(fecha, \"month\"),\n         estado = ifelse(is.na(ventas_reales), \"Faltante (Fantasma)\", \"OK\")) %&gt;%\n  group_by(mes, estado) %&gt;%\n  summarise(dias = n(), .groups = \"drop\") %&gt;%\n  ggplot(aes(x = mes, y = dias, fill = estado)) +\n  geom_col() +\n  scale_fill_manual(values = c(\"Faltante (Fantasma)\" = \"#e74c3c\", \"OK\" = \"#2ecc71\")) +\n  labs(title = \"Auditoría de Completitud Mensual\",\n       subtitle = \"Días con registros vs Días vacíos\",\n       x = \"Mes\", y = \"Cantidad de Días\")\n\n\n\n\n\n\n\nFigure 2.1: Mapa de Calor: Integridad de Datos Mensual\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nNunca imputes ceros a los valores NA sin investigar. Un NA es una duda (falló el sistema); un 0 es una certeza (nadie quiso comprar). Mezclarlos destruirá la precisión de tus algoritmos de Machine Learning.",
    "crumbs": [
      "I: El Diagnóstico",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>1. ¿Dónde estoy parado? ¿Como empiezo?</span>"
    ]
  },
  {
    "objectID": "cap-1-auditoria.html#gestión-de-valores-atípicos-outliers-y-winsorización",
    "href": "cap-1-auditoria.html#gestión-de-valores-atípicos-outliers-y-winsorización",
    "title": "1. Auditoría de Datos y Arquitectura de Red",
    "section": "1.6 Gestión de Valores Atípicos (Outliers) y Winsorización",
    "text": "1.6 Gestión de Valores Atípicos (Outliers) y Winsorización\nLa presencia de valores extremos puede originarse por eventos legítimos o errores de captura. La eliminación simple conlleva pérdida de información de volumen; la inclusión sin tratamiento infla el Stock de Seguridad.\n\n\n\n\n\n\nNoteOutliers: ¿Eliminar o Suavizar?\n\n\n\nExiste una diferencia crítica entre borrar datos y limpiar la señal. Se aconseja que nunca debemos eliminar un outlier, ya que representa una transacción real que existió. Lo que debemos hacer es suavizar su impacto para que no distorsione el futuro.\n\n\nVeamos el concepto con una grafica:\n\n\n\n\n\n\n\n\nFigure 1.2: Ejemplo de Outlier\n\n\n\n\n\nTécnica de Winsorización\nEn lugar de eliminar los datos extraños (lo que podría causar huecos en tu serie temporal), la Winsorización los “recorta”.\n\nSi un dato es demasiado alto, se reemplaza por el valor máximo permitido (el “techo”).\nEsto permite mantener la cronología de los datos pero reduciendo el impacto de picos inexplicables.\n\n\n\n\n\n\n\n\n\n\nMes\nDemanda Real\n¿Es Outlier?\nDemanda Winsorizada (Limpia)\n\n\nEnero\n95\nNo\n95\n\n\nFebrero\n110\nNo\n110\n\n\nMarzo\n500\nSÍ (Error)\n145 (Se ajusta al techo)\n\n\nAbril\n105\nNo\n105\n\n\n\n\n\n\n\n\n\nImportantEntonces es suavizar\n\n\n\n“Un outlier no es un error, es un evento”. Si lo eliminas, ignoras que tu cadena de suministro fue capaz de entregar ese volumen. Si lo suavizas, proteges tu pronóstico futuro de eventos que probablemente no se repitan el próximo mes.\n\n\nGrafiquemos para entender la idea:\n\n\n\n\n\n\n\n\nFigure 1.3: Outlier suavizado\n\n\n\n\n\n\nEl Método Tradicional - Desviación Estándar (\\(\\sigma\\))\nEn estadística tradicional es común ver la winsorización al percentil 95 o a 3 desviaciones estándar.\nNormalmente, una persona usaría la Regla de las 3 Sigmas. Se asume que los datos siguen una distribución normal y se calcula el límite así:\n\\[\n\\large Límite = Media \\pm \\left( 3 \\cdot Desviación\\ Estándar \\right)\n\\]\nEl problema con este enfoque:\n\nLa Media y la Desviación Estándar “se rompen” con los outliers: Si tienes un pico de demanda de 500 cuando lo normal es 100, la media sube a 150 y la desviación estándar se dispara.\nEl efecto “Smeared” (Manchado): Como el outlier infla la desviación estándar, el “techo” se vuelve tan alto que otros errores más pequeños ya no se detectan como anomalías. El outlier se “protege” a sí mismo moviendo la vara de medir.\n\n\n\nEl Método MAD (Median Absolute Deviation)\nEl MAD es más robusto que la desviación estándar tradicional.\n\nEl problema de la Desviación Estándar: Si tienes un outlier masivo, la media y la desviación estándar se inflan artificialmente, haciendo que el “filtro” sea menos eficaz.\nLa ventaja del MAD: Utiliza la mediana, que no se mueve aunque existan valores extremos. Es como calcular qué tan lejos está el dato típico de la mayoría, sin dejar que el outlier “engañe” al cálculo.\n\\[\n\\large Límite = \\text{Mediana} \\pm \\left( K \\cdot MAD \\right)\n\\]\nMediana: El centro de tus datos.\nK: Es un multiplicador de sensibilidad (normalmente entre 2 y 3).\nMAD: La medida de dispersión robusta.\n\nEjemplo:\nImagina que vendes un producto y tu demanda mensual habitual ronda las 100 unidades. Pero un mes hubo un error en el sistema y se registraron 500 unidades (un outlier masivo).\nPrimero calculamos los límites usando la fórmula de tu imagen:\n\nMediana: Es más estable. Si la mayoría de tus meses vendes 100, la mediana será 100, aunque haya un mes de 500.\nMAD (Desviación Absoluta de la Mediana): Mide cuánto varían tus datos típicos. Digamos que tu MAD es 15.\nK (Sensibilidad): Usemos un factor común de 3.\n\nCálculo del Techo: \\(100+(3⋅15)=145.\\)\nCualquier valor por encima de 145 se considera un “accidente logístico” y no negocio recurrente.\n\n\nComparación: Tradicional vs. MAD\nImagina estos datos de demanda: 100, 100, 100, 100, 500\n\n\n\n\n\n\n\n\nCaracterística\nMétodo Tradicional (Media / DS)\nMétodo MAD (Mediana / MAD)\n\n\nCentro\nLa Media sería 180. (Muy influenciada por el 500).\nLa Mediana sería 100. (No le importa el 500).\n\n\nSensibilidad\nEl límite sube tanto que el 500 podría parecer “normal”.\nEl límite se queda cerca de 100, marcando el 500 como outlier claro.\n\n\nRobustez\nBaja. Los accidentes logísticos deforman el cálculo.\nAlta. Detecta el accidente sin que este afecte al límite.\n\n\n\nImplementación Práctica - Con nuestros datos\nNo siempre vas a conseguir gráficas hermosas con los datos que dispongas, a veces es necesario ir filtrando por SKU o reducir el Periodo de análisis para ir acercándote y entender que sucede.\nEl Test Visual: El Boxplot (Diagrama de Caja)\nLa forma más rápida de responder a “¿Hay Outliers?” (Siempre los hay) es mediante un Boxplot. R calcula automáticamente los “bigotes” (1.5 veces el rango intercuartílico). Cualquier punto que flote por encima de esos bigotes es, técnicamente, un outlier.\n\n# Identificar top SKUs usando 'ventas' (el objeto global)\ntop_skus &lt;- ventas[, .(total = sum(cantidad_vendida, na.rm = TRUE)), by = sku_id][order(-total)][1:15, sku_id]\n\n# Filtrar para el gráfico\nventas_top &lt;- ventas[sku_id %in% top_skus]\n\nggplot(ventas_top, aes(x = reorder(sku_id, cantidad_vendida), y = cantidad_vendida)) +\n  geom_boxplot(fill = \"#3498db\", outlier.color = \"red\", outlier.alpha = 0.4) +\n  coord_flip() +\n  theme_minimal()\n\n\n\n\n\n\n\nFigure 1.4: Boxplot Top SKUs\n\n\n\n\n\nEl Test Estadístico: El Score MAD\nPara automatizar esto en miles de SKUs, usamos el MAD (Median Absolute Deviation). Vamos a crear un semáforo que nos diga qué porcentaje de nuestros datos son “ruido”.\n\n# 1. Aseguramos que sea data.table (eficiencia máxima)\nsetDT(ventas)\n\n# 2. Calculamos el diagnóstico directamente (Sin crear columnas extra en la tabla gigante)\n# Usamos k=3 (estándar para detectar anomalías fuertes)\ndiagnostico &lt;- ventas[, {\n  mediana_vta &lt;- median(cantidad_vendida, na.rm = TRUE)\n  mad_vta &lt;- median(abs(cantidad_vendida - mediana_vta), na.rm = TRUE)\n  limite &lt;- mediana_vta + (3 * mad_vta)\n  \n  # Retornamos los cálculos por cada SKU\n  .(\n    total_registros = .N,\n    cantidad_outliers = sum(cantidad_vendida &gt; limite, na.rm = TRUE),\n    mediana = mediana_vta,\n    limite_max_sugerido = limite\n  )\n}, by = sku_id]\n\n# 3. Agregamos el porcentaje de ruido y ordenamos\ndiagnostico[, porcentaje_ruido := (cantidad_outliers / total_registros) * 100]\n\n# 4. Mostramos con \"onda\" y centrado\nver_tabla_core(\n  diagnostico[order(-porcentaje_ruido)], \n  \"Diagnóstico de Calidad: SKUs con mayor ruido (MAD)\"\n)\n\n\n\n\n\nMira la tabla de arriba. Si el porcentaje_ruido es 0%, felicidades: tienes una operación quirúrgicamente estable. Pero lo normal es encontrar entre un 1% y un 5%.\n\n\n\n\n\n\nImportant¿Por qué es peligroso que existan?\n\n\n\nSi un SKU tiene un 2% de outliers pero esos picos son de 500 unidades cuando lo normal es 10, tu Stock de Seguridad se calculará basado en una variabilidad que no es real. Estarás guardando aire en el almacén (inventario inmovilizado) por culpa de un error que el sistema “creyó” que era demanda real.\n\n\nEl Test Visual: Puntos y Señal Suavizada\nPara este ejercicio, tomaremos un SKU específico. Pintaremos en negro la demanda habitual y en rojo aquellos puntos que el método MAD identifica como anomalías.\n\n# 1. Función robusta con factor de escala (1.4826 para asimilar a Desvío Estándar)\ndetectar_limites_mad &lt;- function(x, k = 3) {\n  mediana &lt;- median(x, na.rm = TRUE)\n  mad_val &lt;- median(abs(x - mediana), na.rm = TRUE) * 1.4826\n  \n  list(\n    inf = pmax(0, mediana - (k * mad_val)),\n    sup = mediana + (k * mad_val),\n    med = mediana\n  )\n}\n\n# 2. Selección automática: Buscamos el SKU con más ventas para probar el estrés\nsku_foco &lt;- ventas[, .(total = sum(cantidad_vendida)), by = sku_id][order(-total)][1, sku_id]\n\n# 3. Procesamiento ultra-rápido con data.table\nlimites &lt;- detectar_limites_mad(ventas[sku_id == sku_foco, cantidad_vendida])\ndata_plot &lt;- ventas[sku_id == sku_foco]\n\n# Marcamos outliers basándonos en los límites calculados\ndata_plot[, estado := ifelse(cantidad_vendida &gt; limites$sup | cantidad_vendida &lt; limites$inf, \n                             \"Outlier (Anomalía)\", \"Normal\")]\n\n# 4. Gráfico con Líneas de Control (Estilo Gráfico de Control de Calidad)\nggplot(data_plot, aes(x = fecha, y = cantidad_vendida)) +\n  # Área de \"Normalidad\" en gris muy claro\n  annotate(\"rect\", xmin = min(data_plot$fecha), xmax = max(data_plot$fecha), \n           ymin = limites$inf, ymax = limites$sup, alpha = 0.1, fill = \"blue\") +\n  # Línea de tendencia suave para ver estacionalidad\n  geom_line(color = \"grey\", alpha = 0.4) + \n  # Puntos resaltados\n  geom_point(aes(color = estado, size = estado)) +\n  # Líneas horizontales de los límites\n  geom_hline(yintercept = limites$sup, linetype = \"dashed\", color = \"firebrick\", size = 0.8) +\n  geom_hline(yintercept = limites$med, linetype = \"dotted\", color = \"darkblue\") +\n  # Escalas y Colores\n  scale_color_manual(values = c(\"Normal\" = \"#2c3e50\", \"Outlier (Anomalía)\" = \"#e74c3c\")) +\n  scale_size_manual(values = c(\"Normal\" = 1, \"Outlier (Anomalía)\" = 3)) +\n  theme_minimal() +\n  labs(\n    title = paste(\"Control de Calidad de Señal:\", sku_foco),\n    subtitle = paste(\"Límite Superior Sugerido (MAD):\", round(limites$sup, 2)),\n    x = \"Fecha de Operación\",\n    y = \"Unidades Vendidas\",\n    color = \"Clasificación\",\n    size = \"Clasificación\"\n  ) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\nFigure 1.5: Diagnóstico de Señal: Análisis de Outliers con Límites MAD\n\n\n\n\n\n\n\n¿Qué optimizamos aquí?\n\nFactor de Escala (1.4826): El MAD puro es muy “tacaño”. Al multiplicarlo por 1.4826, el límite se vuelve estadísticamente equivalente a 3 desviaciones estándar si la data fuera normal, pero sigue siendo resistente a los outliers.\nannotate(\"rect\"): Creamos una “zona segura” visual. Todo lo que esté dentro del rectángulo azul claro es demanda estable. Lo que se sale, es ruido.\nLíneas de Control (geom_hline): Ahora el gráfico no solo te dice qué es un outlier, sino por qué. La línea roja discontinua es tu “techo” de demanda normal.\nSelección Dinámica: En lugar de escribir “SKU-0001”, el código busca solo el SKU con más movimiento. Esto es muy útil para testear tu script rápido.\nDiferenciación de Tamaño (scale_size_manual): Los outliers ahora son puntos más grandes. En un gráfico con muchos datos, esto ayuda a que las anomalías “salten” a la vista de inmediato.\n\nAplicando la Winsorización (Limpieza)\nComo vimos en la teoría, no borraremos los puntos rojos. Los vamos a “domar” o “recortar” hasta el límite máximo permitido (el techo estadístico). Esto es lo que llamamos suavizar la señal.\nDefinición del Límite Máximo (Techo)\nEl límite máximo se calcula como vimos : \\(\\text{Techo} = \\text{Mediana} \\pm \\left( K \\cdot MAD \\right)\\). Cualquier valor por encima de este umbral es “recortado” para proteger la integridad del modelo.\n\n# Elegimos un SKU foco del objeto 'ventas'\nsku_foco &lt;- ventas[!is.na(sku_id), sku_id][1]\ndata_plot &lt;- ventas[sku_id == sku_foco & !is.na(fecha)]\n\n# Cálculo de límites (MAD)\nstats_foco &lt;- data_plot[, .(\n  mediana = median(cantidad_vendida, na.rm = TRUE),\n  mad = median(abs(cantidad_vendida - median(cantidad_vendida, na.rm = TRUE)), na.rm = TRUE) * 1.4826\n)]\n\ntecho &lt;- stats_foco$mediana + (3 * stats_foco$mad)\npiso  &lt;- pmax(0, stats_foco$mediana - (3 * stats_foco$mad))\n\n# CREACIÓN DE COLUMNA SINCRONIZADA\ndata_plot[, demanda_limpia := pmin(pmax(cantidad_vendida, piso), techo)]\n\n# Gráfico\nggplot(data_plot, aes(x = fecha)) +\n  geom_line(aes(y = demanda_limpia), color = \"#27ae60\") +\n  geom_hline(yintercept = c(techo, piso), linetype = \"dashed\", color = \"red\") +\n  theme_minimal() +\n  labs(title = paste(\"SKU:\", sku_foco))\n\n\n\n\n\n\n\nFigure 1.6: Winsorización\n\n\n\n\n\n\n\n\n\n\n\nNoteResumiendo\n\n\n\n1. La Winsorización es la ACCIÓN\nLa Winsorización es el acto de recortar un valor extremo y reemplazarlo por un límite (techo o suelo). Independientemente de cómo calcules ese límite, si reemplazas el outlier en lugar de borrarlo, estás haciendo Winsorización.\n2. MAD y el metodo Tradicional son los CRITERIOS\nSon las reglas matemáticas que usas para decidir dónde poner el techo.\n\nMétodo Tradicional: Usa la Media y la Desviación Estándar para poner el techo. Es como usar una regla elástica que se estira si hay valores muy grandes.\nMétodo MAD: Usa la Mediana y la Desviación Absoluta de la Mediana. Es como usar una regla de acero que no se dobla, sin importar qué tan grande sea el outlier.\n\nEntonces lo que hicimos fue aplicar un “filtro de Winsorización basado en el método de MAD”\n\n\n\n\n\n\n\n\nTip¿Visualizar todos los SKU?\n\n\n\nEn la práctica real de un Material Planner o un Data Scientist que maneja millones de registros, la respuesta corta es: No es normal (ni humano) visualizar todos los SKU.\nHacerlo sería como intentar revisar cada grano de arroz de un camión antes de cocinarlo. Aquí te explico cómo se trabaja en la “vida real” de las empresas de alto rendimiento:\n\n1. La Regla del “Management by Exception” (Gestión por Excepción)\nEn empresas con catálogos de 5,000, 10,000 o 50,000 SKUs, nadie mira las gráficas una por una. Lo que se hace es confiar en el proceso automatizado y solo intervenir donde el algoritmo “levanta la mano”.\n\nPaso 1 (Automatización): Se aplica la Winsorización (limpieza) a toda la base de 15 millones de filas de forma masiva (como el código de data.table que optimizamos).\nPaso 2 (Filtro de Excepción): Se crea una tabla de alertas que diga: “Muéstrame solo los SKUs donde el ruido (outliers) represente más del 15% de la venta total”.\nPaso 3 (Visualización Dirigida): Solo visualizas esos 10 o 20 SKUs críticos para entender qué pasó (¿fue una promoción mal cargada?, ¿un error de balanza en el almacén?).\n\n\n\n2. Segmentación ABC / XYZ (Tu brújula)\nComo tienes las columnas abc_class y xyz_class, la práctica real dicta niveles de atención distintos:\n\nSKUs Clase A: Estos sí se visualizan con frecuencia (o al menos sus Top 20). Un error de limpieza aquí cuesta millones.\nSKUs Clase C: Se limpian en automático y “que Dios los bendiga”. El costo de revisarlos es mayor que el beneficio del inventario que ahorras.\n\n\n\n3. Confianza en la “Demanda Limpia”\nEn la práctica, una vez que validas que tu función de Winsorización (MAD) es robusta con una muestra representativa, trabajas directamente con la demanda_limpia.\nLos sistemas de planeación modernos (como los que estás construyendo en R) funcionan bajo la jerarquía:\n\nDatos Crudos: Se guardan para auditoría y KPIs de servicio.\nDatos Limpios: Son los que alimentan el motor de Forecast (Capítulo 2 de tu reporte).\nAjustes Manuales: Solo para eventos conocidos (ej. “El próximo mes habrá una huelga de transporte”).\n\n\n\n4. ¿Por qué es mejor no verlos todos?\nEl cerebro humano busca patrones donde no los hay. Si miras 500 gráficas, empezarás a “corregir” cosas que en realidad son comportamiento normal del mercado. El algoritmo es imparcial.\n\n\nResumen de la “Práctica Real”:\n\nLimpias todo por detrás (código masivo).\nVisualizas una muestra para estar seguro de que tu “Túnel de Normalidad” está bien calibrado.\nCreas un Dashboard de Excepciones (usando ver_tabla_core) para que te avise qué SKUs se ven “raros” después de la limpieza.\nEjecutas tu planeación sobre la columna demanda_limpia.",
    "crumbs": [
      "I: El Diagnóstico",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>1. Auditoría de Datos y Arquitectura de Red</span>"
    ]
  },
  {
    "objectID": "cap-1-auditoria.html#latencia-de-la-información-flujo-físico-vs.-digital",
    "href": "cap-1-auditoria.html#latencia-de-la-información-flujo-físico-vs.-digital",
    "title": "1. Auditoría de Datos y Arquitectura de Red",
    "section": "1.7 Latencia de la Información: Flujo Físico vs. Digital",
    "text": "1.7 Latencia de la Información: Flujo Físico vs. Digital\nEn un mundo ideal, cuando un cliente saca un producto de la góndola o un operario sube un pallet al camión, el sistema debería actualizarse en ese mismo microsegundo. En el mundo real, existe un desfase llamado Latencia.\nLa latencia es la diferencia de tiempo entre el Flujo Físico (lo que ocurre en la bodega) y el Flujo Digital (lo que el analista ve en su pantalla).\n\n1.7.1 El Lead Time de Información (\\(\\Delta_t\\))\nNo solo debemos medir cuánto tarda el proveedor en entregarnos (Lead Time Logístico), sino cuánto tardamos nosotros en “enterarnos” de que algo pasó.\n\\[\n\\Delta t = \\text{Fecha} \\ Registro\\ {Sistema} - \\text{Fecha}\\ Evento\\ {Real}\n\\]\nCausas comunes: Procesos manuales de conteo, turnos nocturnos que no cargan datos hasta la mañana siguiente, o interfaces de sistemas (como la del 3PL al ERP) que solo corren una vez al día.\n\n\n\n\n\n\nNoteSíntesis del Diagnóstico\n\n\n\nAl finalizar este capítulo, hemos establecido una base sólida:\n1. Modelación de la red (Grafos).\n2. Definición de DFU y Jerarquías.\n3. Validación de fuentes (ERP, WMS, TMS).\n4. Selección de herramientas (SQL + R/Python) por sobre Excel.\n5. Tratamiento robusto de outliers (Winsorización).\n6. Reconocimiento de la latencia como variable de diseño.\nCon datos auditados, estamos listos para abordar la discrepancia entre ventas registradas y demanda real.\n\n\nHemos completado el paso más difícil y, a menudo, el más ignorado: mirar debajo del capó.\nAhora que has auditado tus datos, ya no estás navegando a ciegas. Sabes dónde están tus “puntos ciegos” tecnológicos, entiendes que un SKU no es solo un código sino una relación compleja dentro de una red, y has aprendido a limpiar el ruido para quedarte con la señal real.\nSé que puede parecer mucho trabajo administrativo antes de llegar a la “magia” de la Inteligencia Artificial, pero recuerda esto: el mejor algoritmo del mundo no puede salvar un mal dato, pero un dato limpio y bien estructurado puede hacer brillar hasta el modelo más sencillo\n\n\n\n\n\n\nNote\n\n\n\nExiste un consenso silencioso entre los científicos de datos: el 80% de cualquier proyecto de analítica consiste en limpiar, organizar y entender los datos; el otro 20% es quejarse de ese 80%. Aunque todos queremos llegar rápido a la parte de los algoritmos y la Inteligencia Artificial, la realidad es que el éxito no se construye en el modelo, sino en la limpieza obsesiva de la base sobre la que este descansa.\n\n\n\n\n          used  (Mb) gc trigger   (Mb)   max used   (Mb)\nNcells 2208334 118.0   41340066 2207.8   51675082 2759.8\nVcells 4989853  38.1  905123681 6905.6 1131370594 8631.7",
    "crumbs": [
      "I: El Diagnóstico",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>1. Auditoría de Datos y Arquitectura de Red</span>"
    ]
  },
  {
    "objectID": "cap-1-auditoria.html#footnotes",
    "href": "cap-1-auditoria.html#footnotes",
    "title": "1. Auditoría de Datos y Arquitectura de Red",
    "section": "",
    "text": "ERP (siglas en inglés de Enterprise Resource Planning) o Sistema de Planificación de Recursos Empresariales, es un software diseñado para gestionar y automatizar las operaciones diarias de una empresa desde una única plataforma.↩︎\nEl término 3PL significa Third-Party Logistics (Logística de Terceros). Se refiere a la externalización de las funciones de logística y gestión de la cadena de suministro a una empresa especializada.↩︎",
    "crumbs": [
      "I: El Diagnóstico",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>1. Auditoría de Datos y Arquitectura de Red</span>"
    ]
  },
  {
    "objectID": "cap-2-espejo-realidad.html",
    "href": "cap-2-espejo-realidad.html",
    "title": "2. El Espejo de la Realidad: Ventas vs. Demanda",
    "section": "",
    "text": "I. Fundamentos: La Diferencia entre “Vender” y “Necesitar”\nYa pasamos la escoba en el Capítulo 1. Tenemos datos limpios, sin duplicados y con las jerarquías de productos y ubicaciones perfectamente claras. En este punto, es probable que te sientas confiado. Miras tu base de datos, ves una columna que dice “Venta Histórica” o “Consumos de Almacén”, calculas un promedio de 100 unidades mensuales y piensas: “Listo, mi demanda promedio es 100 y mi desviación es 15; ya puedo calcular mi stock de seguridad”.\nTe voy avisando desde ahora: No siempre es tan fácil.\nLo que ves en tu pantalla no es la realidad del mercado ni la necesidad real de tu planta de producción; es un reflejo de tus propias limitaciones operativas. En Supply Chain, es facil confundir lo que el sistema registró como una transacción exitosa (Salida) con lo que el cliente realmente requería (Necesidad).\nMuchas personas cometen el error de pensar que sus reportes de ventas muestran lo que el mercado quiere. En realidad, esos reportes solo muestran lo que pudiste entregar. Para ser un buen planificador, debes aprender a ver más allá de la factura.",
    "crumbs": [
      "I: El Diagnóstico",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>2. El Espejo de la Realidad: Ventas vs. Demanda</span>"
    ]
  },
  {
    "objectID": "cap-2-espejo-realidad.html#i.-fundamentos-la-ecuación-universal",
    "href": "cap-2-espejo-realidad.html#i.-fundamentos-la-ecuación-universal",
    "title": "2. El Espejo de la Realidad: Ventas vs. Demanda",
    "section": "",
    "text": "2.1 La Ecuación de la Mentira: Salidas vs. Necesidad\nLa desigualdad fundamental que rige la vida de un planificador es: \\(Salida_t \\leq Necesidad_t\\). En términos de ingeniería de datos, la Salida es una función restringida por la realidad física de tu almacén:\n\\[\n\\large Salida_t = \\min(Necesidad_t, Disponibilidad_t)\n\\]\nEsta simple fórmula tiene implicaciones profundas. Si el cliente tiene una necesidad de 150 unidades, pero tu disponibilidad es de solo 80, tu sistema grabará “80”. El problema es que para el ERP, ese 80 es una “verdad contable”, pero para el pronosticador es una “mentira estadística”. Al registrar solo lo que pudiste entregar, has borrado el rastro de la demanda real.\n\n\n2.2 El Ciclo de la Mediocridad Automatizada (Sesgo de IA)\nSi utilizas estos datos “censurados” para entrenar un modelo de Inteligencia Artificial, estarás creando un bucle de retroalimentación negativa. El modelo aprenderá que tu capacidad de servicio es la demanda real.\n\nConsecuencia: Si el modelo ve que en Navidad vendiste 500 unidades (estando quebrado), el próximo año predecirá una demanda de 500. Comprarás 500, volverás a quebrar, y el modelo confirmará su “acierto”. Estarás institucionalizando la escasez mediante algoritmos.\n\n\n\n\n\n\n\nNotePlan de Acción: Identificación de la Señal\n\n\n\n\nAuditoría de Tablas: Localiza en tu base de datos la tabla de pedidos originales (Sales Orders o Requirements) y compárala con la de facturación o salidas reales. El gap entre ambas es tu primer indicador de “Demanda No Restringida”.\nCreación del Flag de Censura: En tu dataset maestro, crea una columna booleana llamada es_dato_censurado. Será TRUE si en ese periodo el inventario fue insuficiente para cubrir la demanda promedio.",
    "crumbs": [
      "I: El Diagnóstico",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>2. El Espejo de la Realidad: Ventas vs. Demanda</span>"
    ]
  },
  {
    "objectID": "cap-2-espejo-realidad.html#ii.-diagnóstico-detectando-el-ruido-en-el-espejo",
    "href": "cap-2-espejo-realidad.html#ii.-diagnóstico-detectando-el-ruido-en-el-espejo",
    "title": "2. El Espejo de la Realidad: Ventas vs. Demanda",
    "section": "II. Diagnóstico: Detectando el “Ruido” en el Espejo",
    "text": "II. Diagnóstico: Detectando el “Ruido” en el Espejo\n\n2.3 Los “Días de Stock Out” como Herramienta Forense\nUn día se marca como censurado mediante un análisis forense de datos. No basta con que no haya ventas; debemos validar que no hubo ventas porque no había producto. Si el inventario llega a niveles críticos y las salidas caen drásticamente, estamos ante un quiebre.\n\n\n2.4 La Trampa de la Granularidad: El Mes es el Escondite del Fracaso\nLa detección de demanda real debe ser diaria. Si analizas datos mensuales, podrías ver que vendiste 100 unidades teniendo 100 en stock al cierre de mes, lo que te daría una falsa sensación de cumplimiento del 100%.\nSin embargo, si bajamos a nivel diario, podríamos descubrir que esas 100 unidades se agotaron el día 10 del mes. Durante los 20 días restantes, el stock fue cero. Tu demanda real mensual era probablemente de 300 unidades. La agregación mensual es el mayor enemigo de la visibilidad.",
    "crumbs": [
      "I: El Diagnóstico",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>2. El Espejo de la Realidad: Ventas vs. Demanda</span>"
    ]
  },
  {
    "objectID": "cap-2-espejo-realidad.html#iii.-el-enfoque-industrial-mro-proyectos-y-clientes-internos",
    "href": "cap-2-espejo-realidad.html#iii.-el-enfoque-industrial-mro-proyectos-y-clientes-internos",
    "title": "2. El Espejo de la Realidad: Ventas vs. Demanda",
    "section": "III. El Enfoque Industrial: MRO, Proyectos y Clientes Internos",
    "text": "III. El Enfoque Industrial: MRO, Proyectos y Clientes Internos\nSi trabajas en una industria pesada, tu “cliente” es un Ingeniero de Proyecto o un líder de mantenimiento. Aquí, la demanda no se “predice” tanto como se “gestiona”.\n\n2.5 El Elemento PEP como Segmentador de Demanda\nEn entornos de proyectos, la demanda está vinculada a una estructura de desglose (Elemento PEP). Esto introduce el concepto de Inventario Etiquetado. Puedes tener 10 unidades en el patio, pero si 8 están asignadas contablemente al “Proyecto A”, tu disponibilidad para el “Mantenimiento B” es de solo 2 unidades. Ignorar este bloqueo contable genera quiebres artificiales en tus modelos.\n\n\n2.6 Fecha de Necesidad vs. Fecha de Despacho\nEste es el mayor conflicto en la planificación industrial.\n\nFecha de Necesidad: Cuándo el ingeniero solicitó el material para que la planta no se detenga.\nFecha de Despacho: Cuándo finalmente el almacén pudo entregar el material.\n\nSi el planner analiza la historia basándose en la fecha de despacho, estará modelando el historial de sus propios retrasos. La demanda real siempre viaja en la fecha de necesidad.\n\n\n\n\n\n\nImportantPlan de Acción: Sincronización Operativa\n\n\n\n\nAuditoría de Reservas: Compara sistemáticamente la fecha de solicitud original con la fecha de salida física. El diferencial es tu Lead Time Interno de ineficiencia.\nLimpieza de Hoarding: Identifica reservas cargadas con excesiva antelación por “miedo” al desabasto. Ajusta esas señales para que coincidan con el cronograma real del proyecto.",
    "crumbs": [
      "I: El Diagnóstico",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>2. El Espejo de la Realidad: Ventas vs. Demanda</span>"
    ]
  },
  {
    "objectID": "cap-2-espejo-realidad.html#iv.-ingeniería-de-conceptos-la-caja-de-herramientas-del-planner",
    "href": "cap-2-espejo-realidad.html#iv.-ingeniería-de-conceptos-la-caja-de-herramientas-del-planner",
    "title": "2. El Espejo de la Realidad: Ventas vs. Demanda",
    "section": "IV. Ingeniería de Conceptos: La Caja de Herramientas del Planner",
    "text": "IV. Ingeniería de Conceptos: La Caja de Herramientas del Planner\nPara reconstruir la realidad, trabajamos con la Posición de Inventario (\\(IP\\)).\n\n2.7 Definiciones Críticas: Los Cuatro Pilares\n\nA. Stock Comprometido (Committed)\nInventario físicamente presente pero que ya tiene dueño (reservas de proyectos o pedidos confirmados). No restarlo te llevará a prometer material que ya no te pertenece.\n\n\nB. Backlog (Pendientes por Entregar)\nEs la deuda de tiempo con tus clientes. Pedidos cuya fecha de necesidad ya pasó. El Backlog es “demanda reprimida” que explotará en forma de picos masivos apenas llegue el suministro.\n\n\nC. Stock en Tránsito (In-Transit)\nMaterial que ya salió del proveedor pero no ha ingresado. Es fundamental para el cálculo del punto de reorden y evitar compras duplicadas.\n\n\nD. Fill Rate (Tasa de Surtido)\nMide el porcentaje de la necesidad que pudiste satisfacer inmediatamente. Es el factor matemático que nos permite “de-censurar” la historia:\n\\[\n\\large Demanda_{Estimada} = \\frac{Salida_{Registrada}}{Fill Rate}\n\\]\n\n\n\n2.8 La Fórmula de la Posición de Inventario (\\(IP\\))\n\\[\n\\large \\text{IP} = \\text{Stock Físico} + \\text{En Tránsito} - \\text{Backlog} - \\text{Comprometido}\n\\]",
    "crumbs": [
      "I: El Diagnóstico",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>2. El Espejo de la Realidad: Ventas vs. Demanda</span>"
    ]
  },
  {
    "objectID": "cap-2-espejo-realidad.html#v.-el-ruido-del-éxito-promociones-y-eventos",
    "href": "cap-2-espejo-realidad.html#v.-el-ruido-del-éxito-promociones-y-eventos",
    "title": "2. El Espejo de la Realidad: Ventas vs. Demanda",
    "section": "V. El Ruido del Éxito: Promociones y Eventos",
    "text": "V. El Ruido del Éxito: Promociones y Eventos\nNo todo el ruido en el espejo son valles (quiebres); también hay picos que pueden engañarnos.\n\nUplift (Incremento Promocional): Si vendiste 1,000 unidades en una semana de oferta, tu demanda base quizás sigue siendo 100. Pronosticar 1,000 para una semana normal es una receta para el sobrestock masivo.\nCanibalización: Si el Producto A subió por una promoción, revisa si el Producto B (su sustituto) cayó. Esa caída no es falta de demanda, es desplazamiento.",
    "crumbs": [
      "I: El Diagnóstico",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>2. El Espejo de la Realidad: Ventas vs. Demanda</span>"
    ]
  },
  {
    "objectID": "cap-2-espejo-realidad.html#vi.-reconstrucción-curando-la-serie-de-tiempo",
    "href": "cap-2-espejo-realidad.html#vi.-reconstrucción-curando-la-serie-de-tiempo",
    "title": "2. El Espejo de la Realidad: Ventas vs. Demanda",
    "section": "VI. Reconstrucción: Curando la Serie de Tiempo",
    "text": "VI. Reconstrucción: Curando la Serie de Tiempo\n\n2.9 El Efecto Rebote y la Redistribución de Backlog\nCuando el stock llega tras un quiebre, el Backlog se libera y verás una salida gigante en un solo día.\n\nLa Solución: Debes “aplanar” ese pico. Esas unidades deben ser redistribuidas hacia atrás en la serie de tiempo, asignándolas a las Fechas de Necesidad originales. Solo así la IA entenderá el ritmo real del consumo.\n\n\n\n2.10 Técnicas de Imputación Estadística\nPara los días de quiebre donde la demanda se perdió (Lost Sales), usamos:\n\nMedia Móvil Local: Promedio de los días vecinos sanos.\nSustitución Estacional: ¿Qué pasó el mismo lunes del año pasado?\n\n\n\n\n\n\n\nCautionPlan de Acción: Algoritmos de Curación\n\n\n\n\nScript de Redistribución: Implementa una lógica que detecte picos post-quiebre y los reparta proporcionalmente en el periodo de stockout.\nValidación de Datos Curados: Si tu demanda reconstruida es 3 veces más alta que tu presupuesto comercial, revisa tus cálculos de Fill Rate.",
    "crumbs": [
      "I: El Diagnóstico",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>2. El Espejo de la Realidad: Ventas vs. Demanda</span>"
    ]
  },
  {
    "objectID": "cap-2-espejo-realidad.html#checklist-de-cierre-del-capítulo",
    "href": "cap-2-espejo-realidad.html#checklist-de-cierre-del-capítulo",
    "title": "2. El Espejo de la Realidad: Ventas vs. Demanda",
    "section": "Checklist de Cierre del Capítulo",
    "text": "Checklist de Cierre del Capítulo\nAntes de pasar al siguiente nivel, asegúrate de haber respondido:\n\n¿He identificado los días donde mi inventario limitó mi capacidad de venta/despacho?\n¿He separado el stock asignado a proyectos (PEP) de mi disponibilidad general?\n¿He recalculado mi historia basándome en la Fecha de Necesidad y no en la de Despacho?\n¿He limpiado los picos de promociones y redistribuido el backlog?\n\n\n\n\n\n\n\nTipResumen y Próximos Pasos\n\n\n\nHemos transformado datos contables en Señales de Demanda Real. Ya no tenemos simplemente una lista de facturas; tenemos el registro de lo que el mundo nos pidió.\nAhora la pregunta es: ¿Debo aplicar este nivel de rigor analítico a los 10,000 tornillos de mi inventario? No. En el Capítulo 3, aprenderemos a usar la segmentación ABC/XYZ dinámica para enfocar nuestro esfuerzo donde realmente está el valor.",
    "crumbs": [
      "I: El Diagnóstico",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>2. El Espejo de la Realidad: Ventas vs. Demanda</span>"
    ]
  },
  {
    "objectID": "cap-3-abcxyz-dinamico.html",
    "href": "cap-3-abcxyz-dinamico.html",
    "title": "3. Clasificando el Caos: Segmentación ABC/XYZ Dinámica",
    "section": "",
    "text": "3.1 Fase 1: Entender el Valor (ABC Multi-criterio)\nTras la limpieza y reconstrucción de la demanda realizada en el Capítulo 2, hemos logrado separar la señal del ruido. Sin embargo, poseer datos limpios es solo la mitad de la batalla. El desafío estratégico fundamental que abordaremos ahora es la asignación eficiente de recursos: ¿En qué productos debemos invertir nuestro capital de trabajo, nuestro espacio de almacenamiento y, sobre todo, nuestro tiempo de gestión?\nEn el complejo ecosistema de una cadena de suministro, es un error crítico tratar todos los SKUs bajo una política única. Mientras que algunos artículos representan el núcleo de la rentabilidad y la continuidad operativa, otros son “ruido” que consume recursos administrativos sin aportar valor proporcional. Gestionar un tornillo de bajo costo con el mismo rigor que un motor crítico no es solo ineficiente; es una receta para el agotamiento del planificador y la erosión del margen. Este capítulo presenta un sistema de triaje dinámico diseñado para maximizar el retorno sobre el esfuerzo invertido.\nEl Concepto: El ABC clásico se basa en la Ley de Pareto (80/20), que sugiere que una pequeña minoría de SKUs genera la gran mayoría del valor.",
    "crumbs": [
      "I: El Diagnóstico",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>3. Clasificando el Caos: Segmentación ABC/XYZ Dinámica</span>"
    ]
  },
  {
    "objectID": "cap-3-abcxyz-dinamico.html#fase-1-entender-el-valor-abc-multi-criterio",
    "href": "cap-3-abcxyz-dinamico.html#fase-1-entender-el-valor-abc-multi-criterio",
    "title": "3. Clasificando el Caos: Segmentación ABC/XYZ Dinámica",
    "section": "",
    "text": "3.1.1 Veamos más allá del ABC Tradicional\nLa mayoría de las empresas implementan un ABC basado únicamente en la Facturación Histórica (Precio de Venta x Unidades Vendidas). Si bien esto identifica qué productos traen más dinero, presenta tres fallas críticas para un ingeniero de Supply Chain:\n\nIgnora el Margen: Puedes vender mucho de algo que te deja poca ganancia.\nIgnora el Costo de Oportunidad: No distingue entre un motor de $50,000 y 5,000 tornillos de $10, aunque ambos sumen lo mismo en facturación.\nCeguera Operativa: Un repuesto de $5 que detiene una planta es “Clase C” para el contador, pero es “Clase A” para la operación.\n\nLa Propuesta Profesional: El Enfoque Multidimensional\nPara una gestión de clase mundial, propongo sustituir la facturación simple por un sistema de tres dimensiones que capture la realidad financiera y operativa:\n\n\n3.1.2 Valor de Utilización Anual (VUA)\nEn lugar de ventas, miramos el consumo interno o la demanda proyectada:\nEntonces, hagamos esto: No clasifiques solo por venta o costo. Implementa un sistema de puntaje que cruce estas tres variables fundamentales:\n\nValor de Utilización Anual (VUA): \\((\\text{Costo Unitario} \\times \\text{Demanda Reconstruida})\\).\n\n\n¿De dónde sale? El Costo Unitario viene de tu tabla maestro de materiales (maestro de artículos). La Demanda Reconstruida es la sumatoria anual de la serie de tiempo que saneamos en el Capítulo 2.\n¿Por qué es superior?: Al usar la Demanda Reconstruida del Capítulo 2, eliminamos el sesgo de las ventas perdidas por falta de stock. El VUA nos dice dónde está realmente el riesgo financiero del capital de trabajo.\n\n\n\n3.1.3 Criticidad Técnica (Modelo V.E.D.)\nAquí es donde inyectamos “sentido común de ingeniería” al modelo matemático:\n\nVital (V): Su ausencia provoca un paro total de línea o la pérdida de un cliente estratégico. (Ej: Un sensor de $20 que es pieza única).\nEssential (E): Su ausencia afecta el rendimiento o la calidad, pero permite seguir operando con costos extra.\nDesirable (D): Su ausencia es una molestia administrativa que no afecta la promesa de entrega.\n\n\n\n3.1.4 Intensidad Logística (Picking/Frecuencia)\nMide el “enfisema operativo”. Un artículo con 1,000 movimientos al año de bajo valor consume más horas-hombre y genera más errores que un artículo de alto valor que se mueve una vez al mes.\nComparativa: Tradicional vs. Profesional\n\n\n\n\n\n\n\n\nCaracterística\nEnfoque Tradicional (Miopía)\nEnfoque Profesional (Estratégico)\n\n\n\n\nCriterio Base\nFacturación (Venta x Cantidad)\nVUA (Costo x Demanda Real)\n\n\nFoco\n“Lo que más vendemos”\n“Donde más dinero tenemos atrapado”\n\n\nGestión de Riesgo\nIgnora artículos baratos\nUsa VED para proteger artículos críticos\n\n\nEficiencia Operativa\nTrata igual lo que rota mucho y poco\nMide la intensidad de picking\n\n\nMétrica de Éxito\nDisponibilidad general\nMaximización del ROII\n\n\n\n\n\n3.1.5 La Matriz de Decisión Estratégica (ABC + VED)\nAl cruzar estas dimensiones, obtenemos una hoja de ruta para el planificador:\n\n\n\n\n\n\n\n\n\nCategoría\nPerfil ABC\nPerfil VED\nAcción de Ingeniería\n\n\n\n\nEstratégico\nA o B\nVital\nRevisión Continua. Cero tolerancia al quiebre.\n\n\nFinanciero\nA\nDeseable\nOptimización de Lote. Reducir stock para liberar capital.\n\n\nSeguro Operativo\nC\nVital\nStock de Seguridad Alto. El costo de tenerlo es bajo, el de no tenerlo es fatal.\n\n\nComodities\nC\nDeseable\nAutomatización. Kanban o Punto de Reorden simple.\n\n\n\nEl Resultado: Hemos pasado de una lista de Excel estática a un sistema de triaje dinámico. Ahora el esfuerzo de tu equipo no se desperdicia en artículos irrelevantes y el capital de la empresa está protegido donde más duele.",
    "crumbs": [
      "I: El Diagnóstico",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>3. Clasificando el Caos: Segmentación ABC/XYZ Dinámica</span>"
    ]
  },
  {
    "objectID": "cap-3-abcxyz-dinamico.html#fase-2-medir-la-incertidumbre-matemática-xyz",
    "href": "cap-3-abcxyz-dinamico.html#fase-2-medir-la-incertidumbre-matemática-xyz",
    "title": "3. Clasificando el Caos: Segmentación ABC/XYZ Dinámica",
    "section": "3.2 Fase 2: Medir la Incertidumbre (Matemática XYZ)",
    "text": "3.2 Fase 2: Medir la Incertidumbre (Matemática XYZ)\nEl Concepto: Si el ABC nos dice quién es importante, la segmentación XYZ nos dice qué tan difícil será gestionarlo. Aquí medimos la volatilidad de la señal de demanda. Un producto AX es el escenario ideal (alto valor, alta predictibilidad), mientras que un producto AZ representa el máximo riesgo (alto valor, alta incertidumbre).\nPropuesta de Implementación: Calculamos el Coeficiente de Variación (\\(CV\\)) sobre la serie de tiempo de nuestra Demanda Reconstruida. Esto es vital: no calculamos sobre ventas, sino sobre la intención real de mercado.\n\\[\n\\large CV = \\frac{\\sigma}{\\mu}\n\\]\nDesglose de la fórmula y origen de datos:\n\n\\(\\large\\mu\\) (Media): Es el promedio de la demanda en el horizonte de tiempo analizado.\n\\(\\large\\sigma\\) (Desviación Estándar): Mide cuánto se alejan los datos diarios (o semanales) de ese promedio.\n\nInterpretación para ingeniería:\n\nX (Estables): \\(CV &lt; 0.5\\). La demanda es predecible. Podemos automatizar pedidos y reducir el stock de seguridad al mínimo. Aquí es donde optimizamos el ROII.\nY (Variables): \\(0.5 \\le CV \\le 1.0\\). Existen fluctuaciones (estacionalidad o promociones). Requiere modelos estadísticos más avanzados.\nZ (Inciertos): \\(CV &gt; 1.0\\). La desviación supera al promedio. La predicción es poco fiable.\n\n\n\n\n\n\n\n\nImportantLa Conexión con el Capital\n\n\n\nRecuerda: El Stock de Seguridad (\\(SS\\)) es directamente proporcional a la desviación estándar (\\(\\large\\sigma\\)). Un producto Clase Z requiere, por definición, un colchón de stock mucho más grande. Si un producto es AZ, estás ante un “quemador de capital”. Estos son los SKUs que debemos vigilar con lupa o considerar estrategias de Inventory Pooling (consolidación de stock).",
    "crumbs": [
      "I: El Diagnóstico",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>3. Clasificando el Caos: Segmentación ABC/XYZ Dinámica</span>"
    ]
  },
  {
    "objectID": "cap-3-abcxyz-dinamico.html#fase-3-decodificar-la-personalidad-syntetos-boylan",
    "href": "cap-3-abcxyz-dinamico.html#fase-3-decodificar-la-personalidad-syntetos-boylan",
    "title": "3. Clasificando el Caos: Segmentación ABC/XYZ Dinámica",
    "section": "3.3 Fase 3: Decodificar la Personalidad (Syntetos-Boylan)",
    "text": "3.3 Fase 3: Decodificar la Personalidad (Syntetos-Boylan)\nEl Concepto: Para un ingeniero de datos, el \\(CV\\) es incompleto porque no distingue entre un producto que se vende poco pero constante y uno que vende mucho pero en un solo “golpe” al año. Necesitamos conocer la “textura” del dato para elegir el algoritmo de IA correcto.\nEntonces, hagamos esto: Calculamos dos indicadores técnicos sobre tu serie histórica (se recomienda usar granularidad semanal para este análisis):\n\nADI (Average Demand Interval): Mide la frecuencia o “densidad” de la demanda.\n\\[\n\\large p = \\frac{\\text{Número de Periodos Totales}}{\\text{Número de Periodos con Demanda}}\n\\]\n\n¿De dónde sale? Del conteo de periodos (días/semanas) en tu serie de tiempo. Si analizas 52 semanas y hubo demanda en 10, tu \\(p = 5.2\\).\nSignificado: Si \\(p\\) es alto, el producto es “lento” o intermitente.\n\n\\(CV^2\\) (Variabilidad del Tamaño): Mide la estabilidad de las cantidades cuando sí hay demanda.\n\\[\n\\large CV^2 = \\left( \\frac{\\sigma_{no\\_cero}}{\\mu_{no\\_cero}} \\right)^2\n\\]\n\n¿De dónde sale? Tomas solo los días donde la demanda fue mayor a cero. Calculas su desviación estándar y su promedio, los divides y elevas al cuadrado.\nSignificado: Si es bajo, cuando piden, piden siempre lo mismo. Si es alto, las cantidades son una lotería.\n\n\nY así logramos esto: Clasificamos el SKU en uno de los cuatro perfiles de personalidad de demanda:\n\n\n\n\n\n\n\n\nPerfil\nCaracterísticas Matemáticas\nImplicación de Ingeniería\n\n\n\n\nSmooth\n(\\(p &lt; 1.32, CV^2 &lt; 0.49\\))\nConstante. Usa Distribución Normal. Ideal para JIT.\n\n\nErratic\n(\\(p &lt; 1.32, CV^2 \\ge 0.49\\))\nSiempre presente, pero cantidades locas. Requiere Buffering.\n\n\nIntermittent\n(\\(p \\ge 1.32, CV^2 &lt; 0.49\\))\nGoteo lento pero predecible. Usa Modelos de Croston.\n\n\nLumpy\n(\\(p \\ge 1.32, CV^2 \\ge 0.49\\))\nEl caos: ráfagas inciertas. Requiere Stock de Seguridad no-normal.",
    "crumbs": [
      "I: El Diagnóstico",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>3. Clasificando el Caos: Segmentación ABC/XYZ Dinámica</span>"
    ]
  },
  {
    "objectID": "cap-3-abcxyz-dinamico.html#fase-4-ejecución-dinámica-y-el-fenómeno-del-drift",
    "href": "cap-3-abcxyz-dinamico.html#fase-4-ejecución-dinámica-y-el-fenómeno-del-drift",
    "title": "3. Clasificando el Caos: Segmentación ABC/XYZ Dinámica",
    "section": "3.4 Fase 4: Ejecución Dinámica y el Fenómeno del “Drift”",
    "text": "3.4 Fase 4: Ejecución Dinámica y el Fenómeno del “Drift”\nEl Concepto: El mercado es un organismo vivo. Un producto que hoy es una estrella estable (AX Smooth) puede convertirse en un peso muerto (CZ Lumpy) en seis meses. A esto lo llamamos Drift (Deriva).\nEntonces, hagamos esto: Implementa un recálculo trimestral automatizado. No es una tarea manual; es un script que corre sobre tus datos.\n#| message: false\n#| warning: false\nlibrary(tidyverse)\n\n# Hagamos esto: Simular un portafolio de 500 SKUs para visualizar el riesgo real\nset.seed(123)\ndf_portfolio &lt;- tibble(\n  sku = paste0(\"SKU-\", 1:500),\n  adi = runif(500, 1, 4),    \n  cv2 = runif(500, 0.1, 1.2) \n) %&gt;%\n  mutate(perfil = case_when(\n    adi &lt; 1.32 & cv2 &lt; 0.49 ~ \"Smooth\",\n    adi &gt;= 1.32 & cv2 &lt; 0.49 ~ \"Intermittent\",\n    adi &lt; 1.32 & cv2 &gt;= 0.49 ~ \"Erratic\",\n    TRUE ~ \"Lumpy\"\n  ))\n\n# Visualización para la toma de decisiones estratégicas\nggplot(df_portfolio, aes(x = adi, y = cv2, color = perfil)) +\n  geom_point(alpha = 0.7, size = 3) +\n  geom_vline(xintercept = 1.32, linetype = \"dashed\", color = \"darkred\") +\n  geom_hline(yintercept = 0.49, linetype = \"dashed\", color = \"darkred\") +\n  scale_color_manual(values = c(\"Smooth\"=\"#27ae60\", \"Erratic\"=\"#f1c40f\", \n                                \"Intermittent\"=\"#2980b9\", \"Lumpy\"=\"#c0392b\")) +\n  theme_minimal() +\n  labs(title = \"Mapa de Personalidad de Inventarios (Syntetos-Boylan)\",\n       x = \"Frecuencia de Demanda (ADI)\", y = \"Variabilidad del Tamaño (CV2)\")",
    "crumbs": [
      "I: El Diagnóstico",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>3. Clasificando el Caos: Segmentación ABC/XYZ Dinámica</span>"
    ]
  },
  {
    "objectID": "cap-3-abcxyz-dinamico.html#todos-merecen-stock-de-seguridad-la-estrategia-del-pooling",
    "href": "cap-3-abcxyz-dinamico.html#todos-merecen-stock-de-seguridad-la-estrategia-del-pooling",
    "title": "3. Clasificando el Caos: Segmentación ABC/XYZ Dinámica",
    "section": "3.5 ¿Todos merecen Stock de Seguridad? (La Estrategia del Pooling)",
    "text": "3.5 ¿Todos merecen Stock de Seguridad? (La Estrategia del Pooling)\nLlegamos a la pregunta más dolorosa para un planificador: ¿Debo proteger todos mis SKUs con un inventario de seguridad? La respuesta corta es no. Si intentas ponerle un “colchón” a cada uno de tus 5,000 o 10,000 SKUs, terminarás con un capital inmovilizado que destruirá tu ROII y generará una montaña de obsolescencia.\nAquí es donde el ADN que calculamos en las fases previas se convierte en una guía de despliegue físico:\n\n3.5.1 La Trampa del Stock Descentralizado\nEl error común es replicar el stock de seguridad en cada sucursal o bodega local. Esto ignora que la incertidumbre es aditiva. Si tienes 10 sucursales pidiendo un producto Lumpy (errático), cada una pedirá un “por si acaso”, inflando el inventario total de la red de forma artificial.\n\n\n3.5.2 La Solución: Inventory Pooling (Consolidación)\nPara los productos difíciles de predecir, la estrategia profesional no es tener más stock, sino acercar el stock a la demanda de forma inteligente:\n\nPara artículos AX / Smooth / Vital: Descentralización. Tenlos cerca del cliente o de la línea. Son predecibles, se mueven siempre y el riesgo de tenerlos ahí es bajo. Aquí el stock de seguridad local está justificado.\nPara artículos CZ / Lumpy / Deseable: Pooling Centralizado. No guardes estos artículos en las sucursales. Mantenlos únicamente en tu Centro de Distribución Central.\n\n\n\n\n\n\n\nTipLa Magia Estadística del Pooling\n\n\n\nCuando consolidas la demanda incierta de muchos puntos en uno solo, la variabilidad se compensa. Mientras un cliente en la Sucursal A pide menos de lo esperado, uno en la Sucursal B pide más. Al final, la suma centralizada es mucho más estable que las partes individuales.\nMatemáticamente, esto se rige por la Ley de la Raíz Cuadrada:\n\\[\nSS_{central} \\approx \\frac{\\sum SS_{locales}}{\\sqrt{n}}\n\\] Donde \\(n\\) es el número de ubicaciones consolidadas. Si consolidas 4 bodegas en 1, ¡necesitas aproximadamente la mitad del stock de seguridad original para mantener el mismo nivel de servicio!",
    "crumbs": [
      "I: El Diagnóstico",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>3. Clasificando el Caos: Segmentación ABC/XYZ Dinámica</span>"
    ]
  },
  {
    "objectID": "cap-4-metricas-error.html",
    "href": "cap-4-metricas-error.html",
    "title": "4. ¿Qué tan mal estamos? Estableciendo el Baseline y Métricas de Error",
    "section": "",
    "text": "4.1 El Concepto de Baseline: El Modelo “Naive”\n¡Bienvenido al momento de la verdad! Si llegaste hasta aquí, ya has construido los cimientos: tienes un mapa de tu red (Cap. 1), una demanda reconstruida que refleja la intención real de compra (Cap. 2) y tus productos clasificados por su importancia estratégica y su dificultad técnica (Cap. 3).\nAhora toca enfrentar la realidad. La pregunta que todo director financiero o de operaciones te hará no es si el modelo es “bonito” o si usaste una Red Neuronal, sino: “¿Y qué tanto estamos fallando hoy?”.\nEn Supply Chain, la honestidad brutal es tu mejor aliada. “Estamos más o menos” no es una métrica; es una opinión subjetiva que bloquea la mejora continua. Medir el error es, a menudo, un ejercicio de humildad corporativa que muchas empresas evitan para no evidenciar ineficiencias. Sin embargo, en este capítulo estableceremos el Baseline (tu punto cero de comparación) y aprenderemos a diseccionar el error en sus componentes de magnitud y dirección. Te voy avisando: si no eres capaz de medir el dolor financiero que causa tu error hoy, nunca podrás cuantificar el ahorro que traerán tus modelos avanzados mañana. Este es el “kilómetro cero” de tu transformación digital hacia una cadena inteligente.\nAntes de intentar predecir el futuro con modelos complejos, necesitamos un punto de referencia mínimo que represente el “esfuerzo cero”. En ciencia de datos aplicada, esto se llama el Modelo Base o Naive. Es el “rival a vencer” y la medida de tu propia ineficacia: si tu proceso actual no le gana a un modelo Naive, estás desperdiciando recursos humanos y tecnológicos.\nLa lógica del Pronóstico Ingenuo (Naive Forecast) es la persistencia absoluta: “El mercado se comportará mañana exactamente igual que hoy”.\n\\[\n\\large \\hat{y}_{t+1} = y_t\n\\]\nDesglose de la fórmula y origen de datos:",
    "crumbs": [
      "I: El Diagnóstico",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>4. ¿Qué tan mal estamos? Estableciendo el Baseline y Métricas de Error</span>"
    ]
  },
  {
    "objectID": "cap-4-metricas-error.html#el-concepto-de-baseline-el-modelo-naive",
    "href": "cap-4-metricas-error.html#el-concepto-de-baseline-el-modelo-naive",
    "title": "4. ¿Qué tan mal estamos? Estableciendo el Baseline y Métricas de Error",
    "section": "",
    "text": "\\(\\large \\hat{y}_{t+1}\\) (Pronóstico): Es la cantidad que estimamos que se demandará en el próximo periodo. Representa tu “apuesta” de inventario para el futuro inmediato.\n\\(\\large y_t\\) (Demanda Real): Es el valor de la Demanda Reconstruida (Unconstrained Demand) del Capítulo 2.\nOrigen de los datos: Este valor debe venir de tu tabla de transacciones históricas filtradas. Crucial: Debe ser la demanda después de corregir quiebres de stock. Si usas la venta facturada (que es una venta restringida por tu propia falta de stock), tu baseline será artificialmente bajo y tus métricas de error parecerán mejores de lo que realmente son, ocultando el costo de oportunidad.\n\n\n4.1.1 El S-Naive: Para negocios con memoria estacional\nSi tu negocio vende helados o calefactores, el Naive simple fallará. En ese caso, usamos el Seasonal Naive (S-Naive): “Diciembre de este año será igual a diciembre del año pasado”.\n\\[\n\\large \\hat{y}_{t+1} = y_{t+1-periodo}\n\\]\n\n\n\n\n\n\nTipLa Prueba de Fuego del Analista (FVA)\n\n\n\nEl modelo Naive es tu “competidor silencioso”. En la Parte VI del libro utilizaremos este concepto para calcular el Forecast Value Added (FVA). Si un equipo de 10 personas y un software de 100k USD no logran ser al menos un 10% mejores que un simple Naive, el proceso está “destruyendo valor”. Es preferible automatizar el Naive y dedicar a la gente a otra tarea.",
    "crumbs": [
      "I: El Diagnóstico",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>4. ¿Qué tan mal estamos? Estableciendo el Baseline y Métricas de Error</span>"
    ]
  },
  {
    "objectID": "cap-4-metricas-error.html#anatomía-del-error-magnitud-y-dirección",
    "href": "cap-4-metricas-error.html#anatomía-del-error-magnitud-y-dirección",
    "title": "4. ¿Qué tan mal estamos? Estableciendo el Baseline y Métricas de Error",
    "section": "4.2 Anatomía del Error: Magnitud y Dirección",
    "text": "4.2 Anatomía del Error: Magnitud y Dirección\nUn error de 100 unidades no significa lo mismo en el balance contable si te sobraron que si te faltaron. Para un ingeniero de Supply Chain, el error tiene dos dimensiones críticas que deben analizarse de forma simultánea: la magnitud (¿qué tan lejos estuve?) y la dirección (¿hacia qué lado fallé?).\n\n4.2.1 Magnitud: MAE y RMSE (¿Qué tan fuerte fue el golpe?)\nEstas métricas nos dicen qué tan grande fue la “distancia” entre nuestro plan y la realidad. No les importa el signo; solo miden el impacto del desvío total en unidades físicas.\n\nMAE (Mean Absolute Error): Es el promedio de los errores en valor absoluto. Es la métrica más “operativa” porque se expresa en unidades físicas. Si el MAE es 50, significa que, en promedio, tus pronósticos fallan por 50 unidades de espacio físico o capacidad de transporte. \\[\n\\large MAE = \\frac{1}{n} \\sum_{i=1}^{n} |Actual_i - Forecast_i|\n\\]\nRMSE (Root Mean Square Error): Eleva el error al cuadrado antes de promediar. Esto tiene una implicación logística brutal: penaliza de forma desproporcionada los errores grandes. El RMSE es el “sensor” que detecta esos “bombazos” que quiebran financieramente la operación. \\[\n\\large RMSE = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (Actual_i - Forecast_i)^2}\n\\]\n\nVariables: * \\(\\large Actual_i\\): Demanda real corregida del periodo \\(i\\) (Cap. 2). * \\(\\large Forecast_i\\): Tu apuesta para ese periodo (Naive o plan oficial). * \\(\\large n\\): Número de periodos evaluados (ventana de error).\n\n\n4.2.2 Dirección: El BIAS (Sesgo o la inclinación al error)\nEl sesgo es el cáncer silencioso de la planificación. Nos dice si existe una tendencia psicológica (comercial) o sistémica (parámetros de software) a equivocarnos hacia un lado específico.\n\\[\n\\large BIAS = \\sum_{i=1}^{n} (Forecast_i - Actual_i)\n\\]\n\n\n\n\n\n\nWarningEl Peligro de “Netear” Errores\n\n\n\nNunca presentes un error promedio simple en un reporte de desempeño sin valor absoluto. Si en enero fallaste por +100 (te sobró) y en febrero por -100 (te faltó), el error neto es 0. En el reporte financiero eres un genio, pero en la realidad física: 1) pagaste almacenamiento por lo que sobró y 2) perdiste clientes por lo que faltó. El BIAS sirve para diagnosticar si tu equipo comercial infla las cuotas por optimismo (sesgo positivo) o si producción es demasiado conservadora para no tener merma (sesgo negativo).",
    "crumbs": [
      "I: El Diagnóstico",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>4. ¿Qué tan mal estamos? Estableciendo el Baseline y Métricas de Error</span>"
    ]
  },
  {
    "objectID": "cap-4-metricas-error.html#la-batalla-de-las-métricas-mae-bias-vs.-mape",
    "href": "cap-4-metricas-error.html#la-batalla-de-las-métricas-mae-bias-vs.-mape",
    "title": "4. ¿Qué tan mal estamos? Estableciendo el Baseline y Métricas de Error",
    "section": "4.3 La Batalla de las Métricas: MAE + BIAS vs. MAPE",
    "text": "4.3 La Batalla de las Métricas: MAE + BIAS vs. MAPE\nEn los pasillos de las empresas, el MAPE (Mean Absolute Percentage Error) suele ser el rey indiscutido. ¿La razón? Es fácil de decir: “Nuestro error es del 10%”. Sin embargo, desde una perspectiva de ingeniería master, algunos expertos opinan que el MAPE es una de las métricas más peligrosas y sesgadas que existen.\n\n4.3.1 ¿Por qué los expertos cuestionan el MAPE?\nEl MAPE divide el error entre la demanda real para dar un porcentaje, lo que esconde trampas matemáticas:\n\nSesgo de Subestimación: El MAPE castiga mucho más el hecho de que te sobre stock que el hecho de que te falte. Matemáticamente, es más “barato” fallar hacia abajo. Un modelo que optimiza el MAPE tenderá a dar pronósticos bajos, lo que provoca quiebres de stock sistemáticos.\nEl problema del cero: Si en un mes no hubo ventas (demanda = 0), la fórmula explota por división entre cero.\nIndiferencia Económica: Trata igual un error del 10% en un producto Clase C que un 10% en un Clase A de alto costo.\n\n\n\n4.3.2 El Experimento del Espejismo: ¿Cómo nos miente el MAPE?\nPara entender por qué el MAPE es peligroso para tu inventario, mira esta tabla comparativa. Imagina dos escenarios donde fallamos por las mismas 90 unidades de magnitud absoluta:\n\n\n\n\n\n\n\n\n\n\n\nEscenario\nDemanda Real (\\(\\large y_t\\))\nPronóstico (\\(\\large \\hat{y}_t\\))\nError Absoluto (\\(\\large MAE\\))\nMAPE (%)\nConsecuencia Operativa\n\n\n\n\nA: Optimista\n10\n100\n90\n900%\nTe sobra muchísimo stock.\n\n\nB: Pesimista\n100\n10\n90\n90%\nQuiebre de stock.\n\n\n\nLa trampa: Si le pides a un sistema que “optimice el MAPE”, elegirá siempre el Escenario B, porque un error del 90% “se ve mejor” que uno de 900%. Sin embargo, en el Escenario B dejaste de vender. El MAPE prefiere el desabasto antes que el exceso.\n\n\n4.3.3 Tabla Comparativa de Defensa: MAE vs MAPE\n\n\n\n\n\n\n\n\n\nCaracterística\nMAPE (%)\nMAE + BIAS (Unidades)\nImpacto para el Negocio\n\n\n\n\nInterpretación\nAbstracta y subjetiva\nFísica y tangible\nEl MAE se traduce en camiones y paletas.\n\n\nSesgo Matemático\nTiende a pedir de menos\nNeutral e imparcial\nEl MAE protege el nivel de servicio.\n\n\nManejo de Ceros\nFallo total (Div/0)\nRobusto y funcional\nEl MAE sirve para todo el catálogo.\n\n\nSumabilidad\nNo se puede promediar\nSe suma por categorías\nPuedes ver el error total en unidades.\n\n\nFinanzas\nOculto tras el %\nCuantificable en USD\n$MAE Costo = $ Dinero en riesgo.\n\n\n\n\n\n4.3.4 La Psicología del Interlocutor: ¿Quién quiere ver qué?\n\nGerencia General / CEO: Quieren sensación de escala. A ellos dales el WAPE (Cap. 4.4).\nFinanzas: Quieren saber cuánto dinero hay “en riesgo”. Dales el MAE en USD (\\(\\large MAE \\times Costo\\)).\nOperaciones / Almacén: Quieren saber cuántas manos y camiones necesitan. El MAE en unidades es su lenguaje.\nS&OP / Planeación: Quieren corregir el comportamiento. El BIAS es su brújula.",
    "crumbs": [
      "I: El Diagnóstico",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>4. ¿Qué tan mal estamos? Estableciendo el Baseline y Métricas de Error</span>"
    ]
  },
  {
    "objectID": "cap-4-metricas-error.html#el-wape-weighted-mape-el-puente-estratégico",
    "href": "cap-4-metricas-error.html#el-wape-weighted-mape-el-puente-estratégico",
    "title": "4. ¿Qué tan mal estamos? Estableciendo el Baseline y Métricas de Error",
    "section": "4.4 El WAPE (Weighted MAPE): El Puente Estratégico",
    "text": "4.4 El WAPE (Weighted MAPE): El Puente Estratégico\nPara reportar a gerencia con un porcentaje sin caer en las trampas del MAPE, usamos el WAPE. Pondera el error por el volumen total del portafolio.\n\\[\n\\large WAPE = \\frac{\\sum |Actual_i - Forecast_i|}{\\sum Actual_i}\n\\]\n¿Por qué es superior? Porque le da el peso correcto a lo que realmente mueve la aguja. Un error de 1,000 unidades en un producto Clase A tiene un impacto enorme, mientras que el mismo error en un Clase C se diluye.",
    "crumbs": [
      "I: El Diagnóstico",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>4. ¿Qué tan mal estamos? Estableciendo el Baseline y Métricas de Error</span>"
    ]
  },
  {
    "objectID": "cap-4-metricas-error.html#el-concepto-de-forecastability-pronosticabilidad",
    "href": "cap-4-metricas-error.html#el-concepto-de-forecastability-pronosticabilidad",
    "title": "4. ¿Qué tan mal estamos? Estableciendo el Baseline y Métricas de Error",
    "section": "4.5 El Concepto de “Forecastability” (Pronosticabilidad)",
    "text": "4.5 El Concepto de “Forecastability” (Pronosticabilidad)\nTe voy avisando: no todo error es culpa de un mal modelo. Aquí conectamos con la Matriz ABC-XYZ del Capítulo 3. * Productos Smooth (AX): El error aceptable es bajo (ej. WAPE &lt; 15%). Si es mayor, tu proceso está roto. * Productos Lumpy (CZ): Un WAPE del 60% puede ser un éxito rotundo. Esos productos son inherentemente impredecibles.",
    "crumbs": [
      "I: El Diagnóstico",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>4. ¿Qué tan mal estamos? Estableciendo el Baseline y Métricas de Error</span>"
    ]
  },
  {
    "objectID": "cap-4-metricas-error.html#el-tracking-signal-tu-sistema-de-alertas-automáticas",
    "href": "cap-4-metricas-error.html#el-tracking-signal-tu-sistema-de-alertas-automáticas",
    "title": "4. ¿Qué tan mal estamos? Estableciendo el Baseline y Métricas de Error",
    "section": "4.6 El “Tracking Signal”: Tu sistema de alertas automáticas",
    "text": "4.6 El “Tracking Signal”: Tu sistema de alertas automáticas\nMide cuántos MAEs de error acumulado tenemos para detectar cuándo el BIAS se volvió inaceptable.\n\\[\n\\large Tracking Signal = \\frac{BIAS_{acumulado}}{MAE}\n\\]\nSi supera +/- 4, dispara una alerta roja: el modelo está sesgado y requiere intervención manual.",
    "crumbs": [
      "I: El Diagnóstico",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>4. ¿Qué tan mal estamos? Estableciendo el Baseline y Métricas de Error</span>"
    ]
  },
  {
    "objectID": "cap-4-metricas-error.html#visualización-y-cálculo-en-r",
    "href": "cap-4-metricas-error.html#visualización-y-cálculo-en-r",
    "title": "4. ¿Qué tan mal estamos? Estableciendo el Baseline y Métricas de Error",
    "section": "4.7 Visualización y Cálculo en R",
    "text": "4.7 Visualización y Cálculo en R\nVamos a comparar el desempeño del año pasado contra nuestro modelo Naive.\nlibrary(tidyverse)\n\n# --- SIMULACIÓN DE DATOS MAESTROS ---\nset.seed(456)\nevaluacion &lt;- tibble(\n  mes = 1:12,\n  # Demanda Reconstruida del Cap 2 (Variables: y_t)\n  demanda_real = rnorm(12, 100, 15),\n  # Pronóstico Comercial (y_hat - con sesgo optimista simulado)\n  forecast_comercial = demanda_real + rnorm(12, 12, 25) \n) %&gt;%\n  mutate(\n    # Modelo Naive: El pronóstico hoy es lo que pasó ayer\n    forecast_naive = lag(demanda_real, default = 100)\n  )\n\n# --- CÁLCULO DE MÉTRICAS PASO A PASO ---\nmetricas &lt;- evaluacion %&gt;%\n  summarise(\n    # Magnitud relativa (Ponderada por volumen)\n    WAPE_Comercial = sum(abs(demanda_real - forecast_comercial)) / sum(demanda_real),\n    WAPE_Naive = sum(abs(demanda_real - forecast_naive)) / sum(demanda_real),\n    # Dirección (BIAS acumulado)\n    BIAS_Total = sum(forecast_comercial - demanda_real),\n    # Magnitud absoluta (Unidades reales)\n    MAE_Unidades = mean(abs(demanda_real - forecast_comercial))\n  )\n\nprint(metricas)\n\n\n\n\n\n\nNoteInterpretación de Resultados\n\n\n\nSi el WAPE_Naive es menor que el WAPE_Comercial, significa que tu proceso manual está ensuciando la señal de demanda. Es el momento de dejar de intentar “adivinar” y dejar que los datos hablen.",
    "crumbs": [
      "I: El Diagnóstico",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>4. ¿Qué tan mal estamos? Estableciendo el Baseline y Métricas de Error</span>"
    ]
  },
  {
    "objectID": "cap-4-metricas-error.html#conclusión-del-diagnóstico-el-fin-de-la-parte-i",
    "href": "cap-4-metricas-error.html#conclusión-del-diagnóstico-el-fin-de-la-parte-i",
    "title": "4. ¿Qué tan mal estamos? Estableciendo el Baseline y Métricas de Error",
    "section": "4.8 Conclusión del Diagnóstico: El Fin de la Parte I",
    "text": "4.8 Conclusión del Diagnóstico: El Fin de la Parte I\nHemos terminado la primera gran etapa de este manual. Si has seguido los pasos, ahora tienes una infraestructura de pensamiento robusta:\n\nDatos Auditados: Sabes de dónde vienen (Cap. 1).\nDemanda Real: Limpiaste el historial (Cap. 2).\nSegmentación Estratégica: Clasificaste tu mundo (Cap. 3).\nPunto de Partida: Tienes un número (WAPE/BIAS) que representa tu realidad actual (Cap. 4).\n\nTe voy avisando: hasta ahora solo hemos hablado del pasado. A partir del próximo capítulo, entramos en la Parte II, donde tomaremos el bisturí de la estadística para predecir “qué va a pasar”.\n\n\n\n\n\n\nTipResumen del Capítulo 4\n\n\n\n\nBaseline: El modelo Naive es tu piso mínimo de calidad.\nMAE + BIAS: La combinación necesaria para no engañarse con promedios.\nWAPE: Tu traductor para gerencia ponderando por lo que importa.\nPronosticabilidad: El error es relativo a la variabilidad.",
    "crumbs": [
      "I: El Diagnóstico",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>4. ¿Qué tan mal estamos? Estableciendo el Baseline y Métricas de Error</span>"
    ]
  },
  {
    "objectID": "cap-5-pronostico-ingenuo.html",
    "href": "cap-5-pronostico-ingenuo.html",
    "title": "5. El Pronóstico Ingenuo: Modelos Simples y Benchmarking",
    "section": "",
    "text": "5.1 ¿Qué es un Modelo Simple en Supply Chain?\n¡Bienvenido a la segunda etapa del viaje! Ya pasamos por el quirófano en la Parte I: limpiamos los datos, reconstruimos la demanda, segmentamos el portafolio y medimos el error actual. Ahora que sabemos exactamente qué tan mal (o bien) estamos, es hora de dejar de mirar el espejo retrovisor para empezar a proyectar el futuro con una base sólida y científica.\nEn este capítulo vamos a explorar el mundo de los Modelos de Referencia (Benchmarks). Te voy avisando: en la era actual de la “IA-manía”, existe una tentación casi irresistible de saltar directamente a modelos de Deep Learning para impresionar a la gerencia. Sin embargo, un buen ingeniero siempre empieza con la Navaja de Ockham: la solución más simple suele ser la correcta o, al menos, es la que te servirá de brújula para saber si la compleja realmente justifica su existencia.\nUn modelo simple (también llamado heurístico) es aquel que no requiere optimización de parámetros complejos ni entrenamiento intensivo. Se basa en reglas lógicas directas sobre el historial transaccional de la Demanda Reconstruida (Cap. 2). Su función no es solo “pronosticar”, sino establecer el piso de rendimiento (Baseline) que cualquier modelo avanzado deberá superar obligatoriamente para ser considerado una inversión rentable.",
    "crumbs": [
      "II: Prediciendo el Futuro",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>5. El Pronóstico Ingenuo: Modelos Simples y Benchmarking</span>"
    ]
  },
  {
    "objectID": "cap-5-pronostico-ingenuo.html#qué-es-un-modelo-simple-en-supply-chain",
    "href": "cap-5-pronostico-ingenuo.html#qué-es-un-modelo-simple-en-supply-chain",
    "title": "5. El Pronóstico Ingenuo: Modelos Simples y Benchmarking",
    "section": "",
    "text": "5.1.1 ¿Qué es el Benchmarking y para qué sirve?\nEl Benchmarking es el proceso de comparar el desempeño de tu proceso actual (o de un nuevo algoritmo sofisticado) contra un estándar de referencia básico.\nEn Supply Chain, nos sirve para:\n\nJustificar la Inversión: Si una licencia de software de 50,000 USD predice igual que un promedio móvil de Excel, el software no sirve.\nDetectar Ruido: Si los modelos complejos fallan más que los simples, es señal de que tus datos tienen demasiado ruido o eventos únicos que la IA está tratando de “aprender” erróneamente.\nComunicar Resultados: Es mucho más fácil decir “Somos un 10% mejores que el promedio del año pasado” que hablar de “Gradientes Descendentes”.\n\n\n\n5.1.2 El Concepto de Benchmarking y el Valor Añadido (FVA)\nEn Supply Chain, el Benchmarking es el acto de comparar tu pronóstico contra un estándar mínimo de esfuerzo cero. Aquí introducimos el concepto de Forecast Value Added (FVA), que será tu principal herramienta de auditoría:\n\nFVA Positivo: Si tu modelo avanzado reduce el error respecto al modelo simple, estás creando valor real. Esa mejora se traduce directamente en ahorro de inventario o ventas ganadas.\nFVA Negativo: Si tu modelo complejo rinde menos que una fórmula simple, estás “destruyendo valor”. Estás introduciendo ruido y costos de mantenimiento sin retorno.\n\n\\[\n\\large FVA \\% = \\frac{Error_{Benchmark} - Error_{Modelo}}{Error_{Benchmark}} \\times 100\n\\]\n\n\n\n\n\n\nTipLa Dimensión Política del FVA\n\n\n\nPresentar un FVA negativo es doloroso pero necesario. Indica que el proceso humano de planificación está agregando sesgos o que el modelo está “sobre-entrenado”. Un FVA positivo sólido es la única forma objetiva de justificar la inversión en tecnología ante un Director Financiero.",
    "crumbs": [
      "II: Prediciendo el Futuro",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>5. El Pronóstico Ingenuo: Modelos Simples y Benchmarking</span>"
    ]
  },
  {
    "objectID": "cap-5-pronostico-ingenuo.html#el-menú-de-modelos-simples-anatomía-y-dinámica",
    "href": "cap-5-pronostico-ingenuo.html#el-menú-de-modelos-simples-anatomía-y-dinámica",
    "title": "5. El Pronóstico Ingenuo: Modelos Simples y Benchmarking",
    "section": "5.2 El Menú de Modelos Simples: Anatomía y Dinámica",
    "text": "5.2 El Menú de Modelos Simples: Anatomía y Dinámica\nVamos a desglosar las herramientas fundamentales y qué “foto” de la realidad captura cada una.\n\n5.2.1 El Modelo Naïve 1: El Espejo Inmediato\nEl Concepto: Es el nivel más básico de predicción. Asume que el mundo no cambiará y que mañana será exactamente igual a hoy.\n\\[\n\\large \\hat{y}_{t+1} = y_t\n\\]\n\n\n\n\n\n\nNoteImplicación para el Ingeniero\n\n\n\nEste modelo es el benchmark por excelencia. Si tu equipo de planificación manual no logra vencer al Naïve 1, significa que el juicio humano está “ensuciando” el pronóstico en lugar de mejorarlo.\n\n\n\n\n5.2.2 Seasonal Naïve (S-Naive): El Retrovisor Anual\nEl Concepto: Ideal para productos con estacionalidad clara. Asume que el comportamiento de “este diciembre” será igual al de “diciembre pasado”.\n\\[\n\\large \\hat{y}_{t+1} = y_{t+1-s}\n\\]\nDonde \\(s\\) es el ciclo (ej. 12 meses).\n\n\n5.2.3 Promedio Móvil Simple (SMA)\nEl Concepto: El Naïve es muy reactivo. El SMA suaviza la serie para encontrar la tendencia real eliminando los picos fortuitos.\n\\[\n\\large SMA_n = \\frac{1}{n} \\sum_{i=1}^n y_{t-i+1}\n\\]",
    "crumbs": [
      "II: Prediciendo el Futuro",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>5. El Pronóstico Ingenuo: Modelos Simples y Benchmarking</span>"
    ]
  },
  {
    "objectID": "cap-5-pronostico-ingenuo.html#análisis-de-benchmarking-la-tabla-de-resultados",
    "href": "cap-5-pronostico-ingenuo.html#análisis-de-benchmarking-la-tabla-de-resultados",
    "title": "5. El Pronóstico Ingenuo: Modelos Simples y Benchmarking",
    "section": "5.3 Análisis de Benchmarking: La Tabla de Resultados",
    "text": "5.3 Análisis de Benchmarking: La Tabla de Resultados\nPara que el Benchmarking sea útil, debemos presentar los resultados comparados. Aquí es donde introducimos el Forecast Value Added (FVA).\n\n\n\n\n\n\n\n\n\n\nModelo\nError (MAE)\nError (RMSE)\nFVA (vs Naïve)\n¿Qué nos dice?\n\n\n\n\nNaïve 1 (Baseline)\n15.2\n20.1\n0.0%\nEs nuestro punto de partida.\n\n\nS-Naïve\n12.1\n16.5\n+20.4%\nHay estacionalidad; este modelo aporta valor.\n\n\nPromedio Móvil (k=3)\n14.8\n19.2\n+2.6%\nAporta poco valor frente al Naïve.\n\n\nJuicio Humano (Actual)\n18.5\n24.3\n-21.7%\nEl humano está empeorando el dato. Peligro.",
    "crumbs": [
      "II: Prediciendo el Futuro",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>5. El Pronóstico Ingenuo: Modelos Simples y Benchmarking</span>"
    ]
  },
  {
    "objectID": "cap-5-pronostico-ingenuo.html#implementación-en-r-ejecutando-el-benchmark",
    "href": "cap-5-pronostico-ingenuo.html#implementación-en-r-ejecutando-el-benchmark",
    "title": "5. El Pronóstico Ingenuo: Modelos Simples y Benchmarking",
    "section": "5.6 Implementación en R: Ejecutando el Benchmark",
    "text": "5.6 Implementación en R: Ejecutando el Benchmark\nEn este bloque vamos a generar una demanda real, aplicar los modelos ingenuos y calcular automáticamente quién gana el “combate” de precisión.\n\nlibrary(tidyverse)\nlibrary(zoo)\nlibrary(plotly)\n\n# 1. GENERACIÓN Y PREPARACIÓN DE DATOS (Basado en tu lógica)\nset.seed(123)\nn_meses &lt;- 36\npatron_estacional &lt;- c(20, 25, 30, 45, 60, 85, 95, 80, 50, 35, 25, 20)\n\ndf_modelos &lt;- tibble(\n  mes = 1:n_meses,\n  tendencia = mes * 0.8,\n  estacionalidad = rep(patron_estacional, length.out = n_meses),\n  ruido = rnorm(n_meses, mean = 0, sd = 7),\n  actual = round(pmax(0, 20 + tendencia + estacionalidad + ruido))\n)\n\n# Cálculo de modelos (Asegurando el desfase para que sean pronósticos t+1)\nventana_sma &lt;- 3\ndf_modelos &lt;- df_modelos %&gt;%\n  mutate(\n    naive = lag(actual, 1),\n    snaive = lag(actual, 12),\n    sma = rollmean(actual, k = ventana_sma, fill = NA, align = \"right\") %&gt;% lag(1)\n  )\n\n# 2. CREACIÓN DEL GRÁFICO AVANZADO\np &lt;- plot_ly(df_modelos, x = ~mes) %&gt;%\n  # Demanda Real (La referencia principal)\n  add_lines(y = ~actual, name = \"Demanda Real\", \n            line = list(color = '#1e293b', width = 4),\n            hovertemplate = \"Real: %{y} u.\") %&gt;%\n  \n  # Naive Simple\n  add_lines(y = ~naive, name = \"Naive (t-1)\", \n            line = list(color = '#f97316', width = 2, dash = 'dot'),\n            hovertemplate = \"Naive: %{y} u.\") %&gt;%\n  \n  # S-Naive (Estacional)\n  add_lines(y = ~snaive, name = \"S-Naive (t-12)\", \n            line = list(color = '#8b5cf6', width = 2),\n            visible = \"legendonly\", # Desactivado por defecto para no saturar\n            hovertemplate = \"S-Naive: %{y} u.\") %&gt;%\n  \n  # SMA\n  add_lines(y = ~sma, name = paste0(\"SMA (n=\", ventana_sma, \")\"), \n            line = list(color = '#3b82f6', width = 2, dash = 'dash'),\n            hovertemplate = \"SMA: %{y} u.\") %&gt;%\n  \n  # CONFIGURACIÓN DEL LAYOUT\n  layout(\n    title = list(\n      text = \"&lt;b&gt;Benchmarking de Pronósticos: Análisis de FVA&lt;/b&gt;&lt;br&gt;&lt;span style='font-size:12px; color:#64748b'&gt;Reactividad vs Estabilidad de Modelos Simples&lt;/span&gt;\",\n      x = 0\n    ),\n    xaxis = list(\n      title = \"Meses de Operación\",\n      gridcolor = '#f1f5f9',\n      # Añadir botones de selección de rango\n      rangeselector = list(\n        buttons = list(\n          list(count = 6, label = \"6m\", step = \"month\", stepmode = \"backward\"),\n          list(count = 12, label = \"12m\", step = \"month\", stepmode = \"backward\"),\n          list(step = \"all\", label = \"Todo\")\n        ),\n        bgcolor = '#f8fafc'\n      ),\n      rangeslider = list(visible = TRUE, thickness = 0.05)\n    ),\n    yaxis = list(\n      title = \"Demanda (Unidades)\",\n      gridcolor = '#f1f5f9',\n      zeroline = FALSE\n    ),\n    # Tooltip unificado para comparar errores en el mismo punto x\n    hovermode = \"x unified\",\n    template = \"plotly_white\",\n    legend = list(orientation = 'h', y = -0.3),\n    margin = list(t = 100),\n    \n    # ANOTACIONES PARA EXPLICAR FENÓMENOS (Ejemplo en Mes 25)\n    annotations = list(\n      list(\n        x = 25, y = df_modelos$actual[25],\n        text = \"Efecto Lag en SMA\",\n        showarrow = TRUE, arrowhead = 2,\n        ax = -40, ay = -40,\n        font = list(color = '#3b82f6', size = 11)\n      ),\n      list(\n        x = 13, y = df_modelos$snaive[13],\n        text = \"Efecto Eco (S-Naive)\",\n        showarrow = TRUE, arrowhead = 2,\n        ax = 40, ay = 40,\n        font = list(color = '#8b5cf6', size = 11)\n      )\n    )\n  ) %&gt;%\n  # Añadir configuración de responsividad\n  config(displayModeBar = TRUE, responsive = TRUE)\n\np\n\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(zoo)\nlibrary(DT)\n\n# 1. GENERACIÓN DE DATOS (Consistencia con el modelo de suministro)\nset.seed(123)\nn_meses &lt;- 36\npatron_estacional &lt;- c(20, 25, 30, 45, 60, 85, 95, 80, 50, 35, 25, 20)\n\ndf_base &lt;- tibble(\n  mes = 1:n_meses,\n  tendencia = mes * 0.8,\n  estacionalidad = rep(patron_estacional, length.out = n_meses),\n  ruido = rnorm(n_meses, mean = 0, sd = 7),\n  actual = round(pmax(0, 20 + tendencia + estacionalidad + ruido))\n)\n\n# 2. CÁLCULO DE MODELOS Y MÉTRICAS DE ERROR\nventana_sma &lt;- 3\ndf_audit &lt;- df_base %&gt;%\n  mutate(\n    naive = lag(actual, 1),\n    sma = rollmean(actual, k = ventana_sma, fill = NA, align = \"right\") %&gt;% lag(1)\n  ) %&gt;%\n  mutate(\n    APE_Naive = abs(actual - naive) / actual,\n    APE_SMA = abs(actual - sma) / actual,\n    FVA_Puntos = (APE_Naive - APE_SMA) * 100 # En puntos porcentuales\n  ) %&gt;%\n  filter(!is.na(sma))\n\n# 3. RENDERIZADO DE LA TABLA CON \"MÁS ONDA\"\ndatatable(\n  df_audit %&gt;% select(mes, actual, naive, sma, APE_Naive, APE_SMA, FVA_Puntos),\n  colnames = c('Mes', 'Demanda Real', 'Naive (t-1)', 'SMA (n=3)', 'Error Naive', 'Error SMA', 'FVA (pts)'),\n  class = 'hover cell-border stripe',\n  options = list(\n    pageLength = 12,\n    dom = 'tip', # Solo tabla, info y paginación (sin botones ni buscador para limpieza)\n    columnDefs = list(list(className = 'dt-center', targets = \"_all\"))\n  ),\n  caption = htmltools::tags$caption(\n    style = 'caption-side: top; text-align: left; color: #1e293b; font-weight: bold; font-size: 1.2em; padding: 10px;',\n    'Análisis de Benchmarking: ¿La complejidad justifica la inversión?'\n  )\n) %&gt;%\n  # Ajuste de decimales: Unidades sin decimales\n  formatRound(c('actual', 'naive', 'sma'), 0) %&gt;%\n  # Ajuste de decimales: Porcentajes con 1 decimal\n  formatPercentage(c('APE_Naive', 'APE_SMA'), 1) %&gt;%\n  formatRound('FVA_Puntos', 1) %&gt;%\n  # \"La Onda\": Barras de color para el error (mientras más larga, más error)\n  formatStyle(\n    'APE_SMA',\n    background = styleColorBar(df_audit$APE_SMA, '#dbeafe'),\n    backgroundSize = '95% 70%',\n    backgroundRepeat = 'no-repeat',\n    backgroundPosition = 'center'\n  ) %&gt;%\n  # Semáforo de FVA: Verde si el SMA añade valor, Rojo si el Naive es mejor\n  formatStyle(\n    'FVA_Puntos',\n    color = styleInterval(0, c('#e11d48', '#16a34a')), # Rojo vs Verde esmeralda\n    fontWeight = 'bold',\n    backgroundColor = styleInterval(0, c('#fff1f2', '#f0fdf4'))\n  ) %&gt;%\n  # Estilo para la Demanda Real\n  formatStyle(\n    'actual',\n    fontWeight = 'bold',\n    color = '#0f172a',\n    backgroundColor = '#f8fafc'\n  )\n\n\n\n\n\nInterpretación de la Tabla de Auditoría\nLa tabla anterior no es solo un resumen de errores; es el tablero de control del ROI de tu proceso de planeación. Al analizarla mes a mes, podemos extraer tres conclusiones críticas para la ingeniería de suministro:\n\nEl Valor del FVA (Verde vs. Rojo): Cada celda verde en la columna FVA (pts) representa un acierto de la complejidad: el modelo SMA logró filtrar el ruido mejor que el Naive. Por el contrario, las celdas rojas indican “destrucción de valor”: pagaste el costo de un modelo más complejo para terminar con un error mayor al que habrías tenido simplemente repitiendo el dato del mes anterior.\nLa Patología del Lag: Observa los meses de tendencia alcista. Notarás que el Error SMA suele ser mayor y el FVA tiende a rojo. Esto confirma visualmente que los promedios móviles castigan la reactividad en favor de la estabilidad.\nEl Veredicto de Ockham: Si al final del ejercicio el FVA acumulado no supera el 5%, la recomendación técnica es desmantelar el SMA. Mantener un modelo que no bate al Naive de forma consistente solo añade “grasa” operativa y confusión a la cadena.\n\n\n\n\n\n\n\nNoteCómo leer esta auditoría de benchmarking\n\n\n\nPara interpretar correctamente los resultados de la Tabla 5.1, utiliza la siguiente guía rápida:\n\nColumna Demanda Real: Es tu “norte”. Toda comparación nace de aquí.\nColumna Naive (t-1): Es tu “piso” científico. Representa el esfuerzo cero.\nBarras de Error SMA: Cuanto más larga es la barra azul, más “perdido” está el modelo respecto a la realidad. Si ves barras largas constantes, tu ventana $n$ es demasiado grande.\nSemáforo de FVA: * [+ Verdes]: La complejidad está pagando dividendos. Estás en un mercado con patrones claros que el SMA logra capturar.\n\n[- Rojos]: Estás sobre-procesando ruido. Tu demanda es una “caminata aleatoria” y el Naive es tu mejor aliado.",
    "crumbs": [
      "II: Prediciendo el Futuro",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>5. El Pronóstico Ingenuo: Modelos Simples y Benchmarking</span>"
    ]
  },
  {
    "objectID": "cap-5-pronostico-ingenuo.html#la-navaja-de-ockham-y-el-roi-de-la-complejidad",
    "href": "cap-5-pronostico-ingenuo.html#la-navaja-de-ockham-y-el-roi-de-la-complejidad",
    "title": "5. El Pronóstico Ingenuo: Modelos Simples y Benchmarking",
    "section": "5.7 La Navaja de Ockham y el ROI de la Complejidad",
    "text": "5.7 La Navaja de Ockham y el ROI de la Complejidad\nTe voy avisando: vas a sentir la presión de usar redes neuronales para todo. Pero recuerda la Pirámide de Pronóstico:\n\nBase: Modelos Simples (Costo $0, Explicabilidad 100%).\nMedio: Suavizamiento Exponencial / ARIMA (Costo $, Explicabilidad 70%).\nPunta: Machine Learning / IA (Costo $$$, Explicabilidad 20%).\n\nRegla de Oro: Solo sube un peldaño si el FVA es mayor al 5%. Si un modelo complejo solo mejora el error en un 0.2%, la Navaja de Ockham dicta que el modelo simple es la decisión de negocio correcta.\n\n\n\n\n\n\nTipResumen del Paso 5\n\n\n\nHemos construido los cimientos de nuestra catedral de datos:\n\nEstablecimos el Naïve como el rival a vencer para justificar cualquier esfuerzo extra.\nAprendimos a filtrar el ruido con promedios móviles para productos estables.\nEntendimos que en Supply Chain, explicar el número es tan importante como el número en sí.\n\nPero los promedios tienen un problema: tratan al pasado con la misma importancia que al presente. Para solucionar esto, en el Capítulo 6 entraremos en el mundo del Suavizamiento Exponencial (Holt-Winters).",
    "crumbs": [
      "II: Prediciendo el Futuro",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>5. El Pronóstico Ingenuo: Modelos Simples y Benchmarking</span>"
    ]
  },
  {
    "objectID": "cap-6-suavizamiento-exponencial.html",
    "href": "cap-6-suavizamiento-exponencial.html",
    "title": "6. Suavizando la Curva - La Inteligencia Estadística",
    "section": "",
    "text": "6.1 Los Pilares: Descomponiendo la Anatomía de la Demanda\nEn el capítulo anterior, establecimos el “suelo” de nuestra pirámide de pronóstico con los modelos ingenuos (Naive). Aprendimos que, aunque simples, son jueces implacables de la complejidad. Sin embargo, un ingeniero de Supply Chain inteligente sabe que el futuro no es solo una fotografía estática del último dato disponible, sino una evolución dinámica de patrones subyacentes que el ruido intenta ocultar.\nEn este capítulo, daremos el salto de la heurística simple a la Inteligencia Estadística mediante la familia de modelos de Suavizamiento Exponencial. Estos modelos nos permiten transitar de una visión puramente reactiva a una visión adaptativa. Aprenderemos cómo dotar a nuestros sistemas de una “memoria selectiva”: la capacidad técnica de dar más peso a los eventos recientes (que contienen la señal de cambio del mercado) sin sucumbir ante el ruido aleatorio que suele contaminar el historial transaccional de ventas.\nAntes de escribir una sola línea de código o una fórmula en una celda, debemos entender que la demanda no es un bloque monolítico de números. Es, en realidad, una “receta” química compuesta por ingredientes que podemos aislar, medir y, lo más importante, proyectar de forma independiente. En el mundo de la analítica, a este proceso lo llamamos Descomposición de Series de Tiempo.",
    "crumbs": [
      "II: Prediciendo el Futuro",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>6. Suavizando la Curva - La Inteligencia Estadística</span>"
    ]
  },
  {
    "objectID": "cap-6-suavizamiento-exponencial.html#los-pilares-descomponiendo-la-anatomía-de-la-demanda",
    "href": "cap-6-suavizamiento-exponencial.html#los-pilares-descomponiendo-la-anatomía-de-la-demanda",
    "title": "6. Suavizando la Curva - La Inteligencia Estadística",
    "section": "",
    "text": "6.1.1 El Nivel (Level - \\(\\ell\\))\nEl nivel representa el “volumen base” o el equilibrio local de la serie en un momento dado. Si pudiéramos congelar el tiempo y eliminar instantáneamente todas las fluctuaciones temporales y el ruido, el nivel sería el valor resultante.\n\nAnalogía: Si la demanda fuera un viaje en auto por una carretera de montaña, el nivel es la altitud actual sobre el nivel del mar. No te dice a qué velocidad vas ni hacia dónde giras, sino dónde estás parado exactamente ahora mismo.\nImplicación Logística: Un error en el cálculo del nivel se traduce directamente en un error de Sesgo (Bias). Si tu algoritmo calcula un nivel inferior al real, toda tu cadena de suministro —desde la compra de materia prima hasta la logística de última milla— sufrirá de faltantes crónicos (Stockouts), independientemente de que aciertes o no con la estacionalidad. Corregir el nivel es la prioridad número uno para estabilizar el Fill Rate.\n\n\n\n6.1.2 La Tendencia (Trend - \\(b\\))\nLa tendencia es la dirección y la velocidad del cambio en el nivel a lo largo del tiempo. Es el componente que nos indica si el mercado está adoptando nuestro producto con entusiasmo o si estamos entrando en una fase de obsolescencia.\n\nMecánica de Ingeniería: La tendencia puede ser lineal, exponencial o incluso amortiguada. Es el “acelerador” del modelo que proyecta el crecimiento futuro basándose en la inclinación histórica.\nPeligro de Gestión: La tendencia es el componente más peligroso de proyectar a largo plazo. Una tendencia positiva mal identificada genera el temido Efecto Látigo (Bullwhip Effect): el sistema interpreta un crecimiento temporal como una pendiente infinita y ordena compras masivas de inventario para un futuro que quizás ya se estabilizó, dejando el flujo de caja atrapado en estanterías llenas de obsoletos.\n\n\n\n6.1.3 La Estacionalidad (Seasonality - \\(s\\))\nSon las fluctuaciones que se repiten en intervalos fijos y conocidos. Pueden ser causadas por factores climáticos, calendarios festivos o ciclos comerciales recurrentes que obligan al mercado a comportarse de manera pendular.\n\nAnalogía: Es el ritmo de la respiración o el latido del corazón del negocio. Es predecible, cíclico y, si se ignora, causa picos de estrés operativo insostenibles.\nDecisión Crítica: ¿Aditiva o Multiplicativa?\n\nAditiva: El pico estacional es siempre de la misma magnitud absoluta (ej. siempre vendemos 500 unidades más en Navidad, sin importar si el nivel base es 1,000 o 10,000).\nMultiplicativa: El pico crece proporcionalmente al volumen del negocio (ej. siempre vendemos un 30% más en Navidad). En la práctica industrial moderna, casi siempre preferimos la multiplicativa, ya que los picos estacionales suelen escalar a medida que el negocio se expande.\n\n\n\n\n6.1.4 El Ruido (Error Aleatorio - \\(\\epsilon\\))\nEs el “quinto elemento”, la entropía pura. Representa todo aquello que no podemos explicar ni con promedios, ni con pendientes, ni con ciclos. Es la compra impulsiva de un cliente o el cierre de una tienda por una tormenta inusual.\n\nRegla de Oro del Ingeniero: Un modelo inteligente captura la señal (nivel, tendencia, estacionalidad) pero tiene la disciplina matemática de ignorar el ruido. Si tu modelo intenta “explicar” el ruido (ajustándose demasiado a cada punto histórico), caerás en el pecado del Overfitting, y tu precisión en el mundo real se desplomará al enfrentarse a datos nuevos.",
    "crumbs": [
      "II: Prediciendo el Futuro",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>6. Suavizando la Curva - La Inteligencia Estadística</span>"
    ]
  },
  {
    "objectID": "cap-6-suavizamiento-exponencial.html#el-arsenal-de-modelos-suavizamiento-exponencial-ets",
    "href": "cap-6-suavizamiento-exponencial.html#el-arsenal-de-modelos-suavizamiento-exponencial-ets",
    "title": "6. Suavizando la Curva - La Inteligencia Estadística",
    "section": "6.2 El Arsenal de Modelos: Suavizamiento Exponencial (ETS)",
    "text": "6.2 El Arsenal de Modelos: Suavizamiento Exponencial (ETS)\nEl suavizamiento exponencial funciona bajo una premisa elegante: el valor del futuro es una media ponderada entre lo que acaba de pasar (Realidad reciente) y lo que esperábamos que pasara (Pronóstico anterior). Los pesos asignados a los datos pasados decaen de forma exponencial a medida que el dato envejece.\n\n6.2.1 SES: Simple Exponential Smoothing (Solo Nivel)\nEs el modelo ideal para el segmento “X” de tu clasificación XYZ (productos estables). Su única función es filtrar el ruido para encontrar el nivel real subyacente.\n\\[ \\hat{y}_{t+1} = \u0007lpha y_t + (1 - \u0007lpha) \\hat{y}_t \\]\n\n\\(\u0007lpha\\) (Alpha): Es el coeficiente de aprendizaje o “velocidad de memoria”.\n\nUn \\(\u0007lpha\\) alto (0.8 - 0.9) crea un modelo “nervioso” que reacciona rápido a los cambios pero es extremadamente vulnerable al ruido aleatorio, transmitiendo inestabilidad a la producción.\nUn \\(\u0007lpha\\) bajo (0.05 - 0.1) crea un modelo “estable” que ignora los picos espurios, pero que tardará meses en reconocer que el mercado realmente cambió su nivel de consumo permanente.\n\n\n\n\n6.2.2 El Método de Holt (Nivel + Tendencia)\nCuando tus datos muestran una pendiente clara, el SES falla sistemáticamente porque siempre se queda “atrás” (lag). Holt introduce un segundo parámetro, \\(\beta\\) (Beta), para suavizar la tendencia.\n\nActualización del Nivel: \\(\\ell_t = \u0007lpha y_t + (1 - \u0007lpha)(\\ell_{t-1} + b_{t-1})\\)\nActualización de la Tendencia: \\(b_t = \beta(\\ell_t - \\ell_{t-1}) + (1 - \beta)b_{t-1}\\)\nPronóstico: \\(\\hat{y}_{t+h} = \\ell_t + h b_t\\)\n\nEste modelo es vital para gestionar lanzamientos de productos donde el crecimiento inicial es la señal dominante que debe capturarse para evitar quiebres de stock tempranos.\n\nLa Tendencia Amortiguada (Damped Trend): El Salvador del Inventario\nAquí es donde se separan los académicos de los ingenieros de Supply Chain de clase mundial. En la vida real, ninguna tendencia es infinita. Si un SKU crece al 20% mensual, eventualmente se saturará. La Tendencia Amortiguada introduce un parámetro \\(\\phi\\) (Phi) que “frena” la tendencia a medida que miramos más lejos en el futuro.\n\\[ \\hat{y}_{t+h} = \\ell_t + (\\phi + \\phi^2 + \\dots + \\phi^h)b_t \\]\nEste ajuste es crítico para el cálculo del Stock de Seguridad (Cap. 13), ya que evita compras excesivas basadas en optimismos estadísticos que no tienen sustento en la capacidad finita del mercado.\n\n\n\n6.2.3 Holt-Winters (El Triple Suavizamiento)\nEs el estándar de la industria para productos estacionales. Añade el parámetro \\(\\gamma\\) (Gamma) para gestionar los ciclos. Es capaz de “entender” que un lunes de quincena es diferente a un lunes cualquiera, basándose en la repetición de los ciclos pasados para ajustar el inventario justo antes del pico de demanda.",
    "crumbs": [
      "II: Prediciendo el Futuro",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>6. Suavizando la Curva - La Inteligencia Estadística</span>"
    ]
  },
  {
    "objectID": "cap-6-suavizamiento-exponencial.html#implementación-estratégica-excel-python-o-r",
    "href": "cap-6-suavizamiento-exponencial.html#implementación-estratégica-excel-python-o-r",
    "title": "6. Suavizando la Curva - La Inteligencia Estadística",
    "section": "6.3 Implementación Estratégica: ¿Excel, Python o R?",
    "text": "6.3 Implementación Estratégica: ¿Excel, Python o R?\nLa pregunta que debes hacerte no es qué herramienta es más “avanzada”, sino cuál es la más adecuada para el volumen, la velocidad y la criticidad de tu operación actual.\n\n6.3.1 Excel: El Laboratorio de Conceptos\nExcel es insuperable para la fase de diseño y aprendizaje. Te permite construir las fórmulas de nivel y tendencia celda por celda, visualizando físicamente cómo un cambio en \\(\u0007lpha\\) afecta la curva de pronóstico. Utilizar el Solver para minimizar el RMSE (Error Cuadrático Medio) o el MAE (Error Absoluto Medio) es la mejor forma de entender qué significa realmente “optimizar un modelo”.\n\nLimitación Crítica: Excel no es una herramienta de producción masiva. Si tienes 10,000 SKUs, intentar optimizar parámetros en hojas de cálculo es una sentencia de muerte operativa y una fuente inagotable de errores de referencia que costarán millones en capital de trabajo inmovilizado.\n\n\n\n6.3.2 R: La Excelencia Estadística y el Framework “fable”\nR, a través del ecosistema fable y tsibble, trata a los modelos ETS como ciudadanos de primera clase. La ventaja competitiva de R es su capacidad de realizar Model Selection automática de forma masiva. El sistema prueba todas las combinaciones posibles y elige la que minimiza el error estadístico para cada SKU individual de forma transparente.\nlibrary(fable)\n# El algoritmo selecciona automáticamente la mejor estructura ETS para cada SKU\nfit &lt;- datos_ts %&gt;%\n  model(modelo_optimizado = ETS(demanda)) \n\n# Extraemos los componentes para auditar qué está viendo el modelo\ncomponents(fit) %&gt;% autoplot()\n\n\n6.3.3 Python: Escalabilidad, Integración y “StatsForecast”\nPython es la elección obligatoria si tu pronóstico debe alimentar directamente a un ERP o a un motor automático de reaprovisionamiento en la nube. Librerías modernas como StatsForecast han democratizado la velocidad, permitiendo procesar millones de series de tiempo con optimización de parámetros en cuestión de minutos.",
    "crumbs": [
      "II: Prediciendo el Futuro",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>6. Suavizando la Curva - La Inteligencia Estadística</span>"
    ]
  },
  {
    "objectID": "cap-6-suavizamiento-exponencial.html#el-veredicto-del-ingeniero-fva-y-métricas-robustas",
    "href": "cap-6-suavizamiento-exponencial.html#el-veredicto-del-ingeniero-fva-y-métricas-robustas",
    "title": "6. Suavizando la Curva - La Inteligencia Estadística",
    "section": "6.4 El Veredicto del Ingeniero: FVA y Métricas Robustas",
    "text": "6.4 El Veredicto del Ingeniero: FVA y Métricas Robustas\nLlegamos al punto donde la ciencia se convierte en gestión de activos. Tener un modelo de Holt-Winters optimizado no significa nada si no aporta valor real sobre el suelo que construimos en el Capítulo 5 con el modelo Naive.\n\nBenchmarking Obligatorio: Compara el WAPE (Weighted Absolute Percentage Error) y el RMSE de tu modelo sofisticado contra los mismos indicadores del modelo Naive. Olvida el MAPE; necesitamos métricas que ponderen el volumen y penalicen los errores grandes que causan estragos en el flujo de caja.\nCálculo del FVA (Forecast Value Added): El FVA es la ganancia en precisión que obtienes al subir peldaños en la pirámide de complejidad.\n\nSi el Naive tiene un WAPE del 30% y el Holt-Winters tiene un 22%, tu FVA es de +8%. El modelo se paga solo gracias a la reducción de inventario y la mejora del nivel de servicio.\nSi el FVA es menor al 2%, estás gastando recursos computacionales en una complejidad que el negocio no siente.\n\n\n\n\n\n\n\n\nImportantLa Navaja de Ockham Operativa\n\n\n\nEn Supply Chain, la complejidad es un costo oculto. Un modelo Holt-Winters requiere que alguien vigile la estabilidad de los parámetros y que la calidad del dato de entrada sea impecable. Si el incremento en precisión (FVA) no justifica este costo operativo y el riesgo de error humano, la decisión de ingeniería más valiente y brillante es regresar al modelo Naive. La simplicidad es el máximo grado de sofisticación en la gestión de la demanda.",
    "crumbs": [
      "II: Prediciendo el Futuro",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>6. Suavizando la Curva - La Inteligencia Estadística</span>"
    ]
  },
  {
    "objectID": "cap-6-suavizamiento-exponencial.html#checklist-de-cierre-del-capítulo",
    "href": "cap-6-suavizamiento-exponencial.html#checklist-de-cierre-del-capítulo",
    "title": "6. Suavizando la Curva - La Inteligencia Estadística",
    "section": "Checklist de Cierre del Capítulo",
    "text": "Checklist de Cierre del Capítulo\n\n¿He identificado qué SKUs tienen tendencia y cuáles son puramente estables?\n¿Entiendo por qué el \\(\u0007lpha\\) alto puede ser el origen de mi Efecto Látigo?\n¿He configurado el modelo como Multiplicativo para mis productos en crecimiento?\n¿He comparado el WAPE y RMSE del suavizamiento exponencial contra mi Baseline Naive?\n¿He activado la amortiguación (\\(\\phi\\)) en mis pronósticos de largo plazo para proteger mi capital de trabajo?",
    "crumbs": [
      "II: Prediciendo el Futuro",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>6. Suavizando la Curva - La Inteligencia Estadística</span>"
    ]
  },
  {
    "objectID": "cap-7-arima-y-alternativas.html",
    "href": "cap-7-arima-y-alternativas.html",
    "title": "7. Introducción: El Salto de la Suavización a la Correlación",
    "section": "",
    "text": "El Concepto Sagrado: Estacionariedad y el Suelo Firme\nEn el Capítulo 6, construimos una “memoria selectiva” con los modelos ETS. Aprendimos a filtrar el ruido para encontrar la señal de nivel y tendencia. Sin embargo, un ingeniero de Supply Chain de clase mundial sabe que a veces la demanda no solo “recuerda” el pasado, sino que está atada a él por leyes de correlación interna que el suavizamiento tradicional no alcanza a capturar.\nMientras que ETS mira la serie de tiempo como una suma de componentes (nivel + tendencia + estacionalidad), el enfoque de este capítulo es diseccionar la arquitectura de la correlación. Vamos a aprender a usar modelos ARIMA (Auto-Regressive Integrated Moving Average) y sus alternativas modernas para entender si el dato de ayer tiene la fuerza cinética suficiente para empujar el dato de hoy.\nAntes de encender cualquier motor ARIMA, debemos hablar de la Estacionariedad. En términos de ingeniería de datos, una serie es estacionaria cuando sus propiedades estadísticas (media, varianza y estructura de autocorrelación) no cambian con el paso del tiempo.",
    "crumbs": [
      "II: Prediciendo el Futuro",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>7. Introducción: El Salto de la Suavización a la Correlación</span>"
    ]
  },
  {
    "objectID": "cap-7-arima-y-alternativas.html#el-concepto-sagrado-estacionariedad-y-el-suelo-firme",
    "href": "cap-7-arima-y-alternativas.html#el-concepto-sagrado-estacionariedad-y-el-suelo-firme",
    "title": "7. Introducción: El Salto de la Suavización a la Correlación",
    "section": "",
    "text": "¿Por qué la No-Estacionariedad es una Patología Logística?\nImagina que intentas medir la altura de un objeto con una regla que se estira y encoge de forma impredecible. Si tu demanda tiene una tendencia explosiva o una variabilidad que crece junto con el volumen, ARIMA se confundirá catastróficamente.\n\nConsecuencia: Si modelas una serie no estacionaria sin corregirla, tu pronóstico será una “Caminata Aleatoria” (Random Walk). Esto hará que tus intervalos de confianza (y por ende, tu Stock de Seguridad) se expandan infinitamente, forzándote a comprar inventario de más para cubrir una incertidumbre que el modelo no sabe acotar.\n\n\n\nLa Herramienta de Nivelación: El Diferenciamiento (\\(d\\))\nPara “aplanar” el suelo y hacer la serie estacionaria, restamos el dato de hoy menos el de ayer (\\(y_t - y_{t-1}\\)). * Diferenciación de Primer Orden (\\(d=1\\)): Elimina tendencias lineales. El modelo deja de predecir “cuántas unidades venderé” y empieza a predecir “cuánto cambiará mi venta respecto a ayer”. * Diferenciación Estacional (\\(D=1\\)): Restamos el dato de hoy menos el del mismo periodo del año pasado para eliminar ciclos anuales.",
    "crumbs": [
      "II: Prediciendo el Futuro",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>7. Introducción: El Salto de la Suavización a la Correlación</span>"
    ]
  },
  {
    "objectID": "cap-7-arima-y-alternativas.html#los-tres-motores-de-arima-p-d-q",
    "href": "cap-7-arima-y-alternativas.html#los-tres-motores-de-arima-p-d-q",
    "title": "7. Introducción: El Salto de la Suavización a la Correlación",
    "section": "Los Tres Motores de ARIMA (\\(p, d, q\\))",
    "text": "Los Tres Motores de ARIMA (\\(p, d, q\\))\nUn modelo ARIMA es un sistema de tres motores interconectados que trabajan para estabilizar la predicción mediante el análisis de la correlación.\n\nEl Motor AR (Auto-Regresivo - \\(p\\)): El Impulso\nEste motor asume que el presente es una función de sus propios retrasos. Dice: “Lo que vendí ayer explica en gran medida lo que venderé hoy”. * La Intuición: Es la inercia de la demanda. Si un producto viene rodando con fuerza, es muy probable que siga rodando un poco más antes de detenerse. * Uso: Fundamental en productos con alta fidelidad de compra o contratos recurrentes.\n\n\nEl Motor I (Integrado - \\(d\\)): El Nivelador\nEs el número de veces que tuvimos que diferenciar la serie para que fuera plana. En Supply Chain, un \\(d=1\\) suele bastar. Un \\(d=2\\) es extremadamente peligroso, ya que implica una aceleración parabólica que rara vez se sostiene en mercados físicos reales.\n\n\nEl Motor MA (Moving Average - \\(q\\)): La Auto-Corrección\nAtención Crítica: No confundir con el promedio móvil del Capítulo 5. El motor MA de ARIMA promedia errores pasados. * La Intuición: Es un termostato inteligente. Si ayer el modelo predijo 100 pero se vendieron 120, el motor MA detecta ese error de \\(+20\\) y ajusta el cálculo de hoy basándose en una fracción de esa equivocación. * Beneficio: Es ideal para series con mucha volatilidad de corto plazo, permitiendo que el modelo se auto-corrija rápidamente.",
    "crumbs": [
      "II: Prediciendo el Futuro",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>7. Introducción: El Salto de la Suavización a la Correlación</span>"
    ]
  },
  {
    "objectID": "cap-7-arima-y-alternativas.html#sarima-capturando-los-ritmos-del-mercado",
    "href": "cap-7-arima-y-alternativas.html#sarima-capturando-los-ritmos-del-mercado",
    "title": "7. Introducción: El Salto de la Suavización a la Correlación",
    "section": "SARIMA: Capturando los Ritmos del Mercado",
    "text": "SARIMA: Capturando los Ritmos del Mercado\nComo ingenieros, sabemos que el mundo es cíclico. Por eso usamos SARIMA (la “S” es de Seasonal). Añadimos parámetros estacionales (\\(P, D, Q\\)) que hacen lo mismo que sus hermanos menores, pero en bloques de 12 meses. Esto permite que el modelo entienda que lo que pasa en este Black Friday está correlacionado con los últimos tres, no solo con lo que pasó ayer.",
    "crumbs": [
      "II: Prediciendo el Futuro",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>7. Introducción: El Salto de la Suavización a la Correlación</span>"
    ]
  },
  {
    "objectID": "cap-7-arima-y-alternativas.html#más-allá-de-arima-el-arsenal-de-alternativas-robustas",
    "href": "cap-7-arima-y-alternativas.html#más-allá-de-arima-el-arsenal-de-alternativas-robustas",
    "title": "7. Introducción: El Salto de la Suavización a la Correlación",
    "section": "Más allá de ARIMA: El Arsenal de Alternativas Robustas",
    "text": "Más allá de ARIMA: El Arsenal de Alternativas Robustas\nARIMA es quirúrgico pero frágil ante datos sucios. Por eso, un planificador senior debe conocer estas alternativas de alto impacto:\n\nEl Método Theta: El “Matagigantes”\nFamoso por derrotar a complejos algoritmos de IA en competencias internacionales de pronóstico. Descompone la serie en líneas que magnifican o reducen la curvatura de la demanda. * Fortaleza: Es extremadamente estable. Si tienes historias cortas (menos de 24 meses) o mucha volatilidad, Theta suele entregar un WAPE más bajo que ARIMA sin riesgo de explotar.\n\n\nProphet (Meta): El Especialista en el Calendario\nProphet no es autorregresivo, es un modelo aditivo. Su gran ventaja es que maneja de forma nativa los feriados y promociones. * Fortaleza: Si tu demanda vive de eventos específicos (Día del Padre, Cyber Monday), Prophet permite inyectar ese conocimiento humano directamente en el modelo estadístico sin romper la matemática.",
    "crumbs": [
      "II: Prediciendo el Futuro",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>7. Introducción: El Salto de la Suavización a la Correlación</span>"
    ]
  },
  {
    "objectID": "cap-7-arima-y-alternativas.html#tabla-comparativa-la-matriz-de-decisión-de-modelos",
    "href": "cap-7-arima-y-alternativas.html#tabla-comparativa-la-matriz-de-decisión-de-modelos",
    "title": "7. Introducción: El Salto de la Suavización a la Correlación",
    "section": "Tabla Comparativa: La Matriz de Decisión de Modelos",
    "text": "Tabla Comparativa: La Matriz de Decisión de Modelos\nPara elegir el “motor” adecuado según tu segmentación ABC/XYZ (Cap. 3), utiliza esta tabla como brújula estratégica:\n\n\n\n\n\n\n\n\n\n\nModelo\nComplejidad\nDatos Mínimos\nFortaleza\nMétrica Crítica\n\n\n\n\nNaive (Cap. 5)\n⭐\n1 mes\nEl “suelo” de precisión. Cero costo.\nBenchmark\n\n\nETS (Cap. 6)\n⭐⭐\n6-12 meses\nFiltrado de ruido en productos estables.\nWAPE / Bias\n\n\nHolt-Winters (Cap. 6)\n⭐⭐⭐\n24 meses\nManejo de estacionalidad y tendencia.\nRMSE\n\n\nARIMA (Cap. 7)\n⭐⭐⭐⭐\n24-36 meses\nCaptura de correlaciones quirúrgicas.\nRMSE / AICc\n\n\nTheta (Cap. 7)\n⭐⭐⭐\n12-18 meses\nMáxima robustez en series ruidosas.\nWAPE\n\n\nProphet (Cap. 7)\n⭐⭐⭐\n12-24 meses\nGestión nativa de feriados y eventos.\nBias / WAPE",
    "crumbs": [
      "II: Prediciendo el Futuro",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>7. Introducción: El Salto de la Suavización a la Correlación</span>"
    ]
  },
  {
    "objectID": "cap-7-arima-y-alternativas.html#implementación-industrial-r-o-python",
    "href": "cap-7-arima-y-alternativas.html#implementación-industrial-r-o-python",
    "title": "7. Introducción: El Salto de la Suavización a la Correlación",
    "section": "Implementación Industrial: ¿R o Python?",
    "text": "Implementación Industrial: ¿R o Python?\nAquí abandonamos definitivamente las hojas de cálculo. Optimizar un modelo con 6 parámetros para 5,000 SKUs requiere automatización pura.\n\nR y la Elegancia de fable\nEs la herramienta con mayor rigor estadístico. El algoritmo de selección automática prueba miles de combinaciones y elige la mejor según el Criterio de Información (AICc), penalizando modelos demasiado complejos para evitar el Overfitting.\n\n\nPython y la Escala de StatsForecast\nSi necesitas procesar millones de SKUs en minutos para alimentar un sistema de reaprovisionamiento en tiempo real, Python y la librería StatsForecast son el estándar global de velocidad.",
    "crumbs": [
      "II: Prediciendo el Futuro",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>7. Introducción: El Salto de la Suavización a la Correlación</span>"
    ]
  },
  {
    "objectID": "cap-7-arima-y-alternativas.html#el-veredicto-final-wape-rmse-y-bias",
    "href": "cap-7-arima-y-alternativas.html#el-veredicto-final-wape-rmse-y-bias",
    "title": "7. Introducción: El Salto de la Suavización a la Correlación",
    "section": "El Veredicto Final: WAPE, RMSE y Bias",
    "text": "El Veredicto Final: WAPE, RMSE y Bias\nComo ingenieros de Supply Chain, el éxito no es “correr el modelo”, sino reducir el impacto financiero. 1. WAPE: ¿El modelo redujo el error real ponderado por volumen respecto al Naive? 2. RMSE: ¿Estamos penalizando adecuadamente los errores grandes que causan quiebres de stock masivos? 3. Bias (Sesgo): Vigila si el modelo “se enamora” de una subida y tarda en reaccionar cuando el mercado cae, inflando tu inventario innecesariamente.\n\n\n\n\n\n\nImportantLa Trampa del Sobre-Ajuste (Overfitting)\n\n\n\nARIMA y Prophet son tan potentes que pueden intentar explicar hasta el ruido más insignificante. Si tu modelo sugiere parámetros muy altos (ej. \\(p=5\\)), activa tus alarmas. Estás creando un modelo que describe perfecto el pasado pero que será un desastre absoluto prediciendo el futuro. La parsimonia es rentabilidad.",
    "crumbs": [
      "II: Prediciendo el Futuro",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>7. Introducción: El Salto de la Suavización a la Correlación</span>"
    ]
  },
  {
    "objectID": "cap-7-arima-y-alternativas.html#checklist-de-cierre-del-capítulo",
    "href": "cap-7-arima-y-alternativas.html#checklist-de-cierre-del-capítulo",
    "title": "7. Introducción: El Salto de la Suavización a la Correlación",
    "section": "Checklist de Cierre del Capítulo",
    "text": "Checklist de Cierre del Capítulo\n\n¿He verificado la estacionariedad de mis productos Clase A?\n¿Entiendo que el motor MA de ARIMA es una herramienta de corrección y no un promedio de ventas?\n¿He probado el Método Theta para mis productos con demanda errática (XYZ: Z)?\n¿El FVA obtenido justifica la complejidad técnica frente a un Holt-Winters?\n¿He revisado el BIAS acumulado para asegurar que no estoy comprando de más?",
    "crumbs": [
      "II: Prediciendo el Futuro",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>7. Introducción: El Salto de la Suavización a la Correlación</span>"
    ]
  },
  {
    "objectID": "cap-8-ingenieria-atributos.html",
    "href": "cap-8-ingenieria-atributos.html",
    "title": "8. Introducción: El Cambio de Paradigma",
    "section": "",
    "text": "De Series de Tiempo a Aprendizaje Supervisado\nHasta este punto del libro, hemos tratado la demanda como un ente solitario, una señal que se mira al espejo para intentar adivinar su próximo movimiento. En los Capítulos 6 (ETS) y 7 (ARIMA), nos dedicamos a analizar la “auto-correlación”: la idea de que el pasado se repite de alguna forma. Sin embargo, un ingeniero de Supply Chain de vanguardia sabe que la demanda no es un fenómeno espontáneo; es el resultado de fuerzas externas e internas que colisionan en el mercado.\nComo bien dice la máxima de la disciplina: “La inteligencia no está en el algoritmo, sino en la ingeniería de la señal”. En este capítulo, transformaremos nuestra serie lineal en una matriz de datos inteligente. Pasaremos de preguntar “¿Qué pasó?” a preguntar “¿Qué causó que pasara?”. La Ingeniería de Atributos (Feature Engineering) es el 80% del éxito en Machine Learning aplicado a Suministros. Aquí es donde inyectamos el conocimiento del negocio en el silicio.\nLos modelos estadísticos clásicos (univariantes) leen los datos en fila, buscando patrones en la secuencia cronológica. El Machine Learning (ML), por el contrario, entiende de relaciones. Para que un algoritmo aprenda, debemos convertir nuestro problema en una estructura tabular de Características (\\(X\\)) y un Objetivo (\\(y\\)).",
    "crumbs": [
      "III: El Arsenal del Científico de Datos",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>8. Introducción: El Cambio de Paradigma</span>"
    ]
  },
  {
    "objectID": "cap-8-ingenieria-atributos.html#de-series-de-tiempo-a-aprendizaje-supervisado",
    "href": "cap-8-ingenieria-atributos.html#de-series-de-tiempo-a-aprendizaje-supervisado",
    "title": "8. Introducción: El Cambio de Paradigma",
    "section": "",
    "text": "El Objetivo (\\(y\\)): Es la demanda del próximo periodo que queremos predecir.\nLas Características (\\(X\\)): Son los “porqués”. Las variables (atributos) que explican el comportamiento de \\(y\\).",
    "crumbs": [
      "III: El Arsenal del Científico de Datos",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>8. Introducción: El Cambio de Paradigma</span>"
    ]
  },
  {
    "objectID": "cap-8-ingenieria-atributos.html#atributos-históricos-capturando-la-inercia-y-el-contexto",
    "href": "cap-8-ingenieria-atributos.html#atributos-históricos-capturando-la-inercia-y-el-contexto",
    "title": "8. Introducción: El Cambio de Paradigma",
    "section": "Atributos Históricos: Capturando la Inercia y el Contexto",
    "text": "Atributos Históricos: Capturando la Inercia y el Contexto\nAunque el ML no lea secuencias de forma nativa, podemos “alimentarlo” con pedazos del pasado como columnas actuales. Esto permite que modelos como XGBoost capturen la autorregresión de forma mucho más potente que un ARIMA.\n\nRezagos (Lags) y la Regla del Lead Time\nUn rezago es el valor de la demanda en periodos anteriores. * Lag 1 (\\(y_{t-1}\\)): Captura la inercia inmediata. * Lag 7 (\\(y_{t-7}\\)): Vital para capturar el ciclo semanal en retail. * La Regla del Lead Time: Este es un aporte crítico. Si tu tiempo de reposición es de 4 semanas, predecir el día de mañana con el \\(y_{t-1}\\) es un ejercicio académico. Para que el pronóstico sea útil en la compra de inventario, tus atributos más pesados deben ser aquellos que el planificador conoce en el momento de tomar la decisión (lags iguales o superiores al Lead Time).\n\n\nEstadísticas de Ventana (Rolling Windows)\nEn lugar de mirar un punto exacto, miramos un bloque de tiempo para entender el “clima” de la demanda. * Media Móvil: Captura el nivel actual eliminando el ruido. * Volatilidad Móvil: Le dice al modelo si el mercado está estable o en caos. Un aumento en la desviación estándar suele preceder a un error de pronóstico mayor; el modelo debe saberlo para “desconfiar” de la media y ajustar los márgenes de seguridad.",
    "crumbs": [
      "III: El Arsenal del Científico de Datos",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>8. Introducción: El Cambio de Paradigma</span>"
    ]
  },
  {
    "objectID": "cap-8-ingenieria-atributos.html#atributos-de-contexto-el-calendario-inteligente",
    "href": "cap-8-ingenieria-atributos.html#atributos-de-contexto-el-calendario-inteligente",
    "title": "8. Introducción: El Cambio de Paradigma",
    "section": "Atributos de Contexto: El Calendario Inteligente",
    "text": "Atributos de Contexto: El Calendario Inteligente\nEl tiempo no es una línea uniforme; tiene “personalidad”. Un lunes 24 de diciembre no se comporta como un lunes 14 de mayo.\n\nCodificación Cíclica: Los meses 12 (diciembre) y 1 (enero) están pegados en la realidad, pero lejos matemáticamente. Usamos funciones Seno y Coseno para que el modelo entienda la naturaleza circular del tiempo.\nProximidad a Eventos: No solo marques el día del “Black Friday”. Crea una variable que cuente los “Días restantes para el evento”. Esto permite capturar el “efecto espera” (caída de ventas previa) y la explosión posterior.",
    "crumbs": [
      "III: El Arsenal del Científico de Datos",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>8. Introducción: El Cambio de Paradigma</span>"
    ]
  },
  {
    "objectID": "cap-8-ingenieria-atributos.html#atributos-exógenos-los-drivers-de-valor",
    "href": "cap-8-ingenieria-atributos.html#atributos-exógenos-los-drivers-de-valor",
    "title": "8. Introducción: El Cambio de Paradigma",
    "section": "Atributos Exógenos: Los Drivers de Valor",
    "text": "Atributos Exógenos: Los Drivers de Valor\nAquí es donde el ML supera a la estadística tradicional al integrar variables que mueven la aguja del negocio.\n\nEl Precio y la Elasticidad Dinámica\nNo incluyas solo el precio nominal. Crea el Precio Relativo (Precio Actual / Precio Promedio del Trimestre). Esto captura si el producto está “de oferta” o “caro” respecto a la memoria del consumidor. Al incluir esto, el modelo aprenderá la elasticidad demanda-precio automáticamente.\n\n\nEfectos Cruzados: Canibalización y Halo\nSi pones el Producto A en oferta, la demanda del Producto B (su competidor interno) caerá. * Ingeniería de Canibalización: Crea atributos que indiquen si productos sustitutos están en promoción. Sin esto, el modelo malinterpretará las caídas de ventas de B como una pérdida de tendencia, cuando es un efecto provocado por A.",
    "crumbs": [
      "III: El Arsenal del Científico de Datos",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>8. Introducción: El Cambio de Paradigma</span>"
    ]
  },
  {
    "objectID": "cap-8-ingenieria-atributos.html#el-pecado-capital-fuga-de-datos-data-leakage",
    "href": "cap-8-ingenieria-atributos.html#el-pecado-capital-fuga-de-datos-data-leakage",
    "title": "8. Introducción: El Cambio de Paradigma",
    "section": "El Pecado Capital: Fuga de Datos (Data Leakage)",
    "text": "El Pecado Capital: Fuga de Datos (Data Leakage)\nEste es el error que destruye proyectos y carreras. La Fuga de Datos ocurre cuando incluyes en tu entrenamiento información que no tendrías disponible en el momento de hacer el pronóstico real.\n\nEl Error Típico: Incluir el promedio de ventas del mes actual para predecir la venta de hoy. Si estás a día 5, no conoces el promedio del mes completo.\nLa Consecuencia: Tu modelo tendrá un WAPE perfecto en el laboratorio (0.5%), pero fallará estrepitosamente en la vida real porque ese dato del “futuro” simplemente no existe.",
    "crumbs": [
      "III: El Arsenal del Científico de Datos",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>8. Introducción: El Cambio de Paradigma</span>"
    ]
  },
  {
    "objectID": "cap-8-ingenieria-atributos.html#implementación-técnica-de-la-intuición-al-dato",
    "href": "cap-8-ingenieria-atributos.html#implementación-técnica-de-la-intuición-al-dato",
    "title": "8. Introducción: El Cambio de Paradigma",
    "section": "Implementación Técnica: De la Intuición al Dato",
    "text": "Implementación Técnica: De la Intuición al Dato\n\nCodificación de Categorías (Target Encoding)\nUn algoritmo no sabe qué es “Coca-Cola”. Reemplazar el nombre de la categoría por su venta promedio histórica (Target Encoding) es la forma más inteligente de decirle al modelo el “peso” que tiene un producto sin saturarlo con cientos de columnas innecesarias.\n\n\nVeredicto del FVA por Atributo\nCada atributo nuevo añade ruido y costo de mantenimiento. 1. Mide el FVA: ¿Agregar el “clima” realmente bajó el RMSE significativamente? 2. Importancia de Atributos: Deja que el modelo te diga qué columnas usa realmente. Si la “Fase Lunar” tiene importancia cero, bórrala sin piedad.\n\n\n\n\n\n\nImportantEl Rol del Arquitecto de Demanda\n\n\n\nTú no eres un consumidor de algoritmos; eres el curador de la verdad del negocio. Tu misión es convertir la intuición del mercado en una columna de datos que el algoritmo pueda procesar. La complejidad debe ser una inversión, no un gasto.",
    "crumbs": [
      "III: El Arsenal del Científico de Datos",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>8. Introducción: El Cambio de Paradigma</span>"
    ]
  },
  {
    "objectID": "cap-8-ingenieria-atributos.html#checklist-de-cierre-del-capítulo",
    "href": "cap-8-ingenieria-atributos.html#checklist-de-cierre-del-capítulo",
    "title": "8. Introducción: El Cambio de Paradigma",
    "section": "Checklist de Cierre del Capítulo",
    "text": "Checklist de Cierre del Capítulo\n\n¿He transformado mi serie univariante en una matriz tabular (\\(X, y\\))?\n¿Mis Lags respetan el Lead Time de mi cadena de suministro?\n¿He incluido el Precio Relativo para capturar la elasticidad automáticamente?\n¿He verificado que no hay información del futuro en mis columnas (Data Leakage)?\n¿He medido el FVA de los nuevos atributos respecto a los modelos del Capítulo 7?",
    "crumbs": [
      "III: El Arsenal del Científico de Datos",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>8. Introducción: El Cambio de Paradigma</span>"
    ]
  },
  {
    "objectID": "cap-9-bosque-decisiones.html",
    "href": "cap-9-bosque-decisiones.html",
    "title": "9. El Bosque de las Decisiones - Random Forest y XGBoost",
    "section": "",
    "text": "9.1 La Anatomía de un Árbol: El Inicio del Viaje\nEn el Capítulo 8 preparamos el combustible: la Ingeniería de Atributos. Ahora, es momento de encender los motores. Si la estadística tradicional (ETS, ARIMA) es como un compás que busca rimas en la historia, el Machine Learning (ML) es como un radar que detecta patrones en un mar de variables interconectadas.\nComo ingenieros de Supply Chain, nuestra meta no es usar el algoritmo más complejo para impresionar a la junta directiva, sino reducir la incertidumbre. En este capítulo, dominaremos los dos algoritmos que dominan las competencias de ciencia de datos y las torres de control de las empresas Fortune 500: Random Forest y XGBoost. Te voy avisando: aquí es donde la precisión se vuelve una ventaja competitiva real.\nAntes de entender el bosque, debemos entender el árbol. Un Árbol de Decisión es simplemente una serie de preguntas lógicas (IF-THEN) que dividen tus datos.",
    "crumbs": [
      "III: El Arsenal del Científico de Datos",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>9. El Bosque de las Decisiones - Random Forest y XGBoost</span>"
    ]
  },
  {
    "objectID": "cap-9-bosque-decisiones.html#la-anatomía-de-un-árbol-el-inicio-del-viaje",
    "href": "cap-9-bosque-decisiones.html#la-anatomía-de-un-árbol-el-inicio-del-viaje",
    "title": "9. El Bosque de las Decisiones - Random Forest y XGBoost",
    "section": "",
    "text": "Ejemplo: ¿Es fin de semana? (SÍ/NO) $ ightarrow$ ¿El precio bajó más de un 10%? (SÍ/NO) $ ightarrow$ ¿Hay alerta de tormenta? (SÍ/NO).\nEl Problema: Un solo árbol es frágil. Tiende a memorizar el pasado (Overfitting) y falla estrepitosamente ante datos que no ha visto antes.",
    "crumbs": [
      "III: El Arsenal del Científico de Datos",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>9. El Bosque de las Decisiones - Random Forest y XGBoost</span>"
    ]
  },
  {
    "objectID": "cap-9-bosque-decisiones.html#random-forest-la-fuerza-de-la-multitud-bagging",
    "href": "cap-9-bosque-decisiones.html#random-forest-la-fuerza-de-la-multitud-bagging",
    "title": "9. El Bosque de las Decisiones - Random Forest y XGBoost",
    "section": "9.2 Random Forest: La Fuerza de la Multitud (Bagging)",
    "text": "9.2 Random Forest: La Fuerza de la Multitud (Bagging)\nUn Random Forest es una democracia de árboles. En lugar de confiar en un solo árbol “experto”, creamos cientos de árboles diferentes, cada uno entrenado con una sub-muestra aleatoria de tus datos y atributos.\n\nLa Magia: La promediación. Si un árbol se equivoca por un ruido aleatorio, los otros 99 lo corrigen.\nVentaja Logística: Es extremadamente robusto. Maneja valores nulos y outliers de forma natural, lo cual es oro puro en bases de datos de Supply Chain que no siempre están perfectamente limpias.\nVeredicto de Vandeput: “Random Forest es el mejor modelo de entrada al ML; es difícil de romper y fácil de explicar”.",
    "crumbs": [
      "III: El Arsenal del Científico de Datos",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>9. El Bosque de las Decisiones - Random Forest y XGBoost</span>"
    ]
  },
  {
    "objectID": "cap-9-bosque-decisiones.html#xgboost-la-ferrari-del-pronóstico-boosting",
    "href": "cap-9-bosque-decisiones.html#xgboost-la-ferrari-del-pronóstico-boosting",
    "title": "9. El Bosque de las Decisiones - Random Forest y XGBoost",
    "section": "9.3 XGBoost: La Ferrari del Pronóstico (Boosting)",
    "text": "9.3 XGBoost: La Ferrari del Pronóstico (Boosting)\nSi Random Forest es una democracia, XGBoost es un equipo de élite donde cada miembro aprende de los errores del anterior. Esto es lo que llamamos Gradient Boosting.\n\nEl Árbol 1 hace una predicción.\nEl Árbol 2 no intenta predecir la demanda, intenta predecir el error del Árbol 1.\nEl Árbol 3 intenta predecir el error restante del Árbol 2.\n\n\nEl Resultado: Una precisión quirúrgica. XGBoost es capaz de capturar relaciones no lineales y efectos estacionales complejos que a un modelo ARIMA le tomaría años de parametrización detectar.\nEl Riesgo: Es una herramienta de alta potencia. Si no controlas su “velocidad de aprendizaje” (learning rate), el modelo se enamorará del ruido y destruirá tu FVA.",
    "crumbs": [
      "III: El Arsenal del Científico de Datos",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>9. El Bosque de las Decisiones - Random Forest y XGBoost</span>"
    ]
  },
  {
    "objectID": "cap-9-bosque-decisiones.html#entendiendo-el-porqué-importancia-de-atributos-y-shap-values",
    "href": "cap-9-bosque-decisiones.html#entendiendo-el-porqué-importancia-de-atributos-y-shap-values",
    "title": "9. El Bosque de las Decisiones - Random Forest y XGBoost",
    "section": "9.4 Entendiendo el “Porqué”: Importancia de Atributos y SHAP Values",
    "text": "9.4 Entendiendo el “Porqué”: Importancia de Atributos y SHAP Values\nUno de los grandes miedos en Supply Chain es la “Caja Negra”. No puedes ir a una reunión de S&OP y decir: “El modelo dice que hay que comprar 1,000 unidades porque sí”. Necesitas explicabilidad.\n\nFeature Importance: El modelo te dirá qué porcentaje de la decisión se debió al precio, cuánto al lag y cuánto al feriado.\nSHAP Values: Es la herramienta definitiva. Te permite ver, para un pedido específico de un cliente, exactamente cuánto sumó el “Black Friday” y cuánto restó el “Alza de Precio” al pronóstico final.",
    "crumbs": [
      "III: El Arsenal del Científico de Datos",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>9. El Bosque de las Decisiones - Random Forest y XGBoost</span>"
    ]
  },
  {
    "objectID": "cap-9-bosque-decisiones.html#implementación-estratégica-el-duelo-de-modelos",
    "href": "cap-9-bosque-decisiones.html#implementación-estratégica-el-duelo-de-modelos",
    "title": "9. El Bosque de las Decisiones - Random Forest y XGBoost",
    "section": "9.5 Implementación Estratégica: El Duelo de Modelos",
    "text": "9.5 Implementación Estratégica: El Duelo de Modelos\nNo implementes ML por moda. Tu proceso debe ser una competencia implacable:\n\nBaseline: Tu Naive del Cap. 5.\nChallenger 1: Tu Holt-Winters o ARIMA del Cap. 6 y 7.\nChallenger 2: Tu XGBoost con Ingeniería de Atributos.\n\nSi el WAPE de XGBoost no es al menos un 5% mejor que el de ARIMA, la recomendación técnica es quedarse con la estadística simple. La complejidad debe pagar dividendos.",
    "crumbs": [
      "III: El Arsenal del Científico de Datos",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>9. El Bosque de las Decisiones - Random Forest y XGBoost</span>"
    ]
  },
  {
    "objectID": "cap-9-bosque-decisiones.html#laboratorio-en-python-encendiendo-el-motor",
    "href": "cap-9-bosque-decisiones.html#laboratorio-en-python-encendiendo-el-motor",
    "title": "9. El Bosque de las Decisiones - Random Forest y XGBoost",
    "section": "9.6 Laboratorio en Python: Encendiendo el Motor",
    "text": "9.6 Laboratorio en Python: Encendiendo el Motor\nfrom xgboost import XGBRegressor\nfrom sklearn.ensemble import RandomForestRegressor\n\n# Configuración de XGBoost para Supply Chain\nmodel_xgb = XGBRegressor(\n    n_estimators=1000,\n    learning_rate=0.05,\n    max_depth=6,\n    subsample=0.8\n)\n\n# Entrenamiento con la matriz X, y del Capítulo 8\nmodel_xgb.fit(X_train, y_train)\n\n# Generación del pronóstico\nforecast = model_xgb.predict(X_test)",
    "crumbs": [
      "III: El Arsenal del Científico de Datos",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>9. El Bosque de las Decisiones - Random Forest y XGBoost</span>"
    ]
  },
  {
    "objectID": "cap-9-bosque-decisiones.html#el-veredicto-del-arquitecto",
    "href": "cap-9-bosque-decisiones.html#el-veredicto-del-arquitecto",
    "title": "9. El Bosque de las Decisiones - Random Forest y XGBoost",
    "section": "9.7 El Veredicto del Arquitecto",
    "text": "9.7 El Veredicto del Arquitecto\nEl Machine Learning te da el poder de predecir la elasticidad, el efecto de las promociones y la canibalización. Pero recuerda: un modelo de ML es un extrapolador peligroso. Si ocurre algo que nunca pasó antes (como una pandemia o un cierre de fronteras), el modelo no tendrá “memoria” de eso y fallará. Tu juicio humano sigue siendo el supervisor del bosque.\n\n\n\n\n\n\nImportantLa Disciplina del FVA\n\n\n\nEn la Supply Chain Inteligente, el Machine Learning no sustituye al planificador; lo libera de las tareas repetitivas para que pueda enfocarse en las excepciones. Si tu modelo de ML requiere 20 horas de mantenimiento al mes para ganar un 1% de precisión, has fracasado como ingeniero. Optimiza el valor, no solo el error.",
    "crumbs": [
      "III: El Arsenal del Científico de Datos",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>9. El Bosque de las Decisiones - Random Forest y XGBoost</span>"
    ]
  },
  {
    "objectID": "cap-9-bosque-decisiones.html#checklist-de-cierre-del-capítulo",
    "href": "cap-9-bosque-decisiones.html#checklist-de-cierre-del-capítulo",
    "title": "9. El Bosque de las Decisiones - Random Forest y XGBoost",
    "section": "Checklist de Cierre del Capítulo",
    "text": "Checklist de Cierre del Capítulo\n\n¿He comparado mi modelo de bosque contra mi benchmark estadístico?\n¿He revisado la importancia de los atributos para validar que el modelo tiene “sentido común”?\n¿He configurado los hiperparámetros para evitar el sobreajuste (Overfitting)?\n¿El WAPE obtenido justifica la pérdida de simplicidad del modelo?\n¿He validado el modelo con datos que el algoritmo nunca vio (Out-of-sample)?",
    "crumbs": [
      "III: El Arsenal del Científico de Datos",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>9. El Bosque de las Decisiones - Random Forest y XGBoost</span>"
    ]
  },
  {
    "objectID": "cap-10-validacion-overfitting.html",
    "href": "cap-10-validacion-overfitting.html",
    "title": "10. El Desierto de los Datos",
    "section": "",
    "text": "10.1 La Anatomía del Overfitting (Sobreajuste)\nLlegamos a la frontera crítica que separa a los aficionados de los ingenieros de Supply Chain de élite. En los Capítulos 8 y 9, aprendimos a construir una infraestructura de atributos potentes y a encender motores de Machine Learning de alto rendimiento como XGBoost y LightGBM. Sin embargo, en el desierto de los datos, el espejismo es el error más caro. Existe una trampa mortal esperándote: la asombrosa capacidad de estos modelos para memorizar el pasado en lugar de aprender del pasado.\nComo diría la máxima de esta disciplina: “Si torturas los datos lo suficiente, confesarán lo que quieras”. El problema es que esa “confesión” no te servirá de nada cuando el camión llegue al almacén y la demanda real sea distinta. En este capítulo, aprenderemos a no ser torturadores, sino auditores científicos. Vamos a construir un marco de validación robusto para asegurar que la precisión que vemos en nuestra pantalla sea una representación fiel de la realidad que sentiremos en el flujo de caja.\nEl Overfitting ocurre cuando un modelo es tan complejo o tiene tantos grados de libertad que empieza a explicar el ruido estadístico como si fuera una señal de mercado.",
    "crumbs": [
      "III: El Arsenal del Científico de Datos",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>10. El Desierto de los Datos</span>"
    ]
  },
  {
    "objectID": "cap-10-validacion-overfitting.html#la-anatomía-del-overfitting-sobreajuste",
    "href": "cap-10-validacion-overfitting.html#la-anatomía-del-overfitting-sobreajuste",
    "title": "10. El Desierto de los Datos",
    "section": "",
    "text": "La Patología: El modelo se vuelve “narcisista”: se enamora de tus datos históricos. Ajusta sus parámetros de tal forma que su curva pasa exactamente por cada punto de venta, incluyendo aquel pedido errático de un cliente o aquella caída de ventas provocada por un fallo puntual en el servidor del ERP. El modelo no está aprendiendo la “regla”, está memorizando el “ruido”.\nEl Síntoma del Espejismo: Es el momento en que el analista celebra un WAPE del 2% en sus datos de entrenamiento. Pero, al aplicar ese mismo modelo al mes siguiente (datos no vistos), el error explota hasta el 40%. Esta brecha entre el rendimiento interno y el externo es la firma del sobreajuste.\nLa Consecuencia Operativa: En el mundo físico, el overfitting se traduce en un inventario histérico. Tu sistema de planificación reaccionará violentamente a fluctuaciones irrelevantes, disparando órdenes de compra innecesarias o cancelando suministros críticos basándose en “patrones” que solo existieron una vez.",
    "crumbs": [
      "III: El Arsenal del Científico de Datos",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>10. El Desierto de los Datos</span>"
    ]
  },
  {
    "objectID": "cap-10-validacion-overfitting.html#el-compromiso-entre-sesgo-bias-y-varianza",
    "href": "cap-10-validacion-overfitting.html#el-compromiso-entre-sesgo-bias-y-varianza",
    "title": "10. El Desierto de los Datos",
    "section": "10.2 El Compromiso entre Sesgo (Bias) y Varianza",
    "text": "10.2 El Compromiso entre Sesgo (Bias) y Varianza\nPara domar al modelo, debemos entender la “física del error”. Cualquier error de pronóstico se puede descomponer en dos fuerzas opuestas que debemos equilibrar:\n\nSesgo (Bias - Underfitting): Representa la incapacidad del modelo para capturar la señal real por ser demasiado simple. Un modelo con mucho sesgo es como intentar medir una curva compleja con una regla rígida. Se equivoca sistemáticamente, ignorando tendencias o estacionalidades obvias.\nVarianza (Overfitting): Representa la sensibilidad extrema del modelo a pequeñas fluctuaciones en los datos de entrenamiento. Un modelo con mucha varianza es “demasiado nervioso”. Si cambias un solo dato en el pasado, la predicción para el futuro cambia radicalmente.\n\nEl Objetivo del Ingeniero: Maximizar el valor del negocio encontrando el punto óptimo donde la suma del Sesgo y la Varianza es mínima. Aquí es donde entra la Regularización, que actúa como un “freno de mano” matemático, penalizando al modelo si intenta volverse demasiado complejo.",
    "crumbs": [
      "III: El Arsenal del Científico de Datos",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>10. El Desierto de los Datos</span>"
    ]
  },
  {
    "objectID": "cap-10-validacion-overfitting.html#la-regla-de-oro-validación-cruzada-temporal-backtesting",
    "href": "cap-10-validacion-overfitting.html#la-regla-de-oro-validación-cruzada-temporal-backtesting",
    "title": "10. El Desierto de los Datos",
    "section": "10.3 La Regla de Oro: Validación Cruzada Temporal (Backtesting)",
    "text": "10.3 La Regla de Oro: Validación Cruzada Temporal (Backtesting)\nEn la ciencia de datos tradicional se usa la validación cruzada aleatoria. En Supply Chain, esto es una negligencia técnica. El tiempo es una flecha unidireccional. No puedes usar las ventas de diciembre para predecir las de enero y, simultáneamente, usar las de marzo para “explicar” las de febrero.\n\n10.3.1 Estrategias de Backtesting: Deslizante vs. Expansiva\nPara validar un modelo de demanda de forma profesional, simulamos que estamos en el pasado y corremos el pronóstico mes a mes (Walk-Forward Validation):\n\nVentana Expansiva: El modelo siempre entrena con todo lo que sabe desde el inicio hasta hoy.\nVentana Deslizante (Sliding Window): El modelo solo mira, por ejemplo, los últimos 24 meses. A medida que avanzamos un mes, “olvidamos” el mes más antiguo. Esto es útil si tu mercado cambia tan rápido que los datos antiguos ya no son informativos, sino ruido.",
    "crumbs": [
      "III: El Arsenal del Científico de Datos",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>10. El Desierto de los Datos</span>"
    ]
  },
  {
    "objectID": "cap-10-validacion-overfitting.html#división-de-datos-el-método-de-las-tres-cajas",
    "href": "cap-10-validacion-overfitting.html#división-de-datos-el-método-de-las-tres-cajas",
    "title": "10. El Desierto de los Datos",
    "section": "10.4 División de Datos: El Método de las Tres Cajas",
    "text": "10.4 División de Datos: El Método de las Tres Cajas\nPara evitar el auto-engaño, dividimos nuestro historial en tres cajas sagradas:\n\nEntrenamiento (Train): Donde el modelo “estudia” y ajusta sus pesos iniciales (aprox. 70-80% de la historia).\nPrueba (Test/Validation): Donde el ingeniero ajusta los hiperparámetros. El modelo no entrena aquí, pero sirve para tomar decisiones de diseño.\nValidación Final (Hold-out): La prueba de fuego. Esta caja nunca debe ser vista por el modelo hasta el final del proyecto. Si el rendimiento aquí cae significativamente, el modelo ha fallado.",
    "crumbs": [
      "III: El Arsenal del Científico de Datos",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>10. El Desierto de los Datos</span>"
    ]
  },
  {
    "objectID": "cap-10-validacion-overfitting.html#detectando-la-fuga-de-información-data-leakage",
    "href": "cap-10-validacion-overfitting.html#detectando-la-fuga-de-información-data-leakage",
    "title": "10. El Desierto de los Datos",
    "section": "10.5 Detectando la Fuga de Información (Data Leakage)",
    "text": "10.5 Detectando la Fuga de Información (Data Leakage)\nLa fuga de datos es la razón por la cual muchos proyectos de IA mueren al llegar a producción. Ocurre cuando, por error, le damos al modelo “las respuestas del examen” durante el entrenamiento.\n\nEjemplo Crítico: Incluir el inventario final de hoy para predecir la demanda de hoy.\nLa Señal de Alarma de Vandeput: Si ves un FVA (Forecast Value Added) superior al 30% respecto a un modelo estadístico, desconfía. El éxito real suele ser incremental (5-10%). Un resultado milagroso suele ser evidencia de fuga de información.",
    "crumbs": [
      "III: El Arsenal del Científico de Datos",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>10. El Desierto de los Datos</span>"
    ]
  },
  {
    "objectID": "cap-10-validacion-overfitting.html#el-veredicto-final-del-fva-y-la-deuda-técnica",
    "href": "cap-10-validacion-overfitting.html#el-veredicto-final-del-fva-y-la-deuda-técnica",
    "title": "10. El Desierto de los Datos",
    "section": "10.6 El Veredicto Final del FVA y la Deuda Técnica",
    "text": "10.6 El Veredicto Final del FVA y la Deuda Técnica\nComo Nicolas Vandeput enfatiza, el FVA es la única métrica que importa. Sin embargo, debe ser auditado bajo la lente de la Parsimonia.\n\nLa Trampa de la Complejidad: Si un modelo estadístico simple tiene un WAPE del 18% y tu XGBoost hiper-optimizado tiene un 17.5%, has fracasado como ingeniero. Estás comprando un 0.5% de precisión a cambio de una enorme deuda técnica: un modelo más difícil de explicar, más costoso de mantener y propenso a romperse.\nEstabilidad sobre Precisión: Preferimos un modelo con un 20% de error constante a uno que fluctúe entre el 10% y el 40%. La estabilidad permite dimensionar el stock de seguridad con confianza.\n\n\n\n\n\n\n\nImportantLa Navaja de Ockham en Supply Chain\n\n\n\nEn igualdad de condiciones, la explicación más sencilla suele ser la correcta. El modelo más simple que entregue un FVA aceptable es siempre la elección profesional superior.",
    "crumbs": [
      "III: El Arsenal del Científico de Datos",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>10. El Desierto de los Datos</span>"
    ]
  },
  {
    "objectID": "cap-10-validacion-overfitting.html#checklist-de-cierre-del-capítulo",
    "href": "cap-10-validacion-overfitting.html#checklist-de-cierre-del-capítulo",
    "title": "10. El Desierto de los Datos",
    "section": "Checklist de Cierre del Capítulo",
    "text": "Checklist de Cierre del Capítulo\n\n¿He implementado una validación cruzada temporal (Walk-Forward)?\n¿He verificado que el error en mi set de Hold-out es consistente con el de Entrenamiento?\n¿He auditado mis atributos para asegurar que ninguno contiene información “del futuro” (Data Leakage)?\n¿He aplicado técnicas de Regularización para evitar que el modelo persiga el ruido?\n¿He calculado el FVA final y evaluado si la mejora justifica la complejidad?",
    "crumbs": [
      "III: El Arsenal del Científico de Datos",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>10. El Desierto de los Datos</span>"
    ]
  },
  {
    "objectID": "cap-11-costos-inventario.html",
    "href": "cap-11-costos-inventario.html",
    "title": "11. El Costo del Dinero y el Costo del Vacío",
    "section": "",
    "text": "11.1 El Inventario como Pasivo: El Costo de Mantenimiento (\\(h\\))\nFelicidades. Has sobrevivido a la maratón estadística de las primeras tres partes de este libro. Ya sabes cómo limpiar datos, detectar patrones estructurales con ARIMA y entrenar modelos de Machine Learning para capturar la complejidad del mercado. Pero aquí es donde la ingeniería de datos se encuentra con la Ingeniería Financiera.\nMuchos planificadores cometen el error garrafal de pensar que su trabajo termina cuando entregan un número de demanda. La realidad es que el pronóstico es solo un insumo; un “puro deseo” estadístico. La verdadera decisión de Supply Chain —la que afecta el flujo de caja y la supervivencia de la empresa— ocurre cuando decides cuánta mercancía física poner en la estantería.\nEn esta Parte IV, daremos respuesta a la pregunta definitiva del arquitecto: Ya sé qué es probable que pase, ahora… ¿cuánto capital debo arriesgar en inventario?\nEn la gestión de inventarios, no buscamos “precisión”, buscamos rentabilidad. Cada caja en tu almacén es dinero que no está en el banco rindiendo intereses, y cada estante vacío es una invitación para que tu cliente descubra lo buena que es tu competencia. En este capítulo, aprenderemos a modelar el conflicto eterno entre el costo de tener demasiado y el costo de no tener nada.\nEn la contabilidad tradicional, el inventario se registra en el balance como un activo. Sin embargo, para un optimizador de suministros, el inventario es un pasivo operativo: una promesa de venta que genera gastos operativos y financieros cada segundo que pasa sin moverse.\nEl costo de mantenimiento, denotado como \\(h\\) (holding cost), representa el “impuesto” anual que pagas por el privilegio de tener una unidad almacenada. Se define mediante la ecuación fundamental:\n\\[h = v \\times (i + w + r)\\]",
    "crumbs": [
      "IV: La Ciencia del Stock",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>11. El Costo del Dinero y el Costo del Vacío</span>"
    ]
  },
  {
    "objectID": "cap-11-costos-inventario.html#el-inventario-como-pasivo-el-costo-de-mantenimiento-h",
    "href": "cap-11-costos-inventario.html#el-inventario-como-pasivo-el-costo-de-mantenimiento-h",
    "title": "11. El Costo del Dinero y el Costo del Vacío",
    "section": "",
    "text": "Disección de los Parámetros Financieros\nPara que tu modelo tenga impacto real en el P&L (Estado de Resultados), debes auditar estas fuentes con rigor:\n\n\\(v\\) (Valor del Producto): Es la base sobre la que se calcula todo el riesgo.\n\nOrigen: ERP / Contabilidad de Costos.\nImplicación: Debes utilizar siempre el Costo de Adquisición o Costo de Fabricación (COGS). Nunca uses el precio de venta.\n\n\\(i\\) (Tasa de Capital / Costo de Oportunidad): El valor del dinero en el tiempo.\n\nOrigen: Dirección de Finanzas (Tesorería).\nExplicación: Se utiliza el WACC (Weighted Average Cost of Capital). Si es del 15%, cada unidad te cuesta un 15% de su valor al año solo por existir.\n\n\\(w\\) (Tasa de Almacenaje y Operación): El costo del “techo” y las manos.\n\nOrigen: Control de Gestión Logística.\nDetalle: Renta, electricidad, personal y seguros. Se calcula como el gasto total logístico entre el valor promedio del inventario.\n\n\\(r\\) (Tasa de Riesgo, Merma y Obsolescencia): El costo de la entropía.\n\nOrigen: Auditoría de Inventarios.\nEscenarios: Crítico en moda o tecnología donde el producto caduca moralmente rápido.",
    "crumbs": [
      "IV: La Ciencia del Stock",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>11. El Costo del Dinero y el Costo del Vacío</span>"
    ]
  },
  {
    "objectID": "cap-11-costos-inventario.html#la-tragedia-del-estante-vacío-el-costo-de-escasez-s",
    "href": "cap-11-costos-inventario.html#la-tragedia-del-estante-vacío-el-costo-de-escasez-s",
    "title": "11. El Costo del Dinero y el Costo del Vacío",
    "section": "11.2 La Tragedia del Estante Vacío: El Costo de Escasez (\\(s\\))",
    "text": "11.2 La Tragedia del Estante Vacío: El Costo de Escasez (\\(s\\))\nSi el costo de mantenimiento es un “goteo”, el costo de escasez (stockout cost) es una “hemorragia”. Se descompone en:\n\nMargen Perdido Directo: El dinero que “vuela” en el quiebre. (\\(s_{directo} = \\text{Precio} - \\text{Costo Variable}\\)).\nPenalizaciones Contractuales: Multas por “Fill Rate” bajo.\nCostos de Recuperación (Expedición): El costo de enviar pedidos por avión para mitigar el faltante.\nEfecto Churn y Valor de Vida del Cliente (LTV): Perder el flujo de caja de los próximos años de ese cliente.\n\nEstimación Pragmática: \\[s = \\text{Margen} + (\\text{Probabilidad de Abandono} \\times \\text{LTV})\\]",
    "crumbs": [
      "IV: La Ciencia del Stock",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>11. El Costo del Dinero y el Costo del Vacío</span>"
    ]
  },
  {
    "objectID": "cap-11-costos-inventario.html#la-gran-balanza-ecuación-del-costo-total",
    "href": "cap-11-costos-inventario.html#la-gran-balanza-ecuación-del-costo-total",
    "title": "11. El Costo del Dinero y el Costo del Vacío",
    "section": "11.3 La Gran Balanza: Ecuación del Costo Total",
    "text": "11.3 La Gran Balanza: Ecuación del Costo Total\nTu misión es minimizar el Costo Total (CT):\n\\[CT = (\\bar{I} \\times h) + (P(k) \\times s)\\]\n\nCosto de Posesión \\((\\bar{I} \\times h)\\): El costo de “estar seguro”.\nCosto de Riesgo \\((P(k) \\times s)\\): Donde \\(P(k)\\) es la probabilidad de quiebre derivada directamente del RMSE de tus modelos previos.",
    "crumbs": [
      "IV: La Ciencia del Stock",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>11. El Costo del Dinero y el Costo del Vacío</span>"
    ]
  },
  {
    "objectID": "cap-11-costos-inventario.html#implicaciones-estratégicas-y-segmentación",
    "href": "cap-11-costos-inventario.html#implicaciones-estratégicas-y-segmentación",
    "title": "11. El Costo del Dinero y el Costo del Vacío",
    "section": "11.4 Implicaciones Estratégicas y Segmentación",
    "text": "11.4 Implicaciones Estratégicas y Segmentación\n\nProductos Clase A (Críticos): El costo \\(s\\) es inmenso. Se acepta un \\(h\\) elevado para proteger el margen.\nProductos Clase C (Lentos): El costo \\(h\\) domina. Es financieramente más inteligente dejar que el producto falte ocasionalmente.",
    "crumbs": [
      "IV: La Ciencia del Stock",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>11. El Costo del Dinero y el Costo del Vacío</span>"
    ]
  },
  {
    "objectID": "cap-11-costos-inventario.html#el-mito-del-100-de-nivel-de-servicio",
    "href": "cap-11-costos-inventario.html#el-mito-del-100-de-nivel-de-servicio",
    "title": "11. El Costo del Dinero y el Costo del Vacío",
    "section": "11.5 El Mito del 100% de Nivel de Servicio",
    "text": "11.5 El Mito del 100% de Nivel de Servicio\nComo ingeniero, debes demostrar que el 100% es financieramente suicida. Debido a la distribución normal del error, el inventario crece de forma exponencial al acercarse al 100%, mientras que el beneficio marginal es decreciente.\n\n\n\n\n\n\nImportantLa Visión del Arquitecto\n\n\n\nEn Supply Chain, es infinitamente mejor estar aproximadamente en lo correcto que exactamente en lo incorrecto. Usa una estimación del 20%-25% anual para \\(h\\) y comienza a optimizar.",
    "crumbs": [
      "IV: La Ciencia del Stock",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>11. El Costo del Dinero y el Costo del Vacío</span>"
    ]
  },
  {
    "objectID": "cap-11-costos-inventario.html#checklist-de-cierre-del-capítulo",
    "href": "cap-11-costos-inventario.html#checklist-de-cierre-del-capítulo",
    "title": "11. El Costo del Dinero y el Costo del Vacío",
    "section": "Checklist de Cierre del Capítulo",
    "text": "Checklist de Cierre del Capítulo\n\n¿He calculado el margen contribuido real para mis productos Clase A?\n¿Tengo una cifra consensuada con Finanzas para el WACC?\n¿Entiendo que el RMSE es el que determina cuánto dinero estoy apostando en el riesgo \\(P(k)\\)?",
    "crumbs": [
      "IV: La Ciencia del Stock",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>11. El Costo del Dinero y el Costo del Vacío</span>"
    ]
  },
  {
    "objectID": "cap-12-eoq-punto-reorden.html",
    "href": "cap-12-eoq-punto-reorden.html",
    "title": "12. El Paso del Pronóstico a la Orden",
    "section": "",
    "text": "12.1 El Escenario Determinista: Las Reglas del Juego\nEn las secciones anteriores de este libro, nos obsesionamos con la precisión. Aprendimos a diseccionar la demanda para encontrar niveles, tendencias y estacionalidades utilizando desde suavizamiento exponencial hasta algoritmos de gradiente. Sin embargo, en la trinchera de la Supply Chain, el pronóstico es simplemente una “declaración de intenciones”. La realidad financiera y el impacto operativo solo se materializan cuando el camión llega al muelle de descarga, se firma la factura y el inventario se asienta en el balance general como capital inmovilizado.\nMuchos planificadores operan bajo “reglas de dedo” heredadas: “Pedimos cada lunes”, “Mantenemos dos semanas de stock” o “Pedimos cuando el estante se vea vacío”. Estas heurísticas son peligrosas porque ignoran el equilibrio de costos que modelamos en el Capítulo 11. En este capítulo, estableceremos la física básica del inventario mediante la Fórmula de Wilson (EOQ). Aunque tiene más de un siglo de antigüedad, sigue siendo la brújula fundamental para dimensionar lotes de forma racional, asegurando que cada dólar invertido en logística esté justificado por un ahorro en costos operativos.\nPara entender la base de la optimización, primero debemos simplificar el caos. En este capítulo, trabajaremos en un “laboratorio determinista”. Aquí, el mundo es predecible, lo que nos permite aislar las fuerzas que mueven el costo total. Las reglas son:",
    "crumbs": [
      "IV: La Ciencia del Stock",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>12. El Paso del Pronóstico a la Orden</span>"
    ]
  },
  {
    "objectID": "cap-12-eoq-punto-reorden.html#el-escenario-determinista-las-reglas-del-juego",
    "href": "cap-12-eoq-punto-reorden.html#el-escenario-determinista-las-reglas-del-juego",
    "title": "12. El Paso del Pronóstico a la Orden",
    "section": "",
    "text": "Demanda Constante y Conocida (\\(D\\)): No hay sorpresas. Sabemos exactamente cuántas unidades se venderán por año y la tasa de consumo es uniforme cada día.\nLead Time Invariante (\\(L\\)): El proveedor es una máquina de precisión. Si dice que tarda 5 días, tarda exactamente 5 días.\nCosto de Pedido Fijo (\\(S\\)): Cada orden emitida genera un gasto administrativo y logístico constante.\nCosto de Mantenimiento Lineal (\\(h\\)): El “impuesto” por tener stock visto en el capítulo anterior.\nSin Quiebres de Stock: El objetivo es que el inventario llegue a cero justo cuando el camión del proveedor llega.",
    "crumbs": [
      "IV: La Ciencia del Stock",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>12. El Paso del Pronóstico a la Orden</span>"
    ]
  },
  {
    "objectID": "cap-12-eoq-punto-reorden.html#el-tamaño-de-lote-económico-eoq",
    "href": "cap-12-eoq-punto-reorden.html#el-tamaño-de-lote-económico-eoq",
    "title": "12. El Paso del Pronóstico a la Orden",
    "section": "12.2 El Tamaño de Lote Económico (EOQ)",
    "text": "12.2 El Tamaño de Lote Económico (EOQ)\nEl EOQ (Economic Order Quantity) responde a la pregunta arquitectónica: ¿Cuál es el tamaño óptimo de cada pedido?. No se trata de comprar “mucho” o “poco”, sino de encontrar el punto de equilibrio donde la eficiencia administrativa se encuentra con la eficiencia financiera.\n\n12.2.1 El Conflicto de Costos: La Gran Balanza\n\nSi pides mucho (Lotes gigantes): Realizas pocos pedidos al año (\\(S\\) mínimo). Sin embargo, tu inventario promedio será enorme, lo que disparará el costo de mantenimiento (\\(h\\)), ocupará todo tu almacén y asfixiará tu flujo de caja.\nSi pides poco (Lotes minúsculos): Tu inventario promedio será bajo, pero vivirás en un estado de “hiperactividad administrativa”. Tendrás que procesar cientos de órdenes, pagar fletes diarios y saturar al equipo de recepción, elevando el costo total de pedidos.\n\n\n\n12.2.2 La Fórmula Maestra y el Stock de Ciclo\nLa intersección de estas dos curvas de costo nos entrega la Raíz Cuadrada de Wilson:\n\\[EOQ = \\sqrt{\frac{2    imes D  imes S}{h}}\\]\nDonde: * \\(D\\): Demanda anual (unidades/año). * \\(S\\): Costo fijo de realizar un pedido ($ / pedido). * \\(h\\): Costo de mantenimiento anual por unidad ($/unidad/año).\nEl Concepto de Stock de Ciclo: En este modelo, tu inventario sigue un patrón de “dientes de sierra”. Comienzas con un lote completo (\\(EOQ\\)) y lo consumes linealmente. Por lo tanto, tu Inventario Promedio es exactamente \\(EOQ / 2\\).",
    "crumbs": [
      "IV: La Ciencia del Stock",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>12. El Paso del Pronóstico a la Orden</span>"
    ]
  },
  {
    "objectID": "cap-12-eoq-punto-reorden.html#el-punto-de-reorden-rop-la-gestión-del-tiempo",
    "href": "cap-12-eoq-punto-reorden.html#el-punto-de-reorden-rop-la-gestión-del-tiempo",
    "title": "12. El Paso del Pronóstico a la Orden",
    "section": "12.3 El Punto de Reorden (ROP): La Gestión del Tiempo",
    "text": "12.3 El Punto de Reorden (ROP): La Gestión del Tiempo\nYa definimos cuánto pedir (\\(EOQ\\)). Ahora debemos determinar el cuándo. El Punto de Reorden es el nivel de inventario que activa la señal de compra. Debe cubrir exactamente la demanda que ocurrirá durante el tiempo que el proveedor tarda en entregar (Lead Time).\n\\[ROP = d   imes L\\]\nDonde: * \\(d\\): Tasa de demanda diaria (Demanda anual / 365). * \\(L\\): Lead Time del proveedor en días.\n\n12.3.1 Posición de Inventario vs. Inventario Físico\nUn error común es mirar solo el inventario que está en el estante. El Arquitecto de Suministros mira la Posición de Inventario:\n\\[  ext{Posición} =     ext{Stock Físico} +     ext{Stock en Tránsito} -    ext{Backorders}\\]\nEl ROP debe compararse siempre contra la Posición de Inventario. Ignorar el tránsito es la receta perfecta para el exceso de inventario y la duplicidad de pedidos.",
    "crumbs": [
      "IV: La Ciencia del Stock",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>12. El Paso del Pronóstico a la Orden</span>"
    ]
  },
  {
    "objectID": "cap-12-eoq-punto-reorden.html#la-magia-de-la-raíz-cuadrada-la-robustez-del-eoq",
    "href": "cap-12-eoq-punto-reorden.html#la-magia-de-la-raíz-cuadrada-la-robustez-del-eoq",
    "title": "12. El Paso del Pronóstico a la Orden",
    "section": "12.4 La “Magia” de la Raíz Cuadrada: La Robustez del EOQ",
    "text": "12.4 La “Magia” de la Raíz Cuadrada: La Robustez del EOQ\nVandeput defiende con fervor la generosidad matemática del EOQ. Debido a que la fórmula utiliza una raíz cuadrada, si te equivocas al estimar el costo de pedido (\\(S\\)) o el costo de mantenimiento (\\(h\\)), el impacto financiero es menor de lo que parece.\n\nLa Curva Plana: El fondo de la curva de costo total es muy plano. Pedir un poco más o un poco menos del EOQ exacto apenas castiga el balance.\nEl Efecto Mitigador: Si sobreestimas el costo de orden en un 100%, tu \\(EOQ\\) solo se desviará un 41% (\\(\\sqrt{2} \u0007pprox 1.41\\)).",
    "crumbs": [
      "IV: La Ciencia del Stock",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>12. El Paso del Pronóstico a la Orden</span>"
    ]
  },
  {
    "objectID": "cap-12-eoq-punto-reorden.html#limitaciones-donde-el-modelo-choca-con-la-realidad",
    "href": "cap-12-eoq-punto-reorden.html#limitaciones-donde-el-modelo-choca-con-la-realidad",
    "title": "12. El Paso del Pronóstico a la Orden",
    "section": "12.5 Limitaciones: Donde el Modelo Choca con la Realidad",
    "text": "12.5 Limitaciones: Donde el Modelo Choca con la Realidad\nEl EOQ es la “física” del inventario, pero la realidad es caótica: 1. Variabilidad: La demanda nunca es constante. Necesitaremos un Stock de Seguridad (Capítulo 13). 2. Restricciones Logísticas: Redondear el EOQ a múltiplos de pallets o cajas. 3. Descuentos por Cantidad: El precio unitario baja al comprar más, alterando la balanza de \\(h\\) y \\(S\\).",
    "crumbs": [
      "IV: La Ciencia del Stock",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>12. El Paso del Pronóstico a la Orden</span>"
    ]
  },
  {
    "objectID": "cap-12-eoq-punto-reorden.html#aplicación-estratégica-según-segmentación",
    "href": "cap-12-eoq-punto-reorden.html#aplicación-estratégica-según-segmentación",
    "title": "12. El Paso del Pronóstico a la Orden",
    "section": "12.6 Aplicación Estratégica según Segmentación",
    "text": "12.6 Aplicación Estratégica según Segmentación\n\nProductos Clase A: Calcule el EOQ mensualmente. La precisión aquí libera millones en capital de trabajo.\nProductos Clase C: No pierda tiempo analítico. Use el EOQ para justificar compras de largo plazo (ej. pedir una vez cada 6 meses) y libere capacidad operativa.\n\n\n\n\n\n\n\nImportantLa Parsimonia en el Lote\n\n\n\nEl mayor valor estratégico del EOQ no es el número exacto, sino demostrar que pedir más seguido no siempre es mejor. Si tus costos de transporte son altos, la eficiencia exige lotes más grandes.",
    "crumbs": [
      "IV: La Ciencia del Stock",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>12. El Paso del Pronóstico a la Orden</span>"
    ]
  },
  {
    "objectID": "cap-12-eoq-punto-reorden.html#checklist-de-cierre-del-capítulo",
    "href": "cap-12-eoq-punto-reorden.html#checklist-de-cierre-del-capítulo",
    "title": "12. El Paso del Pronóstico a la Orden",
    "section": "Checklist de Cierre del Capítulo",
    "text": "Checklist de Cierre del Capítulo\n\n¿He auditado cuánto cuesta realmente procesar un pedido (\\(S\\))?\n¿He calculado el EOQ para mis 20 productos con mayor impacto en capital?\n¿He verificado que mi ROP considera el stock en tránsito?\n¿Entiendo que en este modelo el stock promedio es \\(EOQ/2\\)?\n¿Estoy listo para introducir el error de pronóstico (RMSE) en el próximo capítulo?",
    "crumbs": [
      "IV: La Ciencia del Stock",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>12. El Paso del Pronóstico a la Orden</span>"
    ]
  },
  {
    "objectID": "cap-13-stock-seguridad.html",
    "href": "cap-13-stock-seguridad.html",
    "title": "13. Bienvenidos al Mundo Estocástico",
    "section": "",
    "text": "13.1 ¿Qué es realmente el Stock de Seguridad?\nEn el Capítulo 12, exploramos el “mundo determinista”, un laboratorio donde la demanda es una línea recta y el proveedor nunca falla. En ese escenario, el inventario es sencillo: pides exactamente lo que vas a vender y llega justo a tiempo. Sin embargo, si has trabajado más de un día en una cadena de suministro real, sabes que ese mundo es una utopía.\nLa realidad es Estocástica (aleatoria y probabilística). La demanda real rara vez coincide con tu pronóstico de punto, y el Lead Time de tu proveedor suele ser una sugerencia optimista más que una promesa inquebrantable. Aquí es donde entra el Stock de Seguridad (SS): el colchón diseñado no para cubrir lo que sabemos que va a pasar, sino para protegernos de lo que no podemos prever. En este capítulo, aprenderemos a calcular este escudo usando la ciencia de la probabilidad y conectándolo con el error de los modelos que construimos en la Parte III.\nEl Stock de Seguridad no debe verse como “inventario extra” o “por si acaso”. En la mente de un Arquitecto de Suministros, el SS es una inversión de capital destinada a comprar una póliza de seguro contra dos variabilidades críticas:\nLa Regla de Oro de Vandeput: El Stock de Seguridad no debe calcularse sobre el volumen total de la demanda, sino sobre el Error del Pronóstico. Este es un cambio de paradigma vital. Si tu pronóstico es perfecto (Error = 0), no necesitas stock de seguridad. El SS es el castigo económico por la imperfección de tus modelos.",
    "crumbs": [
      "IV: La Ciencia del Stock",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>13. Bienvenidos al Mundo Estocástico</span>"
    ]
  },
  {
    "objectID": "cap-13-stock-seguridad.html#qué-es-realmente-el-stock-de-seguridad",
    "href": "cap-13-stock-seguridad.html#qué-es-realmente-el-stock-de-seguridad",
    "title": "13. Bienvenidos al Mundo Estocástico",
    "section": "",
    "text": "Variabilidad de la Demanda: La diferencia entre lo que el modelo predijo y lo que el mercado realmente pidió.\nVariabilidad del Lead Time: La incertidumbre sobre si el camión llegará en 5 días o en 12 debido a factores logísticos.",
    "crumbs": [
      "IV: La Ciencia del Stock",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>13. Bienvenidos al Mundo Estocástico</span>"
    ]
  },
  {
    "objectID": "cap-13-stock-seguridad.html#los-ingredientes-de-la-receta-estocástica",
    "href": "cap-13-stock-seguridad.html#los-ingredientes-de-la-receta-estocástica",
    "title": "13. Bienvenidos al Mundo Estocástico",
    "section": "13.2 Los Ingredientes de la Receta Estocástica",
    "text": "13.2 Los Ingredientes de la Receta Estocástica\nPara dimensionar este colchón sin asfixiar el flujo de caja, necesitamos tres palancas de riesgo:\n\n13.2.1 La Incertidumbre (\\(\\sigma\\)): El rol del RMSE\nEn la ciencia del stock, el RMSE (Root Mean Squared Error) calculado en capítulos anteriores es nuestra medida de la desviación estándar del error (\\(\\sigma_{error}\\)). * Implicación: Si tu modelo de XGBoost redujo el RMSE en un 20%, tu inversión en inventario de seguridad puede reducirse en una proporción similar.\n\n\n13.2.2 El Tiempo de Exposición (\\(L\\)): La Raíz Cuadrada del Tiempo\nLa incertidumbre crece con el tiempo, pero no de forma lineal. Matemáticamente, el riesgo crece con la raíz cuadrada del Lead Time (\\(\\sqrt{L}\\)). Esto se debe a que los errores diarios tienden a cancelarse parcialmente entre sí.\n\n\n13.2.3 El Factor de Servicio (\\(k\\)): Tu Apetito al Riesgo\nEl factor \\(k\\) representa cuántas desviaciones estándar quieres cubrir. Este valor sale de la Distribución Normal y define tu Nivel de Servicio (Cycle Service Level).",
    "crumbs": [
      "IV: La Ciencia del Stock",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>13. Bienvenidos al Mundo Estocástico</span>"
    ]
  },
  {
    "objectID": "cap-13-stock-seguridad.html#la-ecuación-maestra-del-stock-de-seguridad",
    "href": "cap-13-stock-seguridad.html#la-ecuación-maestra-del-stock-de-seguridad",
    "title": "13. Bienvenidos al Mundo Estocástico",
    "section": "13.3 La Ecuación Maestra del Stock de Seguridad",
    "text": "13.3 La Ecuación Maestra del Stock de Seguridad\nCombinando estos factores, llegamos a la fórmula fundamental:\n\\[SS = k    imes \\sigma_{error}     imes \\sqrt{L}\\]\nDonde: * \\(k\\): Factor de servicio (ej. 1.65 para un 95% de nivel de servicio). * \\(\\sigma_{error}\\): Desviación estándar del error (RMSE del modelo). * \\(L\\): Lead Time expresado en las mismas unidades que el error.\n\n13.3.1 Análisis de Sensibilidad Financiera\nPara un producto con RMSE mensual de 500 unidades y Lead Time de 1 mes: * 90% SL (\\(k=1.28\\)): \\(SS = 640  ext{ unidades}\\). * 99.9% SL (\\(k=3.09\\)): \\(SS = 1,545  ext{ unidades}\\). Implicación: La perfección financiera es costosa; proteger ese último 10% requiere casi triplicar el inventario.",
    "crumbs": [
      "IV: La Ciencia del Stock",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>13. Bienvenidos al Mundo Estocástico</span>"
    ]
  },
  {
    "objectID": "cap-13-stock-seguridad.html#la-tiranía-del-nivel-de-servicio-rendimientos-decrecientes",
    "href": "cap-13-stock-seguridad.html#la-tiranía-del-nivel-de-servicio-rendimientos-decrecientes",
    "title": "13. Bienvenidos al Mundo Estocástico",
    "section": "13.4 La Tiranía del Nivel de Servicio: Rendimientos Decrecientes",
    "text": "13.4 La Tiranía del Nivel de Servicio: Rendimientos Decrecientes\nEl costo de la perfección es infinito. Debido a la campana de Gauss, protegerse contra eventos extremos requiere volúmenes masivos de stock. * Estrategia ABC: * Clase A: \\(k\\) alto (Protección premium). * Clase C: \\(k\\) bajo (Aceptamos quiebres para salvar flujo de caja).",
    "crumbs": [
      "IV: La Ciencia del Stock",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>13. Bienvenidos al Mundo Estocástico</span>"
    ]
  },
  {
    "objectID": "cap-13-stock-seguridad.html#integración-el-rop-estocástico",
    "href": "cap-13-stock-seguridad.html#integración-el-rop-estocástico",
    "title": "13. Bienvenidos al Mundo Estocástico",
    "section": "13.5 Integración: El ROP Estocástico",
    "text": "13.5 Integración: El ROP Estocástico\nEl Punto de Reorden evoluciona para incluir el escudo contra lo inesperado:\n\\[ROP = (d  imes L) + SS\\]\nDonde \\((d   imes L)\\) es el consumo previsto y \\(SS\\) es tu margen de error.",
    "crumbs": [
      "IV: La Ciencia del Stock",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>13. Bienvenidos al Mundo Estocástico</span>"
    ]
  },
  {
    "objectID": "cap-13-stock-seguridad.html#la-variabilidad-del-lead-time-el-enemigo-oculto",
    "href": "cap-13-stock-seguridad.html#la-variabilidad-del-lead-time-el-enemigo-oculto",
    "title": "13. Bienvenidos al Mundo Estocástico",
    "section": "13.6 La Variabilidad del Lead Time: El Enemigo Oculto",
    "text": "13.6 La Variabilidad del Lead Time: El Enemigo Oculto\nSi tu proveedor es inestable (\\(\\sigma_L\\)), la incertidumbre se expande. A menudo es más rentable negociar un Lead Time estable con el proveedor que intentar mejorar el algoritmo de pronóstico.\n\n\n\n\n\n\nImportantLa Trampa de la Normalidad\n\n\n\nLa mayoría de los softwares asumen una Distribución Normal. Si tu demanda tiene “colas pesadas” (picos extremos frecuentes), el SS calculado será insuficiente. En esos casos, recurrimos al Pronóstico Probabilístico (Capítulo 14).",
    "crumbs": [
      "IV: La Ciencia del Stock",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>13. Bienvenidos al Mundo Estocástico</span>"
    ]
  },
  {
    "objectID": "cap-13-stock-seguridad.html#checklist-de-cierre-del-capítulo",
    "href": "cap-13-stock-seguridad.html#checklist-de-cierre-del-capítulo",
    "title": "13. Bienvenidos al Mundo Estocástico",
    "section": "Checklist de Cierre del Capítulo",
    "text": "Checklist de Cierre del Capítulo\n\n¿He extraído el RMSE final de mis modelos de la Parte III?\n¿He definido niveles de servicio diferenciados por segmentación ABC?\n¿He calculado el costo anual de mantener mi stock de seguridad (\\(SS   imes h\\))?\n¿Soy capaz de explicar por qué un nivel de servicio del 100% es financieramente irresponsable?",
    "crumbs": [
      "IV: La Ciencia del Stock",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>13. Bienvenidos al Mundo Estocástico</span>"
    ]
  },
  {
    "objectID": "cap-14-demandas-erraticas.html",
    "href": "cap-14-demandas-erraticas.html",
    "title": "14. Más allá de la Curva Normal",
    "section": "",
    "text": "14.1 La Anatomía del Caos: Clasificación de Demanda\nEn el Capítulo 13, aprendimos a calcular el Stock de Seguridad utilizando el factor \\(k\\) y la desviación estándar del error. Sin embargo, esa fórmula descansa sobre una suposición cómoda pero frecuentemente falsa: que los errores de demanda siguen una Distribución Normal (la famosa campana de Gauss). Esta suposición es el “pecado original” de muchos softwares de ERP y sistemas de planificación tradicionales, y es la razón por la cual muchas empresas tienen estanterías llenas de productos que no rotan y quiebres constantes en los que sí.\nPara un producto de alta rotación y volumen masivo (Clase A), como la leche en un supermercado o los consumibles de oficina estándar, la distribución normal funciona aceptablemente bien. Esto sucede gracias al Teorema del Límite Central: cuando sumas muchos eventos independientes, el resultado tiende a parecerse a una campana. Pero, ¿qué pasa con ese repuesto industrial que se vende una vez cada tres meses? ¿O con ese artículo de lujo que tiene pedidos erráticos de gran volumen? Si intentas aplicar la “campana de Gauss” a estos productos, estarás navegando con una brújula rota.\nEn este capítulo, romperemos el mito de la normalidad y entenderemos por qué la Distribución Gamma es el verdadero salvador del capital de trabajo en la “Larga Cola” de productos intermitentes.\nAntes de elegir un algoritmo, debemos diagnosticar la “física” de nuestra serie de tiempo. No todos los errores son iguales, y tratarlos como tales es una receta para el desastre financiero. Para ello, utilizamos dos métricas que Nicolas Vandeput considera fundamentales para separar la señal del ruido:",
    "crumbs": [
      "IV: La Ciencia del Stock",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>14. Más allá de la Curva Normal</span>"
    ]
  },
  {
    "objectID": "cap-14-demandas-erraticas.html#la-anatomía-del-caos-clasificación-de-demanda",
    "href": "cap-14-demandas-erraticas.html#la-anatomía-del-caos-clasificación-de-demanda",
    "title": "14. Más allá de la Curva Normal",
    "section": "",
    "text": "ADI (Average Demand Interval): Mide la frecuencia temporal. Es el número promedio de periodos entre dos eventos de demanda.\n\nCálculo: $ ext{ADI} = \frac{ ext{Total de periodos}}{ ext{Número de periodos con demanda}}$.\nEjemplo: Si en 10 semanas vendes en las semanas 2, 5 y 8, has tenido 3 ventas en 10 semanas. Tu ADI es \\(10 / 3 = 3.33\\). Un ADI superior a 1.32 suele indicar que la demanda está empezando a ser intermitente y la campana de Gauss empieza a “romperse”.\n\n\\(CV^2\\) (Coefficient of Variation Squared): Mide la variabilidad del tamaño del pedido. Nos dice si, cuando el cliente compra, el volumen es predecible o una sorpresa total.\n\nCálculo: \\(CV^2 = \\left( \frac{\\sigma}{\\mu}\night)^2\\).\nUn \\(CV^2\\) superior a 0.49 indica que la demanda es altamente errática en volumen, lo que significa que incluso si sabes cuándo vendrá el cliente, no tienes idea de cuánto pedirá.\n\n\n\n14.1.1 La Matriz de Syntetos-Boylan: Mapa de Navegación\nDependiendo de estos valores, clasificamos los productos en cuatro cuadrantes críticos, cada uno con una estrategia de inventario distinta:\n\nSmooth (Suave): ADI &lt; 1.32, \\(CV^2\\) &lt; 0.49. La demanda ocurre casi siempre y en cantidades similares.\nErratic (Errática): ADI &lt; 1.32, \\(CV^2\\) &gt; 0.49. El cliente siempre está ahí, pero el volumen es una montaña rusa.\nIntermittent (Intermitente): ADI &gt; 1.32, \\(CV^2\\) &lt; 0.49. Sabes cuánto pedirán, pero no cuándo aparecerán.\nLumpy (A bultos): ADI &gt; 1.32, \\(CV^2\\) &gt; 0.49. El peor escenario. No sabes cuándo vendrá el cliente, ni cuánto pedirá. Es el territorio donde el capital de trabajo muere sin la Distribución Gamma.",
    "crumbs": [
      "IV: La Ciencia del Stock",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>14. Más allá de la Curva Normal</span>"
    ]
  },
  {
    "objectID": "cap-14-demandas-erraticas.html#el-duelo-normal-vs.-gamma",
    "href": "cap-14-demandas-erraticas.html#el-duelo-normal-vs.-gamma",
    "title": "14. Más allá de la Curva Normal",
    "section": "14.2 El Duelo: Normal vs. Gamma",
    "text": "14.2 El Duelo: Normal vs. Gamma\nElegir la distribución de probabilidad correcta no es un detalle técnico; es una decisión de inversión de capital que afecta directamente tu ROIC (Retorno sobre el Capital Invertido).\n\n14.2.1 El Lado Oscuro de Gauss en Supply Chain\nLa campana de Gauss es simétrica. Esto implica que la probabilidad de que la demanda sea 10 unidades por encima de la media es idéntica a la probabilidad de que sea 10 unidades por debajo. Esto genera dos errores fatales:\n\nLa Aberración Negativa: En productos lentos (media de 1 unidad), la curva normal asigna probabilidad a valores negativos. Como en el almacén no podemos tener “-2 cajas”, el sistema simplemente ignora esa parte de la curva, resultando en un stock de seguridad que subestima el riesgo real.\nColas Delgadas (Thin Tails): La Normal asume que los pedidos gigantes son imposibles. En la realidad de la Clase C, los pedidos masivos ocurren más a menudo de lo que Gauss predice. Confiar en la Normal es como construir un dique ignorando que el río puede desbordarse.\n\n\n\n14.2.2 Por qué la Distribución Gamma es la “Liga Adaptativa”\nLa Gamma es una distribución asimétrica que solo existe para valores positivos (de 0 a infinito). * Se adapta a la forma: Si el producto es rápido, la Gamma se comporta como una Normal. Si el producto es lento o intermitente, la Gamma se “encoge” hacia el cero y extiende una cola larga hacia la derecha (capturando el riesgo de pedidos grandes). * Consecuencia Financiera: Al usar Gamma para calcular el stock de seguridad en productos Clase B y C, logras la misma disponibilidad que con la Normal pero invirtiendo entre un 15% y un 25% menos de capital.",
    "crumbs": [
      "IV: La Ciencia del Stock",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>14. Más allá de la Curva Normal</span>"
    ]
  },
  {
    "objectID": "cap-14-demandas-erraticas.html#el-método-de-croston-y-la-mejora-sba",
    "href": "cap-14-demandas-erraticas.html#el-método-de-croston-y-la-mejora-sba",
    "title": "14. Más allá de la Curva Normal",
    "section": "14.3 El Método de Croston y la Mejora SBA",
    "text": "14.3 El Método de Croston y la Mejora SBA\nCuando el historial tiene muchos ceros, los modelos tradicionales (como el Suavizamiento Exponencial Simple) “colapsan”.\nEl modelo de Croston (1972) solucionó esto al desacoplar la demanda en dos canales de información que se actualizan solo cuando hay una venta: 1. Nivel de Demanda (\\(z_t\\)): ¿Cuánto piden cuando deciden comprar? 2. Intervalo entre Pedidos (\\(p_t\\)): ¿Cuál es la frecuencia de compra?\nEl pronóstico final es \\(\\hat{y} = z_t / p_t\\). La aproximación SBA (Syntetos-Boylan) corrige un ligero sesgo positivo de Croston, siendo hoy el estándar para gestionar la “Larga Cola” de materiales de mantenimiento, repuestos y artículos de lujo.",
    "crumbs": [
      "IV: La Ciencia del Stock",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>14. Más allá de la Curva Normal</span>"
    ]
  },
  {
    "objectID": "cap-14-demandas-erraticas.html#el-camino-hacia-el-pronóstico-probabilístico",
    "href": "cap-14-demandas-erraticas.html#el-camino-hacia-el-pronóstico-probabilístico",
    "title": "14. Más allá de la Curva Normal",
    "section": "14.4 El Camino hacia el Pronóstico Probabilístico",
    "text": "14.4 El Camino hacia el Pronóstico Probabilístico\nAquí es donde el Arquitecto de Suministros abandona el “número único” (Single Point Forecast). En demandas erráticas, predecir “venderemos 5 unidades” es una mentira estadística que nadie cree. Lo que necesitamos es un mapa de densidades de probabilidad.\nEn lugar de la media, empezamos a hablar de Cuantiles: * P50 (Mediana): El valor central del riesgo. * P95 (Objetivo): El nivel que protege contra el 95% de la incertidumbre.\nAl usar modelos de Machine Learning que entregan cuantiles, estamos aplicando la lógica de la distribución Gamma de forma automática. Esto nos permite optimizar el inventario basándonos en el Costo de Oportunidad.",
    "crumbs": [
      "IV: La Ciencia del Stock",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>14. Más allá de la Curva Normal</span>"
    ]
  },
  {
    "objectID": "cap-14-demandas-erraticas.html#implicaciones-en-la-gestión-de-inventarios",
    "href": "cap-14-demandas-erraticas.html#implicaciones-en-la-gestión-de-inventarios",
    "title": "14. Más allá de la Curva Normal",
    "section": "14.5 Implicaciones en la Gestión de Inventarios",
    "text": "14.5 Implicaciones en la Gestión de Inventarios\nEste capítulo cambia las reglas del juego para lo que viene: * En el Capítulo 15: Veremos cómo la incertidumbre del Lead Time se suma a esta demanda no-normal. * En el Capítulo 16: Aprenderemos que si la demanda es Gamma, tu política de reaprovisionamiento debe basarse en la probabilidad de faltante.\n\n\n\n\n\n\nImportant¿Gamma para todo? El Criterio del Arquitecto\n\n\n\nNo, la complejidad debe ser una inversión, no un pasatiempo. 1. Clase A / Smooth: Usa la Normal. 2. Clase B / Errática: Evalúa el \\(CV^2\\). Si es alto, la Gamma te ahorrará miles en capital de trabajo. 3. Clase C / Lumpy / Intermittent: Usa Gamma o Poisson sin dudarlo.",
    "crumbs": [
      "IV: La Ciencia del Stock",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>14. Más allá de la Curva Normal</span>"
    ]
  },
  {
    "objectID": "cap-14-demandas-erraticas.html#checklist-de-cierre-del-capítulo",
    "href": "cap-14-demandas-erraticas.html#checklist-de-cierre-del-capítulo",
    "title": "14. Más allá de la Curva Normal",
    "section": "Checklist de Cierre del Capítulo",
    "text": "Checklist de Cierre del Capítulo\n\n¿He clasificado mi catálogo usando ADI y \\(CV^2\\)?\n¿He identificado los productos donde la Distribución Normal sugiere niveles de stock absurdos?\n¿He implementado Croston o SBA para mis repuestos de baja rotación?\n¿He comparado la inversión en SS usando Gamma vs Normal en mi Clase B y C?\n¿He empezado a hablar de cuantiles de riesgo (P90, P95) con los stakeholders?",
    "crumbs": [
      "IV: La Ciencia del Stock",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>14. Más allá de la Curva Normal</span>"
    ]
  },
  {
    "objectID": "cap-15-monte-carlo.html",
    "href": "cap-15-monte-carlo.html",
    "title": "15. El Laboratorio Virtual",
    "section": "",
    "text": "15.1 El Fracaso de las Fórmulas Cerradas y la Tiranía de los Promedios\nHasta ahora, hemos tratado la Supply Chain como una serie de piezas de relojería que se pueden ajustar con fórmulas aisladas: un modelo para la demanda, una raíz cuadrada para el lote económico y un factor \\(k\\) para el stock de seguridad. Sin embargo, en la práctica profesional, estas piezas no operan de forma estática. Están conectadas por hilos invisibles de dependencia, retroalimentación y, sobre todo, por una entropía que las fórmulas deterministas no pueden capturar.\nEn esta Parte V, dejamos de ver la cadena de suministro como una serie de ecuaciones y empezamos a verla como un Sistema Complejo. Ya no buscaremos la “fórmula perfecta”, sino la política más robusta. El mundo real no es un examen de matemáticas; es un laboratorio de caos donde lo que importa es la resiliencia del flujo de caja ante lo inesperado. Aquí es donde la simulación toma el relevo de la estadística pura.\nSi el Capítulo 13 era la “receta” del stock de seguridad, este capítulo es la “cocina de pruebas”. La Simulación de Monte Carlo es la herramienta definitiva del Arquitecto de Suministros para responder a la pregunta más difícil de la gerencia: “¿Qué pasa si…?”.\nEn Supply Chain, la incertidumbre no se suma, se multiplica. ¿Qué pasa si el puerto entra en huelga? ¿Qué pasa si el proveedor asiático se retrasa dos semanas pero la demanda nacional explota por una ola de calor? En lugar de adivinar o confiar en la “intuición” (que suele ser el nombre que le damos a nuestros sesgos), vamos a construir un laboratorio virtual para estresar nuestras políticas de inventario antes de arriesgar un solo dólar en el mundo físico.\nLas fórmulas de inventario tradicionales (vistas en la Parte IV) asumen un mundo de “comportamiento ideal”. El problema es que los promedios engañan de forma sistemática. Como bien dice la metáfora: “Un río que tiene una profundidad promedio de 1 metro puede tener una fosa de 5 metros en el medio; si intentas cruzarlo confiando en el promedio, te ahogarás”.\nLas fórmulas analíticas fallan en la práctica por tres razones sistémicas:\nLa Realidad de Vandeput: Cuando intentas optimizar un portafolio masivo con interacciones complejas, las fórmulas matemáticas “explotan”. La simulación de Monte Carlo no intenta resolver una ecuación compleja; simplemente imita la realidad miles de veces y observa qué sucede.",
    "crumbs": [
      "V: Simulaciones y Redes Complejas",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>15. El Laboratorio Virtual</span>"
    ]
  },
  {
    "objectID": "cap-15-monte-carlo.html#el-fracaso-de-las-fórmulas-cerradas-y-la-tiranía-de-los-promedios",
    "href": "cap-15-monte-carlo.html#el-fracaso-de-las-fórmulas-cerradas-y-la-tiranía-de-los-promedios",
    "title": "15. El Laboratorio Virtual",
    "section": "",
    "text": "La Dictadura de la Normalidad: Creen que la demanda es una campana simétrica, ignorando los picos extremos de la “Larga Cola” y los periodos de venta cero que caracterizan a los productos Clase C.\nLa Maldición de la Independencia: Suponen que la demanda y el Lead Time no tienen relación. En la realidad, existe una correlación positiva: cuando la demanda sube en toda la industria, los transportistas se saturan, los puertos se congestionan y el Lead Time también aumenta. Las fórmulas de la Parte IV no ven esta tormenta perfecta; la simulación sí.\nRestricciones de la Vida Real: Las fórmulas no saben qué hacer con los pedidos mínimos (MOQ), las capacidades limitadas de los camiones o los límites de espacio en bodega. Un modelo matemático puede sugerir pedir 412 unidades, pero si el proveedor solo vende pallets de 500, la fórmula “teórica” deja de tener sentido financiero.",
    "crumbs": [
      "V: Simulaciones y Redes Complejas",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>15. El Laboratorio Virtual</span>"
    ]
  },
  {
    "objectID": "cap-15-monte-carlo.html#la-mecánica-de-monte-carlo-el-azar-bajo-control",
    "href": "cap-15-monte-carlo.html#la-mecánica-de-monte-carlo-el-azar-bajo-control",
    "title": "15. El Laboratorio Virtual",
    "section": "15.2 La Mecánica de Monte Carlo: El Azar Bajo Control",
    "text": "15.2 La Mecánica de Monte Carlo: El Azar Bajo Control\nLa simulación se basa en la Ley de los Grandes Números. Si repetimos un experimento de inventario suficientes veces, la distribución de los resultados finales convergerá hacia el riesgo real que enfrentará la empresa en el mercado.\n\n15.2.1 El Algoritmo del Arquitecto\nPara construir este laboratorio, seguimos un proceso de cuatro pasos:\n\nModelado de Insumos Estocásticos: En lugar de usar un promedio de demanda, definimos una distribución (Gamma para demanda lumpy, Poisson para intermitente). El Lead Time tampoco es un número; es un histograma de frecuencias basado en los últimos 2 años de desempeño real del proveedor.\nMuestreo Aleatorio (Lanzamiento de Dados): En cada iteración de la simulación, el motor lanza “dados virtuales”. En un escenario, el azar dicta una demanda altísima y un transporte lentísimo (el peor caso). En otro, la demanda es baja y la entrega es inmediata.\nEjecución de la Política Logística: Para cada escenario generado, el código aplica las reglas de negocio estrictas: “Si el inventario neto &lt; ROP, emitir orden de compra por tamaño Q”.\nAgregación Estadística: Al final de 10,000 “vidas” simuladas, recolectamos los KPIs. Esto nos permite ver no solo el promedio, sino el Riesgo de Cola (P95): “En el 5% de los peores casos, perderemos más de $50,000 en margen por falta de producto”.",
    "crumbs": [
      "V: Simulaciones y Redes Complejas",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>15. El Laboratorio Virtual</span>"
    ]
  },
  {
    "objectID": "cap-15-monte-carlo.html#el-verdadero-villano-la-variabilidad-del-lead-time",
    "href": "cap-15-monte-carlo.html#el-verdadero-villano-la-variabilidad-del-lead-time",
    "title": "15. El Laboratorio Virtual",
    "section": "15.3 El Verdadero Villano: La Variabilidad del Lead Time",
    "text": "15.3 El Verdadero Villano: La Variabilidad del Lead Time\nUno de los mayores aportes de la simulación es desenmascarar al verdadero asesino del nivel de servicio: la variabilidad de la entrega. En las fórmulas tradicionales, el Lead Time es una constante lineal. En el laboratorio virtual, vemos que el retraso del proveedor es financieramente mucho más destructivo que una mala predicción de demanda.\n\nEl Efecto Látigo en la Simulación: Podemos observar cómo una desviación de 2 días en la materia prima se amplifica a través del sistema hasta convertirse en un quiebre total de 15 días en el producto terminado.\nModelado de “Cisnes Negros”: Monte Carlo permite inyectar disrupciones de baja frecuencia pero alto impacto. Podemos programar que, con una probabilidad del 0.1% (una vez cada 1000 días), el Lead Time sea de 90 días debido a una crisis global. Esto permite calcular la Resiliencia de la Red, algo que ninguna hoja de cálculo puede hacer.",
    "crumbs": [
      "V: Simulaciones y Redes Complejas",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>15. El Laboratorio Virtual</span>"
    ]
  },
  {
    "objectID": "cap-15-monte-carlo.html#probando-políticas-de-inventario-el-duelo-s-q-vs-s-s",
    "href": "cap-15-monte-carlo.html#probando-políticas-de-inventario-el-duelo-s-q-vs-s-s",
    "title": "15. El Laboratorio Virtual",
    "section": "15.4 Probando Políticas de Inventario: El Duelo (\\(s, Q\\)) vs (\\(s, S\\))",
    "text": "15.4 Probando Políticas de Inventario: El Duelo (\\(s, Q\\)) vs (\\(s, S\\))\nEn el laboratorio virtual, podemos enfrentar diferentes estrategias de reaprovisionamiento para ver cuál protege mejor el flujo de caja:\n\nPolítica de Cantidad Fija (\\(s, Q\\)): Basada en el EOQ. Es rígida. Pedimos lo mismo sin importar qué tan bajo esté el stock. La simulación suele mostrar que esta política es ineficiente si la demanda es muy errática porque genera “ecos” de inventario innecesarios.\nPolítica de Nivel Máximo (\\(s, S\\)): Es adaptativa (Order-to-Up-To). Pedimos lo necesario para llegar a un nivel máximo \\(S\\). La simulación revela que, aunque requiere más gestión administrativa, esta política reduce significativamente el inventario promedio manteniendo el mismo nivel de servicio.\n\nLa Ventaja del Arquitecto: No tienes que “creerle” a la teoría de los libros. El simulador te muestra los dólares ahorrados y el impacto en el capital de trabajo de cada política bajo miles de futuros posibles.",
    "crumbs": [
      "V: Simulaciones y Redes Complejas",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>15. El Laboratorio Virtual</span>"
    ]
  },
  {
    "objectID": "cap-15-monte-carlo.html#kpis-estratégicos-más-allá-del-wape",
    "href": "cap-15-monte-carlo.html#kpis-estratégicos-más-allá-del-wape",
    "title": "15. El Laboratorio Virtual",
    "section": "15.5 KPIs Estratégicos: Más allá del WAPE",
    "text": "15.5 KPIs Estratégicos: Más allá del WAPE\nA diferencia de un modelo estadístico que te da una estimación de error, el simulador te entrega métricas operativas directas y auditables por la dirección financiera:\n\nFill Rate Observado: El porcentaje real de las unidades pedidas por el cliente que pudimos satisfacer.\nCosto de Mantenimiento Real: Basado en el inventario promedio segundo a segundo, incluyendo picos de saturación.\nDías de Inventario (DOI): Velocidad real de rotación del capital en el almacén.\nValor en Riesgo (VaR) Logístico: La pérdida máxima esperada en un horizonte de tiempo con un nivel de confianza dado (ej. 95%). Es el lenguaje que entiende el CFO.",
    "crumbs": [
      "V: Simulaciones y Redes Complejas",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>15. El Laboratorio Virtual</span>"
    ]
  },
  {
    "objectID": "cap-15-monte-carlo.html#implementación-en-r-el-motor-de-simulación",
    "href": "cap-15-monte-carlo.html#implementación-en-r-el-motor-de-simulación",
    "title": "15. El Laboratorio Virtual",
    "section": "15.6 Implementación en R: El Motor de Simulación",
    "text": "15.6 Implementación en R: El Motor de Simulación\nR es el lenguaje ideal para este laboratorio debido a su manejo nativo de distribuciones de probabilidad y su sintaxis orientada a datos vectorizados. Aquí el esquema de cómo estructuramos el motor profesional:\n# Motor de Simulación de Monte Carlo en R\nlibrary(tidyverse)\n\nsimular_politica_inventario &lt;- function(iteraciones = 10000, ROP = 200, Q = 500) {\n  resultados &lt;- map_df(1:iteraciones, function(id) {\n    # 1. Escenario Estocástico: Demanda Gamma (Cap 14) y Lead Time Poisson\n    demanda_realizada &lt;- rgamma(1, shape = 2, scale = 40) \n    lt_realizado &lt;- rpois(1, lambda = 8) \n    \n    # 2. Estado del Sistema\n    inv_inicial &lt;- 250\n    inv_final &lt;- max(0, inv_inicial - demanda_realizada)\n    \n    # 3. KPIs del Ciclo\n    quiebre &lt;- ifelse(demanda_realizada &gt; inv_inicial, 1, 0)\n    unidades_perdidas &lt;- max(0, demanda_realizada - inv_inicial)\n    \n    return(tibble(\n      escenario = id,\n      quiebre_stock = quiebre,\n      venta_perdida = unidades_perdidas,\n      inv_promedio = (inv_inicial + inv_final) / 2\n    ))\n  })\n  return(resultados)\n}\n\n# Ejecución del Laboratorio\ndata_simulada &lt;- simular_politica_inventario()\n\n# Análisis de Riesgo de Cola (P95 de ventas perdidas)\nquantile(data_simulada$venta_perdida, 0.95)\n\n\n\n\n\n\nImportantLa Sabiduría de Monte Carlo\n\n\n\nLa simulación no es para encontrar “el número mágico”, es para entender el rango de posibilidades. Como arquitectos de suministros, no diseñamos para el “día promedio”; diseñamos para que la cadena de suministro soporte la variabilidad sin colapsar financieramente. Si tu política de inventarios no ha sido probada en un simulador, es solo una teoría esperando a ser refutada por la realidad del mercado.",
    "crumbs": [
      "V: Simulaciones y Redes Complejas",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>15. El Laboratorio Virtual</span>"
    ]
  },
  {
    "objectID": "cap-15-monte-carlo.html#checklist-de-cierre-del-capítulo",
    "href": "cap-15-monte-carlo.html#checklist-de-cierre-del-capítulo",
    "title": "15. El Laboratorio Virtual",
    "section": "Checklist de Cierre del Capítulo",
    "text": "Checklist de Cierre del Capítulo\n\n¿He definido distribuciones de probabilidad (Gamma/Poisson) basadas en mis datos de los Capítulos 7 y 14?\n¿He modelado el Lead Time como una distribución y no como un número fijo?\n¿He corrido al menos 10,000 iteraciones para asegurar que los resultados sean estadísticamente significativos?\n¿He calculado el Valor en Riesgo (VaR) de mi política actual?\n¿He comparado los resultados de la simulación contra el cálculo estático para medir el FVA de la simulación?",
    "crumbs": [
      "V: Simulaciones y Redes Complejas",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>15. El Laboratorio Virtual</span>"
    ]
  },
  {
    "objectID": "cap-16-efecto-domino-meio.html",
    "href": "cap-16-efecto-domino-meio.html",
    "title": "16. El Efecto Dominó",
    "section": "",
    "text": "16.1 La Física de la Distorsión: El Efecto Látigo (Bullwhip Effect)\nEn los capítulos anteriores, nos convertimos en maestros de la optimización local. Aprendimos a calcular el stock de seguridad perfecto para un nodo y el lote económico para un proveedor. Sin embargo, en la Supply Chain moderna, ningún almacén es una isla independiente. Tu Centro de Distribución (CD) alimenta a diez bodegas regionales, que a su vez surten a cientos de tiendas o clientes finales.\nSi optimizas cada punto de forma aislada, estás cometiendo un error sistémico grave: la Sub-optimización Local. Lo que parece una decisión brillante para el jefe de la Bodega A (como pedir lotes gigantes para ahorrar un 5% en flete) puede ser una catástrofe financiera para la Fábrica, al generar picos de producción artificiales que saturan las máquinas y destruyen la planificación. En este capítulo, aprenderemos a ver la red como un organismo vivo y a implementar la Optimización de Inventarios Multi-escalón (MEIO).\nEl Efecto Látigo es el fenómeno donde pequeñas fluctuaciones en la demanda del consumidor final se transforman en oscilaciones violentas y erráticas a medida que la señal viaja hacia atrás en la cadena (aguas arriba). Una variación del 5% en la venta semanal de una tienda puede llegar a la fábrica de materia prima convertida en una orden del 100% de aumento.",
    "crumbs": [
      "V: Simulaciones y Redes Complejas",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>16. El Efecto Dominó</span>"
    ]
  },
  {
    "objectID": "cap-16-efecto-domino-meio.html#la-física-de-la-distorsión-el-efecto-látigo-bullwhip-effect",
    "href": "cap-16-efecto-domino-meio.html#la-física-de-la-distorsión-el-efecto-látigo-bullwhip-effect",
    "title": "16. El Efecto Dominó",
    "section": "",
    "text": "16.1.1 Los Cuatro Jinetes del Caos Sistémico\nComo arquitectos, debemos identificar las causas raíz para poder diseñar las defensas:\n\nActualización de Pronósticos en Cascada: Cada eslabón utiliza los pedidos de su cliente inmediato como su “demanda real”. Si la tienda añade un pequeño margen de seguridad, el CD añade otro sobre ese, y la fábrica recibe una señal totalmente desconectada de lo que el cliente final está comprando.\nAgrupamiento de Lotes (Batching): Por querer optimizar el transporte (EOQ), acumulamos pedidos para llenar camiones. Esto crea periodos de “silencio” seguidos de pedidos masivos que el proveedor interpreta como un crecimiento del mercado, cuando es solo una acumulación logística.\nFluctuaciones de Precio y Promociones: El Forward Buying (comprar para aprovechar un descuento hoy) destruye la señal de demanda real. El inventario se mueve por incentivos de precio, no por consumo, lo que genera una resaca de demanda nula en los periodos siguientes.\nJuego de Escasez y Racionamiento: Cuando el mercado sospecha que habrá escasez, todos piden el doble de lo que necesitan esperando recibir al menos la mitad. Esto infla artificialmente las carteras de pedidos y lleva a inversiones masivas en capacidad que luego quedan ociosas.",
    "crumbs": [
      "V: Simulaciones y Redes Complejas",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>16. El Efecto Dominó</span>"
    ]
  },
  {
    "objectID": "cap-16-efecto-domino-meio.html#la-filosofía-meio-el-posicionamiento-del-capital",
    "href": "cap-16-efecto-domino-meio.html#la-filosofía-meio-el-posicionamiento-del-capital",
    "title": "16. El Efecto Dominó",
    "section": "16.2 La Filosofía MEIO: El Posicionamiento del Capital",
    "text": "16.2 La Filosofía MEIO: El Posicionamiento del Capital\nLa Optimización Multi-escalón (MEIO) rompe con la tradición de “stock en todos lados”. Su objetivo no es preguntar cuánto stock tener en cada nodo, sino en qué eslabón de la red es más eficiente financieramente posicionar el inventario.\n\n16.2.1 El Poder del Inventario Consolidado (Inventory Pooling)\nAquí aplicamos una de las leyes más potentes de la estadística, la Ley de la Raíz Cuadrada: El stock de seguridad total de una red se reduce si consolidamos los puntos de inventario. * Matemática: \\(SS_{centralizado} \\approx \\frac{SS_{descentralizado}}{\\sqrt{n}}\\), donde \\(n\\) es el número de almacenes. * Implicación: Si tienes 10 tiendas con stock de seguridad independiente, tu inventario total será mucho mayor que si tienes un almacén central que reabastece rápidamente a las 10. Los errores de demanda tienden a cancelarse entre sí.\n\n\n16.2.2 Estrategia de Postergación (Postponement)\nEl MEIO favorece mantener el stock en su forma más genérica y centralizada el mayor tiempo posible. * Aguas Arriba (CD): El inventario es más barato de mantener y es versátil. * Aguas Abajo (Tienda): El inventario es más caro y está “atrapado”.",
    "crumbs": [
      "V: Simulaciones y Redes Complejas",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>16. El Efecto Dominó</span>"
    ]
  },
  {
    "objectID": "cap-16-efecto-domino-meio.html#estrategias-para-mitigar-el-efecto-dominó",
    "href": "cap-16-efecto-domino-meio.html#estrategias-para-mitigar-el-efecto-dominó",
    "title": "16. El Efecto Dominó",
    "section": "16.3 Estrategias para Mitigar el Efecto Dominó",
    "text": "16.3 Estrategias para Mitigar el Efecto Dominó\nLa clave para estabilizar una red compleja es sustituir el Inventario por Información.\n\nVisibilidad de Datos de Punto de Venta (POS): La fábrica debe mirar lo que la cajera escanea en la tienda. Esta es la “señal de demanda pura”.\nReducción del Lead Time: El efecto látigo es directamente proporcional al tiempo de espera.\nVMI (Vendor Managed Inventory): El proveedor decide cuándo reponer basándose en los niveles de stock del cliente.\nSincronización de Promociones: El S&OP es el pegamento que evita que el látigo golpee a la producción.",
    "crumbs": [
      "V: Simulaciones y Redes Complejas",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>16. El Efecto Dominó</span>"
    ]
  },
  {
    "objectID": "cap-16-efecto-domino-meio.html#modelado-de-redes-complejas-en-la-simulación",
    "href": "cap-16-efecto-domino-meio.html#modelado-de-redes-complejas-en-la-simulación",
    "title": "16. El Efecto Dominó",
    "section": "16.4 Modelado de Redes Complejas en la Simulación",
    "text": "16.4 Modelado de Redes Complejas en la Simulación\nEn nuestro Laboratorio Virtual, simulamos el flujo entre nodos. En R, modelamos la salida de un nodo como el activador del pedido al nodo superior.\n# Motor de Simulación Multi-escalón Profesional\nlibrary(tidyverse)\n\nsimular_red_meio &lt;- function(dias = 365) {\n  stock_tiendas &lt;- rep(100, 5)\n  stock_cd &lt;- 1000\n  backlog_total &lt;- 0\n  \n  for(d in 1:dias) {\n    # 1. Demanda del Cliente Final\n    demandas_dia &lt;- rgamma(5, shape=2, scale=15)\n    \n    # 2. Descuento en Tiendas\n    stock_tiendas &lt;- stock_tiendas - demandas_dia\n    \n    # 3. Identificar Quiebres Locales\n    backlog_total &lt;- backlog_total + sum(abs(pmin(0, stock_tiendas)))\n    stock_tiendas &lt;- pmax(0, stock_tiendas)\n    \n    # 4. Señal de Reabastecimiento al CD (MEIO)\n    for(i in 1:5) {\n      if(stock_tiendas[i] &lt; 50) { \n        pedido &lt;- 100 - stock_tiendas[i] \n        surtido &lt;- min(stock_cd, pedido)\n        stock_cd &lt;- stock_cd - surtido\n        stock_tiendas[i] &lt;- stock_tiendas[i] + surtido\n      }\n    }\n    \n    # 5. Reabastecimiento del CD desde Fábrica\n    if(stock_cd &lt; 400) { stock_cd &lt;- stock_cd + 800 }\n  }\n  return(backlog_total)\n}",
    "crumbs": [
      "V: Simulaciones y Redes Complejas",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>16. El Efecto Dominó</span>"
    ]
  },
  {
    "objectID": "cap-16-efecto-domino-meio.html#el-conflicto-de-incentivos-los-silos-organizacionales",
    "href": "cap-16-efecto-domino-meio.html#el-conflicto-de-incentivos-los-silos-organizacionales",
    "title": "16. El Efecto Dominó",
    "section": "16.5 El Conflicto de Incentivos: Los Silos Organizacionales",
    "text": "16.5 El Conflicto de Incentivos: Los Silos Organizacionales\nEl mayor obstáculo para el MEIO no es la matemática, es la estructura de la empresa. Los incentivos contrapuestos (ahorro en flete vs. nivel de servicio) suelen destruir la salud de la red.\n\n\n\n\n\n\nImportantLa Visión Sistémica\n\n\n\nTu competencia real no es el producto de la otra empresa; es la agilidad de la red de suministro de la otra empresa. Una cadena que colabora y centraliza su stock de seguridad siempre derrotará a una red de actores individuales.",
    "crumbs": [
      "V: Simulaciones y Redes Complejas",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>16. El Efecto Dominó</span>"
    ]
  },
  {
    "objectID": "cap-16-efecto-domino-meio.html#checklist-de-cierre-del-capítulo",
    "href": "cap-16-efecto-domino-meio.html#checklist-de-cierre-del-capítulo",
    "title": "16. El Efecto Dominó",
    "section": "Checklist de Cierre del Capítulo",
    "text": "Checklist de Cierre del Capítulo\n\n¿He identificado los puntos de “batching” en mi cadena?\n¿Tengo acceso a la demanda del cliente final (POS)?\n¿He aplicado la ley de la raíz cuadrada para evaluar la consolidación en CD?\n¿He simulado el impacto de un retraso de transporte en la última milla?\n¿Existen incentivos contrapuestos entre gerentes de diferentes nodos?",
    "crumbs": [
      "V: Simulaciones y Redes Complejas",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>16. El Efecto Dominó</span>"
    ]
  },
  {
    "objectID": "cap-17-sim-opt-politica-perfecta.html",
    "href": "cap-17-sim-opt-politica-perfecta.html",
    "title": "17. Optimizando bajo Presión",
    "section": "",
    "text": "17.1 La Anatomía de Sim-Opt: Motor y Cerebro\nEn el Capítulo 15, construimos nuestro Laboratorio Virtual y aprendimos a “romper” nuestra cadena de suministro miles de veces para medir el riesgo de forma científica. Fue un hito: pasamos de la fe ciega en las fórmulas estáticas a la evidencia dinámica de la simulación de Monte Carlo. Sin embargo, nos quedó una brecha operativa. Si la simulación nos permite evaluar una política (un punto de reorden \\(s\\) y una cantidad de pedido \\(Q\\)), ¿cómo encontramos la combinación perfecta entre millones de posibilidades?\nIntentar encontrar el óptimo mediante “ensayo y error” manual es como intentar encontrar una aguja en un pajar que cambia de forma. Si tienes solo 2 variables (\\(s\\) y \\(Q\\)) y quieres probar 100 valores razonables para cada una, tienes 10,000 combinaciones. Si añades el tiempo de revisión (\\(T\\)), el nivel máximo (\\(S\\)) y las restricciones de transporte (MOQs), las combinaciones explotan exponencialmente. Aquí es donde entra la Simulación-Optimización (Sim-Opt): el uso de algoritmos inteligentes que “navegan” por tu simulador para encontrar la máxima eficiencia financiera bajo presión.\nLa Simulación-Optimización es la sinergia de dos disciplinas que suelen trabajar por separado:\nLa Filosofía de Vandeput: En Supply Chain, no buscamos el “Óptimo Matemático” de un libro de texto (que suele ser frágil). Buscamos la Política Robusta: aquella configuración que, en el promedio de mil futuros posibles, ofrece el menor costo total y la mayor resiliencia.",
    "crumbs": [
      "V: Simulaciones y Redes Complejas",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>17. Optimizando bajo Presión</span>"
    ]
  },
  {
    "objectID": "cap-17-sim-opt-politica-perfecta.html#la-anatomía-de-sim-opt-motor-y-cerebro",
    "href": "cap-17-sim-opt-politica-perfecta.html#la-anatomía-de-sim-opt-motor-y-cerebro",
    "title": "17. Optimizando bajo Presión",
    "section": "",
    "text": "El Simulador (El Motor de Realidad): Es el entorno que creamos en los capítulos anteriores. Su función es recibir un conjunto de parámetros (una política) y simular meses de operación, devolviendo los resultados: ¿Cuántas ventas perdimos? ¿Cuánto inventario promedio acumulamos? ¿Cuántas órdenes emitimos? Considera la demanda Gamma, el Lead Time variable y las mermas.\nEl Optimizador (El Cerebro Estratégico): Es un algoritmo de búsqueda (metaheurística) que no sabe nada de logística, pero sabe mucho de matemáticas. Su función es proponer nuevas combinaciones de parámetros, observar los resultados del simulador y “aprender” hacia qué dirección debe moverse para mejorar los KPIs.",
    "crumbs": [
      "V: Simulaciones y Redes Complejas",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>17. Optimizando bajo Presión</span>"
    ]
  },
  {
    "objectID": "cap-17-sim-opt-politica-perfecta.html#el-paisaje-de-la-decisión-por-qué-fallan-los-métodos-simples",
    "href": "cap-17-sim-opt-politica-perfecta.html#el-paisaje-de-la-decisión-por-qué-fallan-los-métodos-simples",
    "title": "17. Optimizando bajo Presión",
    "section": "17.2 El Paisaje de la Decisión: ¿Por qué fallan los métodos simples?",
    "text": "17.2 El Paisaje de la Decisión: ¿Por qué fallan los métodos simples?\nSi graficáramos el Costo Total de una política de inventarios, no veríamos una línea suave. Veríamos un “paisaje” accidentado con valles (zonas de bajo costo) y picos (zonas de alto riesgo).\n\nNo-Convexidad: A diferencia de los problemas de álgebra simple, en inventarios hay “múltiples valles”. Puedes encontrar una política que parece buena, pero a la vuelta de la esquina hay una mucho mejor que tu fórmula no detectó.\nRuido Estocástico: Debido a que simulamos con azar, una política puede parecer buena en una corrida y mala en otra. El optimizador debe ser capaz de ver “a través del ruido”.\nRestricciones de la Vida Real (Constraints): Aquí es donde la presión se vuelve real. El optimizador debe trabajar dentro de límites físicos:\n\nCapacidad de Almacén: No puedes pedir más de lo que cabe.\nPresupuesto de Capital: No puedes invertir más de $X en stock de seguridad.\nNivel de Servicio Garantizado: El Fill Rate debe ser estrictamente \\(\\ge 98\\%\\). Cualquier política que ahorre dinero pero baje del 98% es rechazada automáticamente.",
    "crumbs": [
      "V: Simulaciones y Redes Complejas",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>17. Optimizando bajo Presión</span>"
    ]
  },
  {
    "objectID": "cap-17-sim-opt-politica-perfecta.html#checklist-de-cierre-del-capítulo",
    "href": "cap-17-sim-opt-politica-perfecta.html#checklist-de-cierre-del-capítulo",
    "title": "17. Optimizando bajo Presión",
    "section": "Checklist de Cierre del Capítulo",
    "text": "Checklist de Cierre del Capítulo\n\n¿He definido funciones de costo que penalicen el quiebre de stock de forma realista?\n¿Mi optimizador está respetando las restricciones físicas (MOQ, Capacidad)?\n¿He analizado el Frente de Pareto para ofrecer alternativas estratégicas a la dirección?\n¿He validado la política “ganadora” con una simulación de 100,000 iteraciones para asegurar su estabilidad?\n¿He comparado el ahorro de Sim-Opt frente a mi política actual para reportar el FVA de la optimización?",
    "crumbs": [
      "V: Simulaciones y Redes Complejas",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>17. Optimizando bajo Presión</span>"
    ]
  },
  {
    "objectID": "cap-18-fva-valor-pronostico.html",
    "href": "cap-18-fva-valor-pronostico.html",
    "title": "18. ¿Aportamos Valor? (Forecast Value Added)",
    "section": "",
    "text": "18.1 La Cascada de Valor: ¿Quién se equivoca menos?\nFelicidades. Has construido modelos ARIMA quirúrgicos, has entrenado bosques de XGBoost y has simulado redes complejas mediante Monte Carlo. Tienes en tus manos el motor de decisión más potente que tu empresa haya visto jamás. Pero ahora te enfrentas al reto definitivo: hacer que la organización lo use de forma rentable.\nEn la Supply Chain real, los modelos no operan en un vacío aséptico. Operan en reuniones de S&OP (Sales and Operations Planning) donde el aire está cargado de política, incentivos contrapuestos y egos. El gerente de ventas quiere inflar el número para asegurar disponibilidad y presupuesto de marketing; el gerente de finanzas quiere “ser conservador” para cuidar el flujo de caja, y el planificador veterano confía más en su “olfato” que en un algoritmo de gradiente.\nEn esta Parte VI, aprenderemos a gestionar el factor humano. Ya no optimizaremos hiperparámetros; optimizaremos procesos de decisión y gobernanza.\nEl marco FVA (Forecast Value Added) es la vara de medir definitiva del Arquitecto de Suministros. Su premisa es brutalmente honesta: “Cada paso, cada reunión y cada ajuste manual en el proceso de planificación debe justificar su existencia demostrando que reduce el error de pronóstico frente a no hacer nada”.\nSi un paso del proceso no mejora la precisión (o reduce el sesgo), es un desperdicio operativo —una “grasa” burocrática— que debe ser eliminada. El FVA es el ROI de tu tiempo y del tiempo de tu equipo.\nPara aplicar FVA, debemos visualizar el pronóstico como un proceso de manufactura de información por etapas. Cada etapa toma el resultado de la anterior y lo intenta “pulir”. Registramos el error en cada punto:",
    "crumbs": [
      "VI: El Factor Humano y la Ejecución",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>18. ¿Aportamos Valor? (Forecast Value Added)</span>"
    ]
  },
  {
    "objectID": "cap-18-fva-valor-pronostico.html#la-cascada-de-valor-quién-se-equivoca-menos",
    "href": "cap-18-fva-valor-pronostico.html#la-cascada-de-valor-quién-se-equivoca-menos",
    "title": "18. ¿Aportamos Valor? (Forecast Value Added)",
    "section": "",
    "text": "Nivel 0 (Benchmark Naive): ¿Qué pasaría si simplemente repetimos la venta del mes pasado o la del año pasado? Esfuerzo: Cero. Costo: Cero. Este es nuestro grupo de control.\nNivel 1 (Estadística Base): El resultado de tu modelo automático (ETS/ARIMA). Es la “opinión” de la matemática pura.\nNivel 2 (Machine Learning + Inteligencia): El modelo tras integrar variables exógenas (Precios, Promociones, Clima).\nNivel 3 (Consenso Humano): El ajuste final tras la reunión de S&OP, donde se inyecta el “conocimiento del mercado”.\n\n\nLa Ecuación del FVA\nEl valor añadido de un paso específico \\(i\\) se calcula comparando su error contra el paso anterior \\(i-1\\):\n\\[FVA_{paso} = Error_{paso \\ anterior} - Error_{paso \\ actual}\\]\n\nFVA Positivo (+): El paso mejoró la precisión. Has ganado dinero para la empresa.\nFVA Negativo (-): El paso inyectó ruido. El esfuerzo humano o técnico destruyó valor y aumentó el riesgo de inventario.",
    "crumbs": [
      "VI: El Factor Humano y la Ejecución",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>18. ¿Aportamos Valor? (Forecast Value Added)</span>"
    ]
  },
  {
    "objectID": "cap-18-fva-valor-pronostico.html#la-psicología-del-ajuste-por-qué-el-humano-suele-fallar",
    "href": "cap-18-fva-valor-pronostico.html#la-psicología-del-ajuste-por-qué-el-humano-suele-fallar",
    "title": "18. ¿Aportamos Valor? (Forecast Value Added)",
    "section": "18.2 La Psicología del Ajuste: ¿Por qué el Humano suele fallar?",
    "text": "18.2 La Psicología del Ajuste: ¿Por qué el Humano suele fallar?\nNicolas Vandeput ha documentado que en más del 50% de los casos, los ajustes manuales empeoran el pronóstico. Como ingenieros, debemos entender los sesgos cognitivos que provocan este desastre:\n\nSesgo de Optimismo (Ilusión de Ventas): El equipo comercial tiende a proyectar sus deseos de cuota en el pronóstico. Un pronóstico inflado genera un exceso de inventario que destruye el flujo de caja.\nAnclaje y Ajuste: El humano tiende a quedarse cerca del número inicial y hacer cambios pequeños, incluso cuando hay evidencia de un cambio radical en el mercado.\nSesgo de Recencia: Darle demasiada importancia a lo que pasó ayer (una queja de un cliente, un pedido grande inusual) y olvidar la tendencia de largo plazo que la máquina sí ve.\nAjustes de “Ruido”: Intentar explicar fluctuaciones aleatorias que no tienen causa. El humano busca patrones donde solo hay azar; la máquina tiene la disciplina de ignorar el ruido.",
    "crumbs": [
      "VI: El Factor Humano y la Ejecución",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>18. ¿Aportamos Valor? (Forecast Value Added)</span>"
    ]
  },
  {
    "objectID": "cap-18-fva-valor-pronostico.html#implementación-del-fva-como-sistema-de-gobernanza",
    "href": "cap-18-fva-valor-pronostico.html#implementación-del-fva-como-sistema-de-gobernanza",
    "title": "18. ¿Aportamos Valor? (Forecast Value Added)",
    "section": "18.3 Implementación del FVA como Sistema de Gobernanza",
    "text": "18.3 Implementación del FVA como Sistema de Gobernanza\nPara que el FVA no sea solo un reporte, sino una herramienta de cambio cultural, debemos implementarlo con rigor:\n\nRegistro de Versiones (Versioning): Tu base de datos debe almacenar cada “capa” del pronóstico. El sistema debe saber qué dijo la máquina y qué dijo el humano antes de la venta real.\nDashboard de Responsabilidad: Crea un tablero donde se vea el FVA por planificador, por familia de productos y por región. Si un gerente de ventas tiene un FVA negativo persistente, sus ajustes deben ser bloqueados por el sistema.\nIncentivos Basados en FVA: Deja de premiar a la gente por “vencer al pronóstico” (lo cual incentiva pronósticos bajos/fáciles). Prémialos por un FVA positivo. El objetivo es la verdad, no el optimismo.",
    "crumbs": [
      "VI: El Factor Humano y la Ejecución",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>18. ¿Aportamos Valor? (Forecast Value Added)</span>"
    ]
  },
  {
    "objectID": "cap-18-fva-valor-pronostico.html#caso-de-estudio-el-roi-de-la-inteligencia",
    "href": "cap-18-fva-valor-pronostico.html#caso-de-estudio-el-roi-de-la-inteligencia",
    "title": "18. ¿Aportamos Valor? (Forecast Value Added)",
    "section": "18.4 Caso de Estudio: El ROI de la Inteligencia",
    "text": "18.4 Caso de Estudio: El ROI de la Inteligencia\nImagina que gestionas una categoría de repuestos industriales: * Error Naive (Piso): 40%. * Modelo Machine Learning (Cap. 9): Logra un 32%. (FVA Máquina = +8%). * Ajuste del Planificador: Sube el número por “instinto” y el error real termina en 37%. (FVA Humano = -5%).\nEl Veredicto: El toque humano ha “borrado” más de la mitad de la mejora lograda por el algoritmo. En este escenario, el Arquitecto de Suministros tiene la evidencia para automatizar la categoría y pedirle al planificador que mueva su atención a otra parte donde realmente aporte valor.",
    "crumbs": [
      "VI: El Factor Humano y la Ejecución",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>18. ¿Aportamos Valor? (Forecast Value Added)</span>"
    ]
  },
  {
    "objectID": "cap-18-fva-valor-pronostico.html#hacia-la-excepción-de-valor",
    "href": "cap-18-fva-valor-pronostico.html#hacia-la-excepción-de-valor",
    "title": "18. ¿Aportamos Valor? (Forecast Value Added)",
    "section": "18.5 Hacia la “Excepción de Valor”",
    "text": "18.5 Hacia la “Excepción de Valor”\nEl objetivo del FVA no es eliminar al humano, sino enfocarlo. El humano solo debe intervenir cuando tiene Información Exógena que la máquina no tiene: * Un cambio en la legislación que afectará las ventas. * El cierre de una planta de un cliente principal. * Una huelga de transporte inminente.\nSi no puedes documentar una razón externa clara para un ajuste, no toques el número. Deja que la parsimonia estadística haga su trabajo.\n\n\n\n\n\n\nImportantLa Disciplina del FVA\n\n\n\nEn Supply Chain Inteligente, la complejidad que no genera FVA es vanidad técnica. Si tu modelo de Deep Learning no bate al Naive por un margen que justifique su costo, la decisión más valiente y rentable es apagar el servidor y volver a lo simple.",
    "crumbs": [
      "VI: El Factor Humano y la Ejecución",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>18. ¿Aportamos Valor? (Forecast Value Added)</span>"
    ]
  },
  {
    "objectID": "cap-18-fva-valor-pronostico.html#checklist-de-cierre-del-capítulo",
    "href": "cap-18-fva-valor-pronostico.html#checklist-de-cierre-del-capítulo",
    "title": "18. ¿Aportamos Valor? (Forecast Value Added)",
    "section": "Checklist de Cierre del Capítulo",
    "text": "Checklist de Cierre del Capítulo\n\n¿Mi sistema de datos guarda el histórico de versiones del pronóstico (Máquina vs. Consenso)?\n¿He calculado el FVA acumulado de mi equipo de planificación en los últimos 6 meses?\n¿He identificado los “SKUs Intocables”: aquellos donde el FVA humano es consistentemente negativo?\n¿He comunicado a la dirección financiera el ahorro en inventario derivado del FVA positivo de mis modelos?\n¿He establecido un protocolo donde solo se permiten ajustes manuales si se registra una “causa raíz” externa?",
    "crumbs": [
      "VI: El Factor Humano y la Ejecución",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>18. ¿Aportamos Valor? (Forecast Value Added)</span>"
    ]
  },
  {
    "objectID": "cap-19-gestion-sesgos-humanos.html",
    "href": "cap-19-gestion-sesgos-humanos.html",
    "title": "19. El Algoritmo vs. el Ego",
    "section": "",
    "text": "19.1 Ruido vs. Sesgo: La Herencia de Kahneman\n“El problema no es que los humanos tengan intuición; el problema es que confían en ella más que en los datos, incluso cuando la evidencia demuestra sistemáticamente que están equivocados”.\nEn el Capítulo 18 introdujimos el marco FVA (Forecast Value Added) para auditar el valor de cada intervención. Pero medir el daño no es suficiente; un Arquitecto de Suministros debe ser capaz de prevenirlo. La mente humana, aunque brillante para identificar patrones complejos no estructurados, es un procesador de información imperfecto, plagado de atajos cognitivos que evolucionaron para la supervivencia en la sabana, no para la gestión de inventarios en una red global.\nEn este capítulo, entraremos en la “física de los sesgos”. Aprenderemos por qué las reuniones de S&OP suelen convertirse en campos de batalla políticos y cómo podemos rediseñar el proceso de toma de decisiones para que la inteligencia humana actúe como un amplificador del modelo, y no como un generador de entropía.\nAntes de catalogar los errores, debemos distinguir entre dos fenómenos que destruyen la precisión, tal como define el Nobel Daniel Kahneman:\nLa Misión del Arquitecto: Los algoritmos eliminan el Ruido (siempre dan el mismo resultado ante los mismos datos). Tu trabajo con el factor humano es eliminar el Sesgo y estructurar el juicio para que no inyecte nuevo ruido en el sistema.",
    "crumbs": [
      "VI: El Factor Humano y la Ejecución",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>19. El Algoritmo vs. el Ego</span>"
    ]
  },
  {
    "objectID": "cap-19-gestion-sesgos-humanos.html#ruido-vs.-sesgo-la-herencia-de-kahneman",
    "href": "cap-19-gestion-sesgos-humanos.html#ruido-vs.-sesgo-la-herencia-de-kahneman",
    "title": "19. El Algoritmo vs. el Ego",
    "section": "",
    "text": "Sesgo (Bias): Es un error sistemático. Es cuando el equipo de ventas siempre, mes tras mes, pronostica un 10% por encima de la realidad. Es una desviación en una dirección específica que podemos medir y corregir.\nRuido (Noise): Es la variabilidad no deseada. Es cuando dos planificadores, ante los mismos datos, llegan a conclusiones diferentes, o cuando un mismo planificador da un número diferente el lunes por la mañana respecto al viernes por la tarde.",
    "crumbs": [
      "VI: El Factor Humano y la Ejecución",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>19. El Algoritmo vs. el Ego</span>"
    ]
  },
  {
    "objectID": "cap-19-gestion-sesgos-humanos.html#el-catálogo-de-sesgos-en-la-trinchera-de-sop",
    "href": "cap-19-gestion-sesgos-humanos.html#el-catálogo-de-sesgos-en-la-trinchera-de-sop",
    "title": "19. El Algoritmo vs. el Ego",
    "section": "19.2 El Catálogo de Sesgos en la Trinchera de S&OP",
    "text": "19.2 El Catálogo de Sesgos en la Trinchera de S&OP\nPara ganar esta guerra, primero debemos identificar a los enemigos invisibles que se sientan a la mesa de planificación:\n\n19.2.1 Sesgo de Optimismo y Exceso de Confianza\nEs el más común. Los humanos sobreestimamos nuestra capacidad para influir en el futuro y subestimamos los riesgos. En Supply Chain, esto se traduce en creer que “esta promoción será masiva”, ignorando que las últimas tres fallaron. El exceso de confianza hace que los planificadores ignoren los intervalos de confianza del modelo, creyendo que su “punto de vista” es más preciso que la probabilidad estadística.\n\n\n19.2.2 Sesgo de Anclaje (Anchoring)\nOcurre cuando la mente se “pega” a la primera cifra mencionada. Si el Director Financiero abre la reunión mencionando el presupuesto anual (un objetivo político, no un pronóstico), todos los ajustes posteriores gravitarán alrededor de ese número. El presupuesto actúa como un ancla que impide que el pronóstico se mueva hacia la realidad que dictan los datos de demanda real.\n\n\n19.2.3 El Efecto HiPPO (Highest Paid Person’s Opinion)\nEn una reunión presencial, la jerarquía mata a la estadística. Si el Vicepresidente de Ventas dice que “el mercado está explotando”, los analistas subordinados tenderán a autocensurarse y ajustar sus modelos para coincidir con el jefe, incluso si los datos muestran una desaceleración. Esto destruye la diversidad de información y crea un eco-cámara peligroso.\n\n\n19.2.4 Sesgo de Recencia y Confirmación\nEl planificador le da un peso desproporcionado a la queja que recibió ayer de un cliente importante. Si un cliente grande canceló un pedido, el humano tiende a bajar el pronóstico de toda la familia de productos (Recencia). Luego, buscará activamente cualquier dato menor que confirme su miedo e ignorará las señales de crecimiento de otros mil clientes (Confirmación).",
    "crumbs": [
      "VI: El Factor Humano y la Ejecución",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>19. El Algoritmo vs. el Ego</span>"
    ]
  },
  {
    "objectID": "cap-19-gestion-sesgos-humanos.html#la-sabiduría-de-las-multitudes-the-wisdom-of-crowds",
    "href": "cap-19-gestion-sesgos-humanos.html#la-sabiduría-de-las-multitudes-the-wisdom-of-crowds",
    "title": "19. El Algoritmo vs. el Ego",
    "section": "19.3 La Sabiduría de las Multitudes (The Wisdom of Crowds)",
    "text": "19.3 La Sabiduría de las Multitudes (The Wisdom of Crowds)\nFrancis Galton descubrió en 1906 que el promedio de las estimaciones de una multitud suele ser más preciso que la opinión del mayor experto individual. Pero para que esto funcione en tu empresa, se deben cumplir tres condiciones estrictas que la mayoría de las organizaciones violan:\n\nIndependencia: Cada persona debe dar su pronóstico sin conocer el de los demás. La deliberación grupal contamina la señal.\nDiversidad: Necesitas la opinión de Ventas (mercado), Finanzas (restricciones), Operaciones (capacidad) y Marketing (promociones).\nDescentralización: Los informantes deben estar cerca del dato (ej. los vendedores de campo saben cosas que el gerente en la oficina central ignora).\n\nLa Táctica del Arquitecto: En lugar de una reunión donde todos discuten un número, implementa un sistema de votación ciega previa. Promedia esos números y preséntalos como el “Consenso Humano Inicial”. Te sorprenderá ver cómo este promedio bate constantemente a la opinión del “experto” de la sala.",
    "crumbs": [
      "VI: El Factor Humano y la Ejecución",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>19. El Algoritmo vs. el Ego</span>"
    ]
  },
  {
    "objectID": "cap-19-gestion-sesgos-humanos.html#el-método-delphi-profesional-estructurando-el-juicio",
    "href": "cap-19-gestion-sesgos-humanos.html#el-método-delphi-profesional-estructurando-el-juicio",
    "title": "19. El Algoritmo vs. el Ego",
    "section": "19.4 El Método Delphi Profesional: Estructurando el Juicio",
    "text": "19.4 El Método Delphi Profesional: Estructurando el Juicio\nCuando el riesgo es alto (ej. lanzamiento de un producto disruptivo), no usamos reuniones; usamos el Método Delphi. Es un proceso diseñado para extraer conocimiento experto eliminando la política:\n\nRonda 1 (Anónima): Cada experto envía su estimación y, lo más importante, sus razones cualitativas.\nRonda 2 (Retroalimentación): El Arquitecto resume las razones (sin nombres) y las distribuye. Los expertos ven argumentos que quizás no habían considerado (ej. “No creo que vendamos tanto porque hay un competidor nuevo en el sur”).\nRonda 3 (Ajuste): Los expertos emiten un segundo voto. Generalmente, las estimaciones convergen hacia un número mucho más realista y fundamentado.",
    "crumbs": [
      "VI: El Factor Humano y la Ejecución",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>19. El Algoritmo vs. el Ego</span>"
    ]
  },
  {
    "objectID": "cap-19-gestion-sesgos-humanos.html#la-gobernanza-del-ajuste-manual",
    "href": "cap-19-gestion-sesgos-humanos.html#la-gobernanza-del-ajuste-manual",
    "title": "19. El Algoritmo vs. el Ego",
    "section": "19.5 La Gobernanza del Ajuste Manual",
    "text": "19.5 La Gobernanza del Ajuste Manual\nVandeput insiste: El ajuste humano es una excepción, no una rutina. Para proteger el modelo, implementamos una política de “Etiquetas de Razón”:\n\nAjuste por Evento (Válido): Se basa en información que el modelo no tiene (ej. una huelga de puertos, un cambio de ley).\nAjuste por Promoción (Válido): Si el modelo de ML no incluye la variable “promo”, el humano debe inyectar el incremento esperado.\nAjuste por “Sentimiento” (Inválido): Estos ajustes deben estar prohibidos. Si no hay un dato externo concreto, el número de la máquina se queda.\n\nAuditoría de Ética de Datos: Al final de cada mes, analizamos el FVA por Etiqueta. Si los ajustes por “Sentimiento” tienen un FVA negativo durante 3 meses, el responsable pierde el acceso a modificar el sistema.",
    "crumbs": [
      "VI: El Factor Humano y la Ejecución",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>19. El Algoritmo vs. el Ego</span>"
    ]
  },
  {
    "objectID": "cap-19-gestion-sesgos-humanos.html#midiendo-el-sesgo-el-tracking-signal-ts",
    "href": "cap-19-gestion-sesgos-humanos.html#midiendo-el-sesgo-el-tracking-signal-ts",
    "title": "19. El Algoritmo vs. el Ego",
    "section": "19.6 Midiendo el Sesgo: El Tracking Signal (TS)",
    "text": "19.6 Midiendo el Sesgo: El Tracking Signal (TS)\nNo basta con medir el error absoluto (WAPE). Un Arquitecto debe vigilar si la organización tiene una “tendencia a mentirse”. El Tracking Signal es nuestra alarma de incendio:\n\\[TS_t = \frac{\\sum_{i=1}^t (Actual_i - Pronóstico_i)}{MAD_t}\\]\nDonde MAD es la Desviación Media Absoluta. * Interpretación: El TS mide cuántas MADs nos hemos desviado de forma acumulada. * Límites de Control: Si el \\(TS &gt; 4\\) o \\(TS &lt; -4\\), el proceso está fuera de control. * Un TS positivo alto indica que estamos subestimando sistemáticamente (perdiendo ventas). * Un TS negativo alto indica que el sesgo de optimismo ha secuestrado la cadena (inflamos inventario).",
    "crumbs": [
      "VI: El Factor Humano y la Ejecución",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>19. El Algoritmo vs. el Ego</span>"
    ]
  },
  {
    "objectID": "cap-19-gestion-sesgos-humanos.html#sincronización-el-camino-hacia-el-ibp-integrated-business-planning",
    "href": "cap-19-gestion-sesgos-humanos.html#sincronización-el-camino-hacia-el-ibp-integrated-business-planning",
    "title": "19. El Algoritmo vs. el Ego",
    "section": "19.7 Sincronización: El Camino hacia el IBP (Integrated Business Planning)",
    "text": "19.7 Sincronización: El Camino hacia el IBP (Integrated Business Planning)\nLa gestión de sesgos es la base del IBP. En este nivel de madurez, la empresa entiende que el pronóstico no es una meta de ventas, sino una proyección de la realidad. * Ventas pronostica lo que cree que pasará. * Finanzas calcula la brecha respecto al presupuesto. * La gerencia decide qué acciones comerciales tomar para cerrar esa brecha.\nNunca permitas que el pronóstico de demanda se convierta en el objetivo de ventas. Si lo haces, el sesgo de optimismo destruirá tu cadena de suministro para siempre.\n\n\n\n\n\n\nImportantEl Rol del Moderador Científico\n\n\n\nComo Arquitecto de Suministros, tu labor en la reunión de S&OP no es dar un número, sino proteger la integridad del proceso. Tu éxito se mide en un Tracking Signal cercano a cero y un FVA humano positivo. Si logras esto, habrás transformado la cultura de tu empresa de una basada en opiniones a una basada en evidencias.",
    "crumbs": [
      "VI: El Factor Humano y la Ejecución",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>19. El Algoritmo vs. el Ego</span>"
    ]
  },
  {
    "objectID": "cap-19-gestion-sesgos-humanos.html#checklist-de-cierre-del-capítulo",
    "href": "cap-19-gestion-sesgos-humanos.html#checklist-de-cierre-del-capítulo",
    "title": "19. El Algoritmo vs. el Ego",
    "section": "Checklist de Cierre del Capítulo",
    "text": "Checklist de Cierre del Capítulo\n\n¿He identificado a los “generadores de ruido” en mi proceso de consenso?\n¿He implementado un registro obligatorio de “Razones de Ajuste” para cada cambio manual?\n¿Tengo un reporte mensual de Tracking Signal para detectar sesgos sistémicos?\n¿He eliminado la deliberación abierta en favor de estimaciones independientes antes de las reuniones?\n¿He comunicado a la dirección el costo financiero (en inventario o ventas perdidas) derivado de los sesgos detectados?",
    "crumbs": [
      "VI: El Factor Humano y la Ejecución",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>19. El Algoritmo vs. el Ego</span>"
    ]
  },
  {
    "objectID": "cap-20-plan-maestro-sop.html",
    "href": "cap-20-plan-maestro-sop.html",
    "title": "20. El Plan Maestro",
    "section": "",
    "text": "20.1 El Ciclo S&OP: Sincronizando el Latido del Negocio\nLlegamos a la última frontera de la arquitectura de suministros. Has dominado el arte de limpiar datos, has construido bosques de decisiones y has simulado la incertidumbre mediante modelos estocásticos. Tienes en tus manos un motor de precisión quirúrgica, pero ahora te enfrentas al reto definitivo: convencer a la organización de que deje de confiar en su “instinto” y empiece a confiar en el sistema.\nComo bien sabe cualquier profesional con cicatrices de batalla en logística, las empresas no quiebran por tener un WAPE un 3% más alto; quiebran por la falta de alineación y por la toma de decisiones basada en silos. El S&OP (Sales and Operations Planning) no es una reunión para revisar hojas de cálculo; es el proceso maestro donde la empresa decide cómo va a ganar dinero y proteger su capital en los próximos 18 meses. En este capítulo final, aprenderemos a integrar tus modelos en el ciclo ejecutivo y a construir la Torre de Control que transformará la cultura de tu empresa de “reactiva” a “predictiva”.\nUn proceso de S&OP profesional no es un evento aislado, es un latido mensual que sincroniza la demanda con el suministro. Tu rol como Arquitecto de Suministros es actuar como el “facilitador de la verdad” en estas cinco etapas:",
    "crumbs": [
      "VI: El Factor Humano y la Ejecución",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>20. El Plan Maestro</span>"
    ]
  },
  {
    "objectID": "cap-20-plan-maestro-sop.html#el-ciclo-sop-sincronizando-el-latido-del-negocio",
    "href": "cap-20-plan-maestro-sop.html#el-ciclo-sop-sincronizando-el-latido-del-negocio",
    "title": "20. El Plan Maestro",
    "section": "",
    "text": "Recolección y Preparación de Datos: Es la base de la pirámide (Parte I del libro). Sin datos limpios, el S&OP es solo una discusión de opiniones.\nRevisión de la Demanda (Demand Review): Aquí es donde el modelo de ML o estadística base se encuentra con el juicio humano. Es el momento de aplicar el FVA (Cap. 18) y filtrar los sesgos (Cap. 19). El objetivo es un Pronóstico de Consenso Insesgado.\nRevisión de Suministro (Supply Review): Usamos el EOQ (Cap. 12) y el Stock de Seguridad (Cap. 13) para validar si la red es físicamente capaz de soportar la demanda. Se identifican restricciones de capacidad, cuellos de botella en proveedores y necesidades de flete extra.\nReconciliación (Pre-S&OP): La fase más táctica. Se comparan las brechas: ¿Lo que ventas quiere vender cabe en el presupuesto de finanzas? Si hay una brecha, se simulan escenarios (Cap. 15) para decidir si invertimos en más stock o si hacemos promociones para limpiar excesos.\nReunión Ejecutiva de S&OP (Executive Review): El foro del CEO. Aquí no se validan datos, se toman decisiones. Se presentan tres escenarios claros con sus respectivos impactos en el flujo de caja.",
    "crumbs": [
      "VI: El Factor Humano y la Ejecución",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>20. El Plan Maestro</span>"
    ]
  },
  {
    "objectID": "cap-20-plan-maestro-sop.html#la-torre-de-control-el-sistema-nervioso-central-control-tower",
    "href": "cap-20-plan-maestro-sop.html#la-torre-de-control-el-sistema-nervioso-central-control-tower",
    "title": "20. El Plan Maestro",
    "section": "20.2 La Torre de Control: El Sistema Nervioso Central (Control Tower)",
    "text": "20.2 La Torre de Control: El Sistema Nervioso Central (Control Tower)\nSi el S&OP es el “cerebro” que planifica a medio plazo, la Torre de Control es el “sistema nervioso” que gestiona la ejecución en tiempo real. Una Torre de Control no es solo un conjunto de pantallas bonitas; es una infraestructura de personas, procesos y tecnología diseñada para proporcionar visibilidad de extremo a extremo (End-to-End o E2E).\n\n20.2.1 Visibilidad E2E: Rompiendo las Paredes del Almacén\nTradicionalmente, la visibilidad se limitaba a lo que ocurría dentro de las cuatro paredes de tu bodega. Una Torre de Control moderna extiende sus sensores hacia: * Aguas Arriba (Proveedores): Conocer el estado de la materia prima antes de que salga de la fábrica del proveedor. * En Tránsito: Monitorear buques, camiones y aviones mediante GPS e IoT para ajustar el ROP dinámicamente si hay retrasos. * Aguas Abajo (Clientes/Retail): Ver el inventario en el estante del cliente para detectar el “Efecto Látigo” (Cap. 16) antes de que llegue a tu almacén.\n\n\n20.2.2 Gestión por Excepciones (Management by Exception)\nLa Torre de Control libera al planificador de la tarea de mirar miles de SKUs que se comportan “normalmente”. El sistema utiliza los modelos de Machine Learning (Cap. 9) para establecer túneles de control. Solo cuando la demanda o el suministro se salen de ese túnel, la Torre dispara una alerta roja. &gt; “No me digas que el 95% de la cadena está bien; dime qué contenedor está retrasado y qué cliente Clase A se verá afectado”.",
    "crumbs": [
      "VI: El Factor Humano y la Ejecución",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>20. El Plan Maestro</span>"
    ]
  },
  {
    "objectID": "cap-20-plan-maestro-sop.html#capacidades-de-la-torre-de-control-de-la-visibilidad-a-la-autonomía",
    "href": "cap-20-plan-maestro-sop.html#capacidades-de-la-torre-de-control-de-la-visibilidad-a-la-autonomía",
    "title": "20. El Plan Maestro",
    "section": "20.3 Capacidades de la Torre de Control: De la Visibilidad a la Autonomía",
    "text": "20.3 Capacidades de la Torre de Control: De la Visibilidad a la Autonomía\nLa evolución de una Torre de Control sigue cuatro estadios de madurez que todo Arquitecto debe liderar:\n\nVisibilidad (¿Qué está pasando?): Rastreo de envíos y niveles de stock centralizados.\nAnálisis (¿Por qué está pasando?): Correlación de eventos. Si el puerto de Shanghái cierra, el sistema identifica automáticamente qué órdenes de compra están comprometidas.\nPredicción (¿Qué va a pasar?): Uso de simulaciones de Monte Carlo (Cap. 15) para predecir la probabilidad de quiebre de stock en los próximos 15 días basándose en la variabilidad real del Lead Time.\nPrescripción y Autonomía (¿Qué debemos hacer?): El sistema sugiere —o ejecuta automáticamente— el desvío de un pedido a otro almacén para cubrir un faltante inminente.",
    "crumbs": [
      "VI: El Factor Humano y la Ejecución",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>20. El Plan Maestro</span>"
    ]
  },
  {
    "objectID": "cap-20-plan-maestro-sop.html#el-tablero-operativo-la-sala-de-máquinas-engine-room",
    "href": "cap-20-plan-maestro-sop.html#el-tablero-operativo-la-sala-de-máquinas-engine-room",
    "title": "20. El Plan Maestro",
    "section": "20.4 El Tablero Operativo: La Sala de Máquinas (Engine Room)",
    "text": "20.4 El Tablero Operativo: La Sala de Máquinas (Engine Room)\nPara el equipo de planeación, la Torre de Control provee un tablero táctico: * Tracking Signal por SKU: Alerta sobre sesgos sistemáticos. * Alertas de FVA Negativo: Identificación de ajustes humanos que destruyen valor. * Detección de Outliers: Visualización de picos inusuales que requieren acción inmediata. * Monitor de Lead Time Real vs. Teórico: ¿El proveedor realmente está cumpliendo con los 10 días que dice el sistema?",
    "crumbs": [
      "VI: El Factor Humano y la Ejecución",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>20. El Plan Maestro</span>"
    ]
  },
  {
    "objectID": "cap-20-plan-maestro-sop.html#el-tablero-ejecutivo-el-puente-de-mando-the-bridge",
    "href": "cap-20-plan-maestro-sop.html#el-tablero-ejecutivo-el-puente-de-mando-the-bridge",
    "title": "20. El Plan Maestro",
    "section": "20.5 El Tablero Ejecutivo: El Puente de Mando (The Bridge)",
    "text": "20.5 El Tablero Ejecutivo: El Puente de Mando (The Bridge)\nLa gerencia necesita ver valor y riesgo en términos financieros. * Valor del Inventario en Riesgo: Dólares en riesgo por obsolescencia o por ventas perdidas. * Frente de Pareto (Servicio vs. Inversión): La herramienta para que el CEO decida el punto de rentabilidad óptima. * Proyección de Cash Flow: Cómo impactará el plan de suministro en la liquidez de la empresa en los próximos 3 meses.",
    "crumbs": [
      "VI: El Factor Humano y la Ejecución",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>20. El Plan Maestro</span>"
    ]
  },
  {
    "objectID": "cap-20-plan-maestro-sop.html#el-arte-de-la-comunicación-ejecutiva-del-error-a-los-dólares",
    "href": "cap-20-plan-maestro-sop.html#el-arte-de-la-comunicación-ejecutiva-del-error-a-los-dólares",
    "title": "20. El Plan Maestro",
    "section": "20.6 El Arte de la Comunicación Ejecutiva: Del Error a los Dólares",
    "text": "20.6 El Arte de la Comunicación Ejecutiva: Del Error a los Dólares\nAprender a hablar el lenguaje del dinero es la habilidad final del Arquitecto: * Traducción de Precisión: “La mejora en el modelo redujo el stock de seguridad en $400k, liberando flujo de caja para la expansión de la planta”. * Traducción de Riesgo: “Gracias a la Torre de Control, detectamos el retraso del proveedor 12 días antes del quiebre, evitando una pérdida de margen de $150k mediante un desvío de inventario estratégico”.",
    "crumbs": [
      "VI: El Factor Humano y la Ejecución",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>20. El Plan Maestro</span>"
    ]
  },
  {
    "objectID": "cap-20-plan-maestro-sop.html#de-sop-a-ibp-la-integración-total",
    "href": "cap-20-plan-maestro-sop.html#de-sop-a-ibp-la-integración-total",
    "title": "20. El Plan Maestro",
    "section": "20.7 De S&OP a IBP: La Integración Total",
    "text": "20.7 De S&OP a IBP: La Integración Total\nEl IBP (Integrated Business Planning) es el estado donde el pronóstico de demanda se funde con el Plan Financiero (P&L), eliminando la “doble contabilidad” y asegurando que Ventas, Operaciones y Finanzas remen hacia el mismo número de rentabilidad.\n\n\n\n\n\n\nImportantLa Sabiduría del Arquitecto\n\n\n\nEl éxito de tus modelos no se mide en la pantalla, sino en la confianza de la junta directiva y en la agilidad de la operación. La Torre de Control es la que permite que el plan maestro de S&OP sobreviva al contacto con la realidad diaria del mercado.",
    "crumbs": [
      "VI: El Factor Humano y la Ejecución",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>20. El Plan Maestro</span>"
    ]
  },
  {
    "objectID": "cap-20-plan-maestro-sop.html#checklist-de-cierre-del-capítulo",
    "href": "cap-20-plan-maestro-sop.html#checklist-de-cierre-del-capítulo",
    "title": "20. El Plan Maestro",
    "section": "Checklist de Cierre del Capítulo",
    "text": "Checklist de Cierre del Capítulo\n\n¿He definido los parámetros de “Excepción” para mi Torre de Control?\n¿Tengo visibilidad de los tránsitos internacionales integrada en mi sistema de reorden?\n¿Mi tablero ejecutivo traduce los quiebres de stock a pérdida de margen ($)?\n¿He sincronizado el plan de S&OP con los objetivos financieros (IBP)?\n¿Utilizo simulaciones en tiempo real para evaluar el impacto de las disrupciones logísticas?",
    "crumbs": [
      "VI: El Factor Humano y la Ejecución",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>20. El Plan Maestro</span>"
    ]
  },
  {
    "objectID": "notas-finales-estrategia.html",
    "href": "notas-finales-estrategia.html",
    "title": "Notas y Recomendaciones Estratégicas",
    "section": "",
    "text": "1. El Rigor Estadístico como Base\nLa culminación de este manual no representa solo la entrega de un conjunto de algoritmos, sino la propuesta de un nuevo modelo para la cadena de suministro. La transición de una gestión basada en la intuición hacia una arquitectura basada en la evidencia requiere una comprensión profunda de las palancas financieras y los límites estadísticos.",
    "crumbs": [
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Notas y Recomendaciones Estratégicas</span>"
    ]
  },
  {
    "objectID": "notas-finales-estrategia.html#el-rigor-estadístico-como-base",
    "href": "notas-finales-estrategia.html#el-rigor-estadístico-como-base",
    "title": "Notas y Recomendaciones Estratégicas",
    "section": "",
    "text": "1.1 La Auditoría de Métricas: Más allá del MAPE\nAunque el MAPE (Mean Absolute Percentage Error) es un estándar reconocido por su simplicidad comunicativa, presenta defectos estructurales matemáticos que lo hacen inadecuado para la toma de decisiones estratégicas en Supply Chain. Un Arquitecto de Suministros debe entender que el MAPE no es neutral; tiene “opiniones” matemáticas que pueden inducir a errores graves:\n\nSesgo hacia la subestimación: El MAPE penaliza más a los pronósticos que están por encima de la demanda real que a los que están por debajo. Matemáticamente, el error no puede superar el 100% si predices de menos (el mínimo es 0), pero no tiene límite si predices de más. Esto empuja a los planificadores a ser “conservadores”, lo que causa rupturas de stock (out-of-stock).\nProblemas con el cero: Si la demanda real es 0, el MAPE no se puede calcular (división por cero). Si la demanda es muy baja, cualquier pequeño error absoluto se convierte en un error porcentual astronómico que arruina el promedio del KPI.\nNo prioriza el valor: El MAPE trata por igual un error del 10% en un producto que vende un millón de unidades que en uno que vende diez. Para Vandeput, esto es un error de gestión, ya que el impacto financiero es totalmente distinto.\n\n\nLa recomendación: Utilizar el MAE (Error Absoluto Medio) combinado con el Sesgo (Bias), o preferiblemente el WMAPE (MAPE Ponderado), el cual evita los problemas de los valores bajos al ponderar por el volumen total.",
    "crumbs": [
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Notas y Recomendaciones Estratégicas</span>"
    ]
  },
  {
    "objectID": "notas-finales-estrategia.html#quiénes-se-benefician-y-quiénes-no",
    "href": "notas-finales-estrategia.html#quiénes-se-benefician-y-quiénes-no",
    "title": "Notas y Recomendaciones Estratégicas",
    "section": "¿Quiénes se benefician y quiénes no?",
    "text": "¿Quiénes se benefician y quiénes no?\nEl uso del MAPE crea “ganadores” y “perdedores” dentro de la organización debido a su naturaleza matemática:\n\nQuienes se “benefician” (aparentemente):\n\nPlanificadores que subestiman la demanda: Como el MAPE castiga menos el quedarse corto que el pasarse, alguien que siempre pronostica por debajo de lo real obtendrá “mejores” números de KPI (aunque deje a la empresa sin stock).\nVendedores de software básico: Muchas herramientas antiguas incluyen el MAPE porque es fácil de explicar a personas que no saben de estadística, aunque sea técnicamente deficiente.\nProductos de alto volumen y baja variabilidad: En estos casos, el MAPE suele ser estable y no presenta tantas distorsiones.\n\n\n\nQuienes NO se benefician (los perjudicados):\n\nEl Departamento de Finanzas y Operaciones: El MAPE no refleja el costo real del error. Puedes tener un MAPE “bajo” pero estar perdiendo millones en los productos más importantes.\nProductos de “cola larga” (Long Tail): Los productos con demanda intermitente o baja (repuestos, artículos de lujo, etc.) siempre tendrán un MAPE desastroso, haciendo que parezca que el modelo de predicción es inútil cuando quizás no lo es.\nLa Gerencia: Reciben informes de “80% de precisión” que no se traducen en una mejor disponibilidad de producto o menores costos de inventario.",
    "crumbs": [
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Notas y Recomendaciones Estratégicas</span>"
    ]
  },
  {
    "objectID": "notas-finales-estrategia.html#modelado-probabilístico-vs.-distribución-normal",
    "href": "notas-finales-estrategia.html#modelado-probabilístico-vs.-distribución-normal",
    "title": "Notas y Recomendaciones Estratégicas",
    "section": "2. Modelado Probabilístico vs. Distribución Normal",
    "text": "2. Modelado Probabilístico vs. Distribución Normal\nLa “falsa seguridad” de la campana de Gauss ignora los riesgos de cola (Tail Risk). En mercados volátiles, la demanda rara vez es simétrica.\n\nRecomendación: Priorice el uso de la Distribución Gamma para el cálculo del stock de seguridad. Este enfoque permite modelar con precisión la asimetría de la demanda, asegurando que la inversión en inventario cubra las variaciones reales y no supuestos teóricos que suelen subestimar el riesgo de quiebre.",
    "crumbs": [
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Notas y Recomendaciones Estratégicas</span>"
    ]
  },
  {
    "objectID": "notas-finales-estrategia.html#optimización-del-capital-el-tco-del-inventario",
    "href": "notas-finales-estrategia.html#optimización-del-capital-el-tco-del-inventario",
    "title": "Notas y Recomendaciones Estratégicas",
    "section": "3. Optimización del Capital: El TCO del Inventario",
    "text": "3. Optimización del Capital: El TCO del Inventario\nEl stock de seguridad es un síntoma de incertidumbre, no una solución operativa. Para optimizar el Costo Total de Propiedad (TCO), actúe sobre tres palancas:\n\nZ (Nivel de Servicio): Segmente clientes y productos. No todo requiere el mismo nivel de protección; la sobre-protección en Clase C es destrucción de valor.\n\\(\\sigma_d\\) (Variabilidad): Mejore la calidad del pronóstico mediante S&OP disciplinado y el uso de señales reales de consumo (sell-out).\nLT (Lead Time): Ataque la variabilidad de sus proveedores. Un Lead Time consistente es financieramente superior a uno rápido pero errático.",
    "crumbs": [
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Notas y Recomendaciones Estratégicas</span>"
    ]
  },
  {
    "objectID": "notas-finales-estrategia.html#arquitectura-tecnológica-el-cerebro-y-el-músculo",
    "href": "notas-finales-estrategia.html#arquitectura-tecnológica-el-cerebro-y-el-músculo",
    "title": "Notas y Recomendaciones Estratégicas",
    "section": "4. Arquitectura Tecnológica: El Cerebro y el Músculo",
    "text": "4. Arquitectura Tecnológica: El Cerebro y el Músculo\nEs imperativo definir las responsabilidades de la infraestructura:\n\nEl ERP es el Músculo Transaccional: Su función es la robustez y el registro. No fuerce al ERP a realizar analítica avanzada para la que no fue diseñado.\nEl Motor Analítico es el Cerebro Predictivo: Utilice herramientas de código abierto (R/Python) para gestionar la inteligencia estocástica y la optimización de parámetros dinámicos.",
    "crumbs": [
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Notas y Recomendaciones Estratégicas</span>"
    ]
  },
  {
    "objectID": "notas-finales-estrategia.html#el-factor-humano-forecast-value-added-fva",
    "href": "notas-finales-estrategia.html#el-factor-humano-forecast-value-added-fva",
    "title": "Notas y Recomendaciones Estratégicas",
    "section": "5. El Factor Humano: Forecast Value Added (FVA)",
    "text": "5. El Factor Humano: Forecast Value Added (FVA)\nEl juicio humano debe ser auditado. El ajuste manual solo añade valor cuando inyecta información exógena que el algoritmo no posee (promociones, cambios de ley). Si la intervención humana incrementa el error de forma constante, el proceso debe favorecer la parsimonia estadística para proteger el flujo de caja.",
    "crumbs": [
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Notas y Recomendaciones Estratégicas</span>"
    ]
  },
  {
    "objectID": "notas-finales-estrategia.html#conclusión-estratégica",
    "href": "notas-finales-estrategia.html#conclusión-estratégica",
    "title": "Notas y Recomendaciones Estratégicas",
    "section": "6. Conclusión Estratégica",
    "text": "6. Conclusión Estratégica\nEl inventario es capital en espera. Cada unidad reducida mediante la precisión analítica es flujo de caja liberado para la innovación y el crecimiento. Al adoptar estos principios, la organización deja de reaccionar ante la volatilidad para empezar a diseñarla.",
    "crumbs": [
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Notas y Recomendaciones Estratégicas</span>"
    ]
  },
  {
    "objectID": "cap-1-auditoria.html#análisis-exploratorio-de-datos-eda",
    "href": "cap-1-auditoria.html#análisis-exploratorio-de-datos-eda",
    "title": "1. Auditoría de Datos y Arquitectura de Red",
    "section": "1.5 Análisis Exploratorio de Datos (EDA)",
    "text": "1.5 Análisis Exploratorio de Datos (EDA)\nVamos a utilizar dataset de ejemplo, que nos acompañe durante el desarrollo de estos capítulos:\n\nMaestro de Productos (productos): Datos que no cambian seguido (Atributos).\nTransacciones de Ventas (ventas): La voz del cliente (Demanda).\nTransacciones de Compras (compras): Nuestra gestión con proveedores (Abastecimiento).\n\nAntes de analizar cuánto vendemos, debemos saber qué vendemos. El maestro de productos contiene información crítica como el costo, el precio y el Lead Time Prometido.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1.5.1 Completitud, Corte de Datos y el Peligro de Trabajar con “Fantasmas”\nEl análisis de completitud no es más que una inspección de salud: ¿están todos los que deberían estar? En Supply Chain, los datos no son solo números; son el rastro digital de camiones moviéndose, gente haciendo picking y clientes comprando. Si faltan datos, es como intentar armar un rompecabezas al que le faltan las piezas del centro.\n¿Qué revisar en la integridad de datos entonces?\n\nCompletitud → ¿faltan valores en columnas críticas?\nConsistencia → ¿los tipos de datos son correctos (fechas, números, texto)?\nValidez → ¿los valores cumplen reglas de negocio (ejemplo: precio ≥ 0)?\nUnicidad → ¿hay duplicados en claves primarias (ejemplo: ID de venta)?\nRangos → ¿las fechas están dentro del período esperado?\n\n\n¿Qué pasa si NO lo haces?\n\nResultados erróneos en los análisis: Si hay duplicados, valores faltantes o inconsistentes, las métricas (promedios, totales, tendencias) pueden quedar distorsionadas y llevar a conclusiones equivocadas.\nDecisiones equivocadas: En un entorno empresarial, basarse en datos incorrectos puede significar comprar demasiado stock, calcular mal la rentabilidad o tomar decisiones estratégicas con información falsa.\nPérdida de confianza: Si los reportes muestran incoherencias, los equipos y directivos dejan de confiar en los datos, lo que afecta la credibilidad del área de análisis o del sistema.\nProblemas regulatorios y legales: En sectores como finanzas, salud o energía, datos incompletos o incorrectos pueden violar normas de cumplimiento y generar sanciones.\nCostos ocultos: Tiempo extra para limpiar datos después, reprocesar informes, corregir errores en sistemas, o incluso pérdidas económicas por decisiones mal fundamentadas.\nImposibilidad de escalar proyectos: Si la base no es confiable, cualquier intento de aplicar modelos predictivos, machine learning o dashboards avanzados se vuelve inestable.\n\nPaso 1: Panorama general\nUsa skimr para ver tipos de variables, valores faltantes y rangos:\n\nlibrary(skimr)\n\nskim(productos)\n\n\nData summary\n\n\nName\nproductos\n\n\nNumber of rows\n1000\n\n\nNumber of columns\n10\n\n\nKey\nNULL\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n5\n\n\nlogical\n1\n\n\nnumeric\n4\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nsku_id\n0\n1\n8\n8\n0\n1000\n0\n\n\ncategoria\n0\n1\n5\n11\n0\n5\n0\n\n\nproveedor_id\n0\n1\n8\n8\n0\n50\n0\n\n\nabc_class\n0\n1\n1\n1\n0\n3\n0\n\n\nxyz_class\n0\n1\n1\n1\n0\n3\n0\n\n\n\nVariable type: logical\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\ncount\n\n\n\n\ntiene_vencimiento\n0\n1\n0.52\nTRU: 518, FAL: 482\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\ncosto_unitario\n0\n1.00\n186.02\n371.88\n5.03\n30.10\n49.45\n142.52\n1961.86\n▇▁▁▁▁\n\n\nprecio_venta\n0\n1.00\n384.85\n787.60\n8.18\n60.11\n109.96\n307.32\n4889.61\n▇▁▁▁▁\n\n\nvida_util_dias\n482\n0.52\n198.91\n97.71\n31.00\n116.25\n197.00\n286.00\n364.00\n▇▇▇▆▇\n\n\nvolumen_m3\n0\n1.00\n0.26\n0.14\n0.00\n0.13\n0.26\n0.38\n0.50\n▇▇▇▇▇\n\n\n\n\nskim(compras)\n\n\nData summary\n\n\nName\ncompras\n\n\nNumber of rows\n5000\n\n\nNumber of columns\n16\n\n\nKey\nNULL\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n6\n\n\nDate\n2\n\n\nlogical\n1\n\n\nnumeric\n7\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\norden_compra_id\n0\n1\n9\n9\n0\n5000\n0\n\n\nsku_id\n0\n1\n8\n8\n0\n988\n0\n\n\ncategoria\n0\n1\n5\n11\n0\n5\n0\n\n\nproveedor_id\n0\n1\n8\n8\n0\n50\n0\n\n\nabc_class\n0\n1\n1\n1\n0\n3\n0\n\n\nxyz_class\n0\n1\n1\n1\n0\n3\n0\n\n\n\nVariable type: Date\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\nfecha_orden\n0\n1\n2020-01-01\n2024-12-31\n2022-06-10\n1717\n\n\nfecha_recepcion\n0\n1\n2020-01-10\n2025-02-08\n2022-07-04\n1729\n\n\n\nVariable type: logical\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\ncount\n\n\n\n\ntiene_vencimiento\n0\n1\n0.51\nTRU: 2527, FAL: 2473\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\ncosto_unitario\n0\n1.00\n194.13\n388.36\n5.03\n30.98\n50.65\n147.05\n1961.86\n▇▁▁▁▁\n\n\nprecio_venta\n0\n1.00\n398.69\n812.02\n8.18\n60.88\n111.49\n309.61\n4889.61\n▇▁▁▁▁\n\n\nvida_util_dias\n2473\n0.51\n200.91\n97.38\n31.00\n116.00\n202.00\n289.00\n364.00\n▇▆▇▆▇\n\n\nvolumen_m3\n0\n1.00\n0.25\n0.14\n0.00\n0.13\n0.26\n0.38\n0.50\n▇▇▇▇▇\n\n\ncantidad_ordenada\n0\n1.00\n100.05\n10.11\n65.00\n93.00\n100.00\n107.00\n137.00\n▁▃▇▃▁\n\n\nlead_time\n0\n1.00\n22.49\n10.33\n5.00\n14.00\n22.00\n31.00\n40.00\n▇▇▇▇▇\n\n\ncantidad_recibida\n0\n1.00\n95.09\n9.98\n59.00\n88.00\n95.00\n102.00\n130.00\n▁▃▇▃▁\n\n\n\n\nskim(ventas)\n\n\nData summary\n\n\nName\nventas\n\n\nNumber of rows\n15000000\n\n\nNumber of columns\n16\n\n\nKey\nNULL\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n6\n\n\nDate\n1\n\n\nlogical\n1\n\n\nnumeric\n8\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nsku_id\n0\n1\n8\n8\n0\n395\n0\n\n\nalmacen_id\n0\n1\n10\n12\n0\n8\n0\n\n\ncategoria\n0\n1\n5\n11\n0\n5\n0\n\n\nproveedor_id\n0\n1\n8\n8\n0\n50\n0\n\n\nabc_class\n0\n1\n1\n1\n0\n3\n0\n\n\nxyz_class\n0\n1\n1\n1\n0\n3\n0\n\n\n\nVariable type: Date\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\nfecha\n0\n1\n2020-01-01\n2024-12-31\n2022-07-04\n1827\n\n\n\nVariable type: logical\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\ncount\n\n\n\n\ntiene_vencimiento\n0\n1\n0.53\nTRU: 7890000, FAL: 7110000\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\ncosto_unitario\n0\n1.00\n181.14\n370.62\n5.11\n30.54\n48.52\n128.16\n1961.86\n▇▁▁▁▁\n\n\nprecio_venta\n0\n1.00\n375.03\n773.07\n8.18\n61.21\n102.41\n260.72\n4888.88\n▇▁▁▁▁\n\n\nvida_util_dias\n7110000\n0.53\n195.41\n91.87\n32.00\n117.00\n196.00\n274.00\n363.00\n▆▆▇▅▆\n\n\nvolumen_m3\n0\n1.00\n0.27\n0.15\n0.00\n0.15\n0.28\n0.40\n0.50\n▆▆▆▇▇\n\n\ncantidad_demandada\n0\n1.00\n5.67\n2.97\n0.00\n4.00\n5.00\n7.00\n30.00\n▇▃▁▁▁\n\n\nes_devolucion\n0\n1.00\n0.05\n0.22\n0.00\n0.00\n0.00\n0.00\n1.00\n▇▁▁▁▁\n\n\ncantidad_vendida\n0\n1.00\n5.39\n3.15\n0.00\n3.00\n5.00\n7.00\n30.00\n▇▃▁▁▁\n\n\ncantidad_devuelta\n0\n1.00\n0.28\n1.40\n0.00\n0.00\n0.00\n0.00\n27.00\n▇▁▁▁▁\n\n\n\n\n\nPaso 2: Integridad básica\n\nDuplicados\n\n\nlibrary(janitor)\n\nget_dupes(productos)    # productos repetidos\n\ndata.table vacía (0 filas y 11 columnas): sku_id,categoria,proveedor_id,costo_unitario,precio_venta,abc_class...\n\nget_dupes(compras)     # compras repetidas\n\ndata.table vacía (0 filas y 17 columnas): orden_compra_id,sku_id,fecha_orden,categoria,proveedor_id,costo_unitario...\n\nget_dupes(ventas)      # ventas repetidas\n\n              fecha   sku_id   almacen_id   categoria proveedor_id\n             &lt;Date&gt;   &lt;char&gt;       &lt;char&gt;      &lt;char&gt;       &lt;char&gt;\n      1: 2023-10-20 SKU-0812  WH-TIENDA-B Electrónica     PROV-030\n      2: 2023-10-20 SKU-0812  WH-TIENDA-B Electrónica     PROV-030\n      3: 2023-10-20 SKU-0812  WH-TIENDA-B Electrónica     PROV-030\n      4: 2023-10-20 SKU-0812  WH-TIENDA-B Electrónica     PROV-030\n      5: 2023-10-20 SKU-0812  WH-TIENDA-B Electrónica     PROV-030\n     ---                                                          \n4134000: 2024-12-31 SKU-0994  WH-TIENDA-C Electrónica     PROV-001\n4134001: 2024-12-31 SKU-0994  WH-TIENDA-C Electrónica     PROV-001\n4134002: 2024-12-31 SKU-0994  WH-TIENDA-C Electrónica     PROV-001\n4134003: 2024-12-31 SKU-1000 WH-REG-NORTE       Hogar     PROV-031\n4134004: 2024-12-31 SKU-1000 WH-REG-NORTE       Hogar     PROV-031\n         costo_unitario precio_venta abc_class xyz_class tiene_vencimiento\n                  &lt;num&gt;        &lt;num&gt;    &lt;char&gt;    &lt;char&gt;            &lt;lgcl&gt;\n      1:     1063.67255    2395.8221         C         Y             FALSE\n      2:     1063.67255    2395.8221         C         Y             FALSE\n      3:     1063.67255    2395.8221         C         Y             FALSE\n      4:     1063.67255    2395.8221         C         Y             FALSE\n      5:     1063.67255    2395.8221         C         Y             FALSE\n     ---                                                                  \n4134000:      324.60546     779.3269         A         Y             FALSE\n4134001:      324.60546     779.3269         A         Y             FALSE\n4134002:      324.60546     779.3269         A         Y             FALSE\n4134003:       83.77424     144.0287         C         Y             FALSE\n4134004:       83.77424     144.0287         C         Y             FALSE\n         vida_util_dias volumen_m3 cantidad_demandada es_devolucion\n                  &lt;int&gt;      &lt;num&gt;              &lt;int&gt;         &lt;int&gt;\n      1:             NA 0.46861640                  3             0\n      2:             NA 0.46861640                  3             0\n      3:             NA 0.46861640                  3             0\n      4:             NA 0.46861640                  3             0\n      5:             NA 0.46861640                  3             0\n     ---                                                           \n4134000:             NA 0.10852604                  7             0\n4134001:             NA 0.10852604                 10             0\n4134002:             NA 0.10852604                 10             0\n4134003:             NA 0.05043692                  6             0\n4134004:             NA 0.05043692                  6             0\n         cantidad_vendida cantidad_devuelta dupe_count\n                    &lt;num&gt;             &lt;num&gt;      &lt;int&gt;\n      1:                3                 0         11\n      2:                3                 0         11\n      3:                3                 0         11\n      4:                3                 0         11\n      5:                3                 0         11\n     ---                                              \n4134000:                7                 0          2\n4134001:               10                 0          2\n4134002:               10                 0          2\n4134003:                6                 0          2\n4134004:                6                 0          2\n\n\n\nValores faltantes (NA) :\n\n\nsapply(productos, function(x) sum(is.na(x)))\n\n           sku_id         categoria      proveedor_id    costo_unitario \n                0                 0                 0                 0 \n     precio_venta         abc_class         xyz_class tiene_vencimiento \n                0                 0                 0                 0 \n   vida_util_dias        volumen_m3 \n              482                 0 \n\nsapply(compras, function(x) sum(is.na(x)))\n\n  orden_compra_id            sku_id       fecha_orden         categoria \n                0                 0                 0                 0 \n     proveedor_id    costo_unitario      precio_venta         abc_class \n                0                 0                 0                 0 \n        xyz_class tiene_vencimiento    vida_util_dias        volumen_m3 \n                0                 0              2473                 0 \ncantidad_ordenada         lead_time   fecha_recepcion cantidad_recibida \n                0                 0                 0                 0 \n\nsapply(ventas, function(x) sum(is.na(x)))\n\n             fecha             sku_id         almacen_id          categoria \n                 0                  0                  0                  0 \n      proveedor_id     costo_unitario       precio_venta          abc_class \n                 0                  0                  0                  0 \n         xyz_class  tiene_vencimiento     vida_util_dias         volumen_m3 \n                 0                  0            7110000                  0 \ncantidad_demandada      es_devolucion   cantidad_vendida  cantidad_devuelta \n                 0                  0                  0                  0 \n\n\nLa prueba de fuego: ¿Faltan días?\nSi estamos analizando un año, deberíamos tener registros de venta (o al menos la presencia de la fecha con venta cero) para cada día. Vamos a crear un calendario “maestro” y compararlo con nuestras ventas reales para detectar silencios del sistema.\nEl Semáforo de Integridad\nIgnorar estos huecos nos llevaría al Sesgo del Mes Incompleto. Si un algoritmo ve un cero donde debería haber un dato no grabado, bajará los niveles de inventario erróneamente. Visualicemos la salud de nuestros datos:\nAuditoría de Continuidad Temporal\nLo primero es saber si faltan días. En 5 años (aprox. 1.825 días), si hay saltos, tu estacionalidad estará mal calculada. Veamos si en nuestra tabla de 15.000.000 de filas hay algo raro.\n\n# 1. Crear calendario maestro\ncalendario_ideal &lt;- data.table(fecha = seq(min(ventas$fecha), max(ventas$fecha), by = \"day\"))\n\n# 2. Unir con ventas (Sincronía total)\nauditoria_completa &lt;- calendario_ideal %&gt;%\n  left_join(ventas[, .(ventas_reales = .N), by = fecha], by = \"fecha\") %&gt;%\n  as.data.table()\n\n# 3. Preparar para el mapa de calor\nauditoria_completa[, `:=`(\n  anio = year(fecha),\n  semana = isoweek(fecha),\n  dia_sem = lubridate::wday(fecha, label = TRUE, abbr = TRUE, week_start = 1)\n)]\n\nggplot(auditoria_completa, aes(x = semana, y = dia_sem, fill = ventas_reales)) +\n  geom_tile(color = \"white\") +\n  facet_wrap(~anio, ncol = 1) +\n  scale_fill_viridis_c(na.value = \"red\", option = \"mako\") +\n  theme_minimal()\n\n\n\n\n\n\n\nFigure 1.1: Calendario 5 años de ventas\n\n\n\n\n\n¿Cómo se lee la estructura?\n\nEje Y (Filas): Son tus 5 años de historia. Cada fila es un año completo.\nEje X (Columnas): Son las 52 o 53 semanas del año.\nCeldas (Cuadritos): Cada cuadro representa un día de la semana (Lunes a Domingo).\nColor (Escala Viridis/Mako): * Colores Claros/Azules: Indican que hubo muchas ventas (día de alta operación).\n\nColores Oscuros/Negros: Indican pocas ventas.\nColor ROJO (el na.value): Indica CERO registros. El sistema no encontró absolutamente nada ese día.\n\n\n\n# 2. Si ya no necesitas el detalle de los 15M de filas:\nrm(ventas) #Limpiamos tabla Ventas de R, cuando la necesitemos la llamamos de nuevo\n\n# Borra todos los objetos del Environment\nrm(list = ls())\n\n# 3. LIBERAR ESPACIO (El paso clave)\ngc() # Esto es el \"Garbage Collector\", obliga a R a devolver la RAM al sistema\n\n¿Cuándo es el momento adecuado para borrarla?\nDepende de tu flujo de trabajo:\n\nDurante el Análisis (EDA): Mantenla activa. Necesitarás filtrar por SKU, Almacén o fecha constantemente. Con 16 GB de RAM, 15 millones de filas (aprox. 1.5 - 2 GB) caben bien, siempre y cuando no dupliques la tabla.\nAl finalizar el cálculo de un reporte: Si tu objetivo era solo sacar el “Cierre de Mes”, borra la tabla de 15M antes de empezar a generar los gráficos de ggplot2, ya que los gráficos consumen mucha RAM extra para renderizar.\nAl final de tu jornada/script: Siempre limpia el entorno.\n\nIntegridad de “Huérfanos” (Referential Integrity)\nComo tienes tablas de productos y almacenes, hay que verificar que cada venta tenga un “padre” real. Si hay una venta con un ID_SKU que no existe en tu maestro de productos, tienes basura en la data.\n\n# Buscar ventas con productos que NO existen en el maestro\nhuerfanos_prod &lt;- ventas[!productos, on = .(sku_id), which = TRUE]\n# Buscar ventas con almacenes que NO existen\nhuerfanos_alm &lt;- ventas[!almacenes, on = .(almacen_id), which = TRUE]\n\nmessage(\"Registros con SKU inexistente: \", length(huerfanos_prod))\n\n¿Cómo lo presento? (El semáforo de integridad)\nIgnorar estos huecos nos llevaría al Sesgo del Mes Incompleto. Si un algoritmo ve un cero donde debería haber un dato no grabado, bajará los niveles de inventario erróneamente. Visualicemos la salud de nuestros datos:\n\nDías cubiertos: 1.820 / 1.825 (99.7%) ✅\nSKUs válidos: 100% ✅\nValores Nulos: 0% ✅\nVentas Negativas: 0.02% (Revisar devoluciones) ⚠️\n\n\n\n\n\n\n\nTip\n\n\n\nNunca imputes ceros a los valores NA sin investigar. Un NA es una duda (falló el sistema); un 0 es una certeza (nadie quiso comprar). Mezclarlos destruirá la precisión de tus algoritmos de Machine Learning.",
    "crumbs": [
      "I: El Diagnóstico",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>1. Auditoría de Datos y Arquitectura de Red</span>"
    ]
  },
  {
    "objectID": "cap-2-espejo-realidad.html#i.-fundamentos-la-diferencia-entre-vender-y-necesitar",
    "href": "cap-2-espejo-realidad.html#i.-fundamentos-la-diferencia-entre-vender-y-necesitar",
    "title": "2. El Espejo de la Realidad: Ventas vs. Demanda",
    "section": "",
    "text": "2.1 Lo que el sistema dice vs. Lo que el cliente quería\nImagina que tienes una frutería. Hoy vinieron 10 personas queriendo comprar una manzana cada una, pero tú solo tenías 3 en el mostrador. Al final del día, tu registro dirá: “Ventas: 3 unidades”.\nSi te basas solo en ese número para el futuro, pensarás que tu demanda es de 3, cuando en realidad el mercado te pedía 10. Esta es la Ecuación Universal simplificada:\n\\[\n\\large Salida_t = \\min(Necesidad_t, Disponibilidad_t)\n\\]\nEn términos simples: Tus ventas tienen un “techo” que es tu propio inventario. Si no tienes producto, tu venta será cero, aunque el cliente esté afuera gritando que quiere comprar. El sistema registrará un “cero”, ocultando la verdadera necesidad.\n\n\n2.2 El peligro de enseñar errores a tus algoritmos (Sesgo de IA)\nHoy en día usamos programas o Inteligencia Artificial (IA) para que nos digan cuánto comprar. Estos programas aprenden del pasado, pero no tienen sentido común. Si les das datos “mentirosos” (ventas bajas porque no tenías stock), crearás un círculo vicioso de escasez:\n\nEl pasado: No tenías stock, vendiste poco.\nEl aprendizaje: El algoritmo ve esa venta baja y piensa: “A nadie le gusta este producto, no se vende”.\nEl futuro: El algoritmo te recomienda comprar muy poco.\nEl resultado: Vuelves a quedarte sin nada, el cliente se va frustrado y el sistema cree que “acertó” porque se vendió lo poquito que compraste.\n\nEstamos institucionalizando la escasez. En lugar de usar la tecnología para crecer, la estamos usando para limitar nuestro propio negocio basándonos en errores del pasado.\n\n\n2.3 El Objetivo: La Demanda No Restringida\nPara romper este círculo, el planificador debe buscar la Demanda No Restringida. Este es el número mágico que representa lo que habrías vendido si hubieras tenido stock infinito.\n\\[\n\\large \\text{Demanda No Restringida} = \\text{Venta Real} + \\text{Venta Perdida}\n\\]\nSi no calculas la “Venta Perdida”, tu pronóstico siempre será una sombra pequeña de lo que tu empresa podría llegar a ser.\n\n\n\n\n\n\nTipPlan de Acción: Empezar a ver la realidad\n\n\n\n\nBusca la intención, no solo el resultado: No mires solo las facturas. Busca en tu sistema la tabla de “Pedidos” o “Reservas”. Ahí es donde el cliente dejó escrita su verdadera intención antes de que tú le dijeras que no tenías stock.\nMarca los datos “mentirosos”: Crea una marca o etiqueta en tu base de datos para los días en los que no tuviste suficiente mercancía. Dile a tu sistema: “Este dato de venta es bajo porque yo fallé, no porque el cliente no quisiera el producto”.\nCalcula tu tasa de servicio (Fill Rate): Empieza a medir qué porcentaje de los pedidos completas a tiempo. Si solo entregas el 80% de lo que te piden, tu demanda real es mucho mayor de lo que dicen tus ventas.",
    "crumbs": [
      "I: El Diagnóstico",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>2. El Espejo de la Realidad: Ventas vs. Demanda</span>"
    ]
  },
  {
    "objectID": "cap-2-espejo-realidad.html#ii.-diagnóstico-dónde-se-esconde-la-verdad",
    "href": "cap-2-espejo-realidad.html#ii.-diagnóstico-dónde-se-esconde-la-verdad",
    "title": "2. El Espejo de la Realidad: Ventas vs. Demanda",
    "section": "II. Diagnóstico: ¿Dónde se esconde la verdad?",
    "text": "II. Diagnóstico: ¿Dónde se esconde la verdad?\n\n2.3 El “Día Cero” (Stock Out)\nNo basta con ver que no hubo ventas; hay que saber por qué.\n\nEscenario A: No hubo ventas porque nadie quiso comprar (Demanda baja).\nEscenario B: No hubo ventas porque el estante estaba vacío (Quiebre de stock).\n\nPara el planificador, el Escenario B es una emergencia que debe marcarse. Si el inventario llegó a cero y las ventas cayeron, ese dato de “cero ventas” debe ser descartado o corregido.\n\n\n2.4 La Trampa del Mes: Cuidado con la Granularidad\nSi miras tus ventas de forma mensual, podrías ver que vendiste 100 teniendo 100 en stock. Parece un éxito total. Pero si miras el día a día, quizás descubres que las 100 unidades se agotaron el día 10. Durante los otros 20 días estuviste vacío. Tu demanda real no era 100, ¡era probablemente 300! El análisis mensual es el escondite favorito de los errores.",
    "crumbs": [
      "I: El Diagnóstico",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>2. El Espejo de la Realidad: Ventas vs. Demanda</span>"
    ]
  },
  {
    "objectID": "cap-2-espejo-realidad.html#iii.-el-mundo-industrial-proyectos-y-clientes-internos",
    "href": "cap-2-espejo-realidad.html#iii.-el-mundo-industrial-proyectos-y-clientes-internos",
    "title": "2. El Espejo de la Realidad: Ventas vs. Demanda",
    "section": "III. El Mundo Industrial: Proyectos y Clientes Internos",
    "text": "III. El Mundo Industrial: Proyectos y Clientes Internos\nEn la industria pesada, tu cliente no es un extraño en la calle, sino un Ingeniero de Mantenimiento o de Proyectos. Aquí, la demanda tiene “nombre y apellido”.\n\n2.5 El concepto PEP: Inventario con Dueño\nImagina que tienes 10 motores en el patio, pero 8 ya están “prometidos” para la construcción de una nueva planta (Proyecto PEP1). Aunque los veas ahí, no están disponibles para el mantenimiento diario. Ignorar estas reservas contables es la forma más rápida de causar un accidente operativo.\n\n\n2.6 Fecha de Necesidad vs. Fecha de Entrega\nEste es el mayor error en la planificación:\n\nFecha de Necesidad: Cuándo el ingeniero pidió el repuesto para que la máquina no se detenga.\nFecha de Entrega: Cuándo finalmente pudiste dárselo (quizás semanas después).\n\nSi analizas tu historia con la fecha de entrega, estarás planificando basándote en tus propios retrasos. La demanda real siempre se mide en la fecha en que el cliente levantó la mano.\n\n\n\n\n\n\nImportantPlan de Acción: Sincronización Operativa\n\n\n\n\nAuditoría de Reservas: Compara sistemáticamente la fecha de solicitud original con la fecha de salida física. El diferencial es tu Lead Time Interno de ineficiencia.\nLimpieza de Hoarding: Identifica reservas cargadas con excesiva antelación por “miedo” al desabasto. Ajusta esas señales para que coincidan con el cronograma real del proyecto.",
    "crumbs": [
      "I: El Diagnóstico",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>2. El Espejo de la Realidad: Ventas vs. Demanda</span>"
    ]
  },
  {
    "objectID": "cap-2-espejo-realidad.html#footnotes",
    "href": "cap-2-espejo-realidad.html#footnotes",
    "title": "2. El Espejo de la Realidad: Ventas vs. Demanda",
    "section": "",
    "text": "En el ecosistema de SAP (específicamente en el módulo de PS - Project System), un Elemento PEP (Plan de Estructura de Proyecto) es la unidad organizativa fundamental para planificar, gestionar y controlar los costes y fechas de un proyecto.↩︎",
    "crumbs": [
      "I: El Diagnóstico",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>2. El Espejo de la Realidad: Ventas vs. Demanda</span>"
    ]
  },
  {
    "objectID": "cap-3-abcxyz-dinamico.html#fase-3-decodificando-la-personalidad-del-dato-syntetos-boylan",
    "href": "cap-3-abcxyz-dinamico.html#fase-3-decodificando-la-personalidad-del-dato-syntetos-boylan",
    "title": "3. Clasificando el Caos: Segmentación ABC/XYZ Dinámica",
    "section": "3.3 Fase 3: Decodificando la “Personalidad” del Dato (Syntetos-Boylan)",
    "text": "3.3 Fase 3: Decodificando la “Personalidad” del Dato (Syntetos-Boylan)\nMientras que el ABC nos indica la importancia económica y el XYZ la magnitud del ruido, la metodología de Syntetos-Boylan nos permite entender la estructura temporal de la demanda. Esta fase es crítica porque determina qué “motor matemático” (algoritmo) debemos usar para cada producto.\nPara clasificar la demanda, utilizamos dos métricas fundamentales que describen cómo se comporta un SKU a lo largo del tiempo.\n\n3.3.1 ADI (Average Demand Interval)\nEl Intervalo Promedio de Demanda mide la intermitencia o la “rareza” de los pedidos. Nos indica cuántos periodos pasan, en promedio, entre un evento de demanda y el siguiente.\nFórmula:\n\\[\n\\large ADI =p = \\frac{\\text{Número de Periodos Totales}}{\\text{Número de Periodos con Demanda}}\n\\]\n\nIntuición: Si un producto se pide todos los meses en un año, su ADI = 12/12 = 1 (Demanda Continua). Si se pide solo en 4 meses del año, su ADI = 12/4 = 3 (Demanda Intermitente).\nUmbral Crítico: El estándar de la industria sitúa el límite en 1.32. Por encima de este valor, la demanda se considera formalmente “intermitente”.\n\n\n\n3.3.2 \\(CV^2\\) (Squared Coefficient of Variation)\nEl Coeficiente de Variación al Cuadrado mide la estabilidad en el tamaño de los pedidos cuando estos ocurren. Ignora los periodos con demanda cero y se enfoca solo en la variabilidad de las cantidades pedidas.\nFórmula\n\n\\(CV^2\\) (Variabilidad del Tamaño): Mide la estabilidad de las cantidades cuando sí hay demanda.\n\\[\n\\large CV^2 = \\left( \\frac{\\sigma_{p}}{\\mu_{p}} \\right)^2\n\\]\nDonde:\n\\(\\large\\sigma_{p}\\): Desviación estándar de las cantidades en los periodos con demanda.\n\\(\\large\\mu_{p}\\): Promedio de las cantidades en los periodos con demanda.\nIntuición: Un \\(CV^2\\)bajo indica que, cada vez que el cliente pide, pide aproximadamente la misma cantidad. Un \\(CV^2\\) alto indica que los pedidos son erráticos (un mes pide 2 unidades y al siguiente 500).\nUmbral Crítico: El estándar se fija en 0.49.\n\n\n\n3.3.3 La Matriz de Clasificación Estratégica\nAl cruzar estos dos ejes, definimos cuatro cuadrantes que dictan el comportamiento del SKU y la herramienta de planificación a utilizar:\n\n\n\n\n\n\n\n\n\nCategoría\nCondición Matemática\nCaracterística\nEstrategia de Pronóstico Sugerida\n\n\n\n\nSmooth (Liso)\n(\\(p &lt; 1.32, CV^2 &lt; 0.49\\))\nDemanda regular en tiempo y cantidad.\nSuavización Exponencial Simple o SES.\n\n\nErratic (Errático)\n(\\(p &lt; 1.32, CV^2 \\ge 0.49\\))\nPedidos frecuentes pero de tamaños muy variables.\nModelos que gestionen la varianza (Holt-Winters).\n\n\nIntermittent (Intermitente)\n(\\(p \\ge 1.32, CV^2 &lt; 0.49\\))\nPedidos espaciados pero de tamaños predecibles.\nMétodo de Croston (separa intervalo de volumen).\n\n\nLumpy (Atronado)\n(\\(p \\ge 1.32, CV^2 \\ge 0.49\\))\nLa peor pesadilla: aleatorio en tiempo y en cantidad.\nSimulación Monte Carlo o Bootstrapping.\n\n\n\n\n\n\n\n\n\nImportantEl Gran Error del “Promedio Simple”\n\n\n\nTratar un producto Lumpy con un promedio móvil simple es el error más costoso en Supply Chain. El promedio te dará un número “cómodo” (ej: 10 unidades/mes), pero la realidad es que el producto vende 0 durante 4 meses y luego vende 40 de golpe. Si planeas con el promedio, tendrás 4 meses de sobrestock inútil y un quiebre masivo justo cuando ocurra la venta real.\n\n\n\n\n3.3.4 ¿Cómo impacta esto en el ROII?\nLa identificación de productos Intermittent y Lumpy permite dejar de perseguir un “pronóstico perfecto” (que no existe para ellos) y pasar a una gestión de Stock de Seguridad Basado en Riesgo.\n\nPara productos Smooth: Reducimos stock de seguridad al mínimo para liberar capital.\nPara productos Lumpy: Aplicamos políticas de “Pedido bajo pedido” o consolidación de inventario (Inventory Pooling) para evitar que el capital se oxide en el estante.\n\nConclusión de la Fase 3: Dominar Syntetos-Boylan es pasar de ser un “digitador de pedidos” a un Estratega de Inventarios. Ya no solo sabes qué es importante (ABC), sino que ahora sabes exactamente qué “arma” matemática usar para ganar la batalla contra la incertidumbre.",
    "crumbs": [
      "I: El Diagnóstico",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>3. Clasificando el Caos: Segmentación ABC/XYZ Dinámica</span>"
    ]
  },
  {
    "objectID": "cap-3-abcxyz-dinamico.html#fase-4-posicionamiento-táctico-y-gestión-del-drift",
    "href": "cap-3-abcxyz-dinamico.html#fase-4-posicionamiento-táctico-y-gestión-del-drift",
    "title": "3. Clasificando el Caos: Segmentación ABC/XYZ Dinámica",
    "section": "3.4 Fase 4: Posicionamiento Táctico y Gestión del “Drift”",
    "text": "3.4 Fase 4: Posicionamiento Táctico y Gestión del “Drift”\nUna vez que tenemos el ADN del producto (ABC-VED / XYZ / Syntetos-Boylan), la pregunta es: ¿Qué hacemos con esta información? No se trata de tener un reporte bonito, sino de decidir dónde poner físicamente el inventario y cada cuánto tiempo debemos cuestionar nuestras clasificaciones.\n\n3.4.1 Posicionamiento de Inventario y “Pooling”\nEl error tradicional es replicar todo el catálogo en todas las sucursales o nodos de la red. Aplicando nuestra segmentación, optimizamos la red logística:\n\nAX / Smooth / Vital: Descentralización Total. Estos productos deben estar cerca del punto de consumo (línea de producción o tiendas locales). Su flujo es predecible y el costo de quiebre es altísimo.\nCZ / Lumpy / Deseable: Centralización (Inventory Pooling). No guardes estos artículos en cada sucursal. Consolídalos en un Centro de Distribución (CD) Central.\n\n\n\n\n\n\n\nNoteLa Ley de la Raíz Cuadrada del Inventario\n\n\n\n¿Por qué centralizar los productos “Lumpy”? La estadística nos dice que al consolidar la demanda incierta de \\(n\\) ubicaciones en una sola, el stock de seguridad necesario se reduce drásticamente.\n\\[\nSS_{central} \\approx \\frac{\\sum_{i=1}^{n} SS_{i}}{\\sqrt{n}}\n\\]\nAl consolidar, la variabilidad de un cliente se compensa con la de otro, reduciendo la exposición financiera total sin sacrificar el nivel de servicio.\n\n\n\n\n3.4.2 Implementación: El “ADN del Producto” en Código\nPara llevar esto a la práctica, no podemos depender de cálculos manuales. Utilizaremos el ecosistema tidyverse para clasificar nuestro portafolio y generar un Mapa de Personalidad de Inventarios. Este mapa permite identificar visualmente dónde reside el riesgo operativo.. Este bloque de código procesa la Demanda Reconstruida para asignar todas las categorías de forma simultánea.\n\nlibrary(tidyverse)\n\n# 1. Simulación de un portafolio de 500 SKUs para visualización estratégica\nset.seed(123)\ndf_portfolio &lt;- tibble(\n  sku = paste0(\"SKU-\", 1:500),\n  adi = runif(500, 1, 4),    # Intervalo promedio de demanda\n  cv2 = runif(500, 0.1, 1.2)  # Variabilidad del tamaño del pedido\n) %&gt;%\n  mutate(perfil = case_when(\n    adi &lt; 1.32 & cv2 &lt; 0.49 ~ \"Smooth\",\n    adi &gt;= 1.32 & cv2 &lt; 0.49 ~ \"Intermittent\",\n    adi &lt; 1.32 & cv2 &gt;= 0.49 ~ \"Erratic\",\n    TRUE ~ \"Lumpy\"\n  ))\n\n# 2. Visualización para la toma de decisiones (Mapa Syntetos-Boylan)\nggplot(df_portfolio, aes(x = adi, y = cv2, color = perfil)) +\n  geom_point(alpha = 0.7, size = 3) +\n  # Líneas de umbral técnico (Thresholds)\n  geom_vline(xintercept = 1.32, linetype = \"dashed\", color = \"darkred\") +\n  geom_hline(yintercept = 0.49, linetype = \"dashed\", color = \"darkred\") +\n  # Colores estratégicos\n  scale_color_manual(values = c(\n    \"Smooth\" = \"#27ae60\",       # Verde: Predictibilidad alta\n    \"Erratic\" = \"#f1c40f\",      # Amarillo: Volumen variable\n    \"Intermittent\" = \"#2980b9\", # Azul: Frecuencia baja\n    \"Lumpy\" = \"#c0392b\"         # Rojo: Riesgo máximo\n  )) +\n  theme_minimal() +\n  labs(\n    title = \"Mapa de Personalidad de Inventarios (Syntetos-Boylan)\",\n    subtitle = \"Segmentación para selección de algoritmos de pronóstico\",\n    x = \"Frecuencia de Demanda (ADI)\", \n    y = \"Variabilidad del Tamaño (CV2)\",\n    color = \"Perfil de Demanda\"\n  )\n\n\n\n\n\n\n\n\n\n\n3.4.3 Gestión del “Drift” (El Inventario está Vivo)\nEl mayor peligro de una segmentación es dejarla estática. Un producto que hoy es A (Estrella) puede convertirse en C (Hueso) en tres meses. A este fenómeno lo llamamos Drift.\nReclasificación Automática: Recomendamos un ciclo de recalculo mensual. Si un SKU salta de C a A, el sistema debe disparar una alerta de “Cambio de Política de Reabastecimiento”.\nGestión de Transiciones: Cuando un producto baja de categoría (Drift Negativo), debemos reducir inmediatamente el Punto de Reorden para evitar el Stock Obsoleto.",
    "crumbs": [
      "I: El Diagnóstico",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>3. Clasificando el Caos: Segmentación ABC/XYZ Dinámica</span>"
    ]
  },
  {
    "objectID": "cap-3-abcxyz-dinamico.html#resumen-y-conclusión-general-del-capítulo-3",
    "href": "cap-3-abcxyz-dinamico.html#resumen-y-conclusión-general-del-capítulo-3",
    "title": "3. Clasificando el Caos: Segmentación ABC/XYZ Dinámica",
    "section": "3.6 Resumen y Conclusión General del Capítulo 3",
    "text": "3.6 Resumen y Conclusión General del Capítulo 3\nDominar la segmentación dinámica es pasar de una gestión reactiva a una arquitectura de suministros. En este capítulo hemos establecido que:\n\nEl Inventario no es estático: La segmentación debe “vivir”. Un producto que hoy es un “hueso” (C) puede ser mañana una “estrella” (A). Por eso calculamos el Drift Dinámico mensualmente.\nEl esfuerzo debe ser proporcional al impacto: No todas las neuronas del planificador valen lo mismo; deben enfocarse donde el capital está en juego. No pierdas tiempo pronosticando un tornillo de 10 centavos que es Clase C y Smooth; automatízalo.\nLa tecnología es el gran habilitador: Herramientas como R (usando tidyverse y ggplot2) nos permiten ver el “Mapa de Personalidad” de miles de productos en segundos, algo que en un Excel tradicional sería imposible de visualizar con claridad.\n\nAl finalizar este capítulo, ya no vemos una bodega llena de cajas. Vemos un mapa de calor financiero y operativo. Sabemos qué proteger con garras y dientes (los Vitales), qué optimizar para liberar caja (los Clase A) y qué centralizar para reducir el riesgo (los Lumpy).\n\n\n\n\n\n\nNoteEl Siguiente Paso: El Espejo de la Verdad\n\n\n\nAhora que hemos segmentado nuestro mundo, es hora de medir qué tan buenos somos prediciendo su futuro. En el Capítulo 4, entraremos en el terreno de los KPIs de Pronóstico (Accuracy, Bias, WAPE). Vamos a descubrir quiénes de nuestros modelos están ganando la batalla contra la incertidumbre y dónde estamos fallando.",
    "crumbs": [
      "I: El Diagnóstico",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>3. Clasificando el Caos: Segmentación ABC/XYZ Dinámica</span>"
    ]
  },
  {
    "objectID": "cap-3-abcxyz-dinamico.html#footnotes",
    "href": "cap-3-abcxyz-dinamico.html#footnotes",
    "title": "3. Clasificando el Caos: Segmentación ABC/XYZ Dinámica",
    "section": "",
    "text": "ROII (Return on Inventory Investment): Es la métrica quirúrgica para inventarios. También se conoce en finanzas como GMROI (Gross Margin Return on Investment).↩︎\nROI (Return on Investment) es una métrica de visión general corporativa.↩︎",
    "crumbs": [
      "I: El Diagnóstico",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>3. Clasificando el Caos: Segmentación ABC/XYZ Dinámica</span>"
    ]
  }
]